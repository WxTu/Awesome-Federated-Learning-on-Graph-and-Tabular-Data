# Federated-Learning-on-Graph-and-Tabular-Data

[![Stars](https://img.shields.io/github/stars/youngfish42/Awesome-Federated-Learning-on-Graph-and-Tabular-Data.svg?color=orange)](https://github.com/youngfish42/Awesome-Federated-Learning-on-Graph-and-Tabular-Data/stargazers)  [![Awesome](https://awesome.re/badge-flat.svg)](https://awesome.re) [![License](https://img.shields.io/github/license/youngfish42/Awesome-Federated-Learning-on-Graph-and-Tabular-Data.svg?color=green)](https://github.com/youngfish42/image-registration-resources/blob/master/LICENSE) ![](https://img.shields.io/github/last-commit/youngfish42/Awesome-Federated-Learning-on-Graph-and-Tabular-Data)

---

**Table of Contents**

- [Papers](#Papers)
  - [FL on Graph Data and Graph Neural Networks](#FL-on-Graph-Data-and-Graph-Neural-Networks)  [![dblp](https://img.shields.io/badge/dynamic/json?label=dblp&query=%24.result.hits[%27%40total%27]&url=https%3A%2F%2Fdblp.org%2Fsearch%2Fpubl%2Fapi%3Fq%3DFederated%2520graph%257Csubgraph%257Cgnn%26format%3Djson%26h%3D1000)](https://dblp.uni-trier.de/search?q=Federated%20graph%7Csubgraph%7Cgnn) 
  - [FL on Tabular Data](#FL-on-Tabular-Data)  [![dblp](https://img.shields.io/badge/dynamic/json?label=dblp&query=%24.result.hits[%27%40total%27]&url=https%3A//dblp.org/search/publ/api%3Fq%3Dfederate%2520tree%257Cboost%257Cbagging%257Cgbdt%257Ctabular%257Cforest%26format%3Djson%26h%3D1000)](https://dblp.org/search?q=federate%20tree%7Cboost%7Cbagging%7Cgbdt%7Ctabular%7Cforest)
  - [FL in top-tier journal](#FL-in-top-tier-journal)
  - FL in top-tier conferences
    - [AI](#FL-in-top-AI-Conferences)  [ML](#FL-in-top-ML-Conferences) [DM](#FL-in-top-DM-Conferences) [Secure](#FL-in-top-Secure-Conferences) [CV](#FL-in-top-CV-Conferences) [NLP](#FL-in-top-NLP-Conferences) [IR](#FL-in-top-IR-Conferences) [DB](#FL-in-top-DB-Conferences) [Network](#FL-in-top-Network-Conferences)  [System](#FL-in-top-System-Conferences) 
- [Framework](#Framework)
- [Datasets](#Datasets)



# Papers

**Categories**

- Artificial Intelligence (IJCAI, AAAI, AISTATS)
- Machine Learning (NeurIPS, ICML, ICLR, COLT, UAI)
- Data Mining (KDD, WSDM)
- Secure (S&P, CCS, USENIX Security, NDSS)
- Computer Vision (ICCV, CVPR, ECCV, MM)
- Natural Language Processing (ACL, EMNLP, NAACL, COLING)
- Information Retrieval (SIGIR)
- Database (SIGMOD, ICDE, VLDB)
- Network (SIGCOMM, INFOCOM, MOBICOM, NSDI, WWW)
- System (OSDI, SOSP, ISCA, MLSys) 



**keywords**

Statistics: :fire: code is available & stars >= 100 | :star: citation >= 50  | :mortar_board: Top-tier venue 

**`kg.`**: Knowledge Graph |     **`data.`**: dataset  |   **`surv.`**: survey





**Update log**

 ![](https://img.shields.io/github/last-commit/youngfish42/Awesome-Federated-Learning-on-Graph-and-Tabular-Data)

- *2022/07/31 -  Add VLDB papers*
- *2022/07/30 -  Add top-tier system conferences papers and add COLT,UAI,OSDI, SOSP, ISCA, MLSys, AISTATS,WSDM papers*
- *2022/07/28 -  Add a list of top-tier conferences papers and add IJCAI,SIGIR,SIGMOD,ICDE,WWW,SIGCOMM.INFOCOM,WWW papers*
- *2022/07/27 -  add some ECCV 2022 papers*
- *2022/07/22 -  add CVPR 2022 and MM 2020,2021 papers*
- *2022/07/21 - give TL;DR and interpret information of papers. And add KDD 2022 papers*
- *2022/07/15 - give a list of papers in the field of federated learning in top NLP/Secure conferences. And add ICML 2022 papers*
- *2022/07/14 - give a list of papers in the field of federated learning in top ML/CV/AI/DM conferences from  [innovation-cat](https://github.com/innovation-cat)‘s’    [Awesome-Federated-Machine-Learning](https://github.com/innovation-cat/Awesome-Federated-Machine-Learning) and find :fire:  papers(code is available & stars >= 100)*
- *2022/07/12 - added information about the last commit time of the federated learning open source framework (can be used to determine the maintenance of the code base)*
- *2022/07/12 - give a list of papers in the field of federated learning in top journals*
- *2022/05/25 - complete the paper and code lists of FL on tabular data and Tree algorithms*
- *2022/05/25 - add the paper list of FL on tabular data and Tree algorithms*
- *2022/05/24 - complete the paper and code lists of FL on graph data and Graph Neural Networks*
- *2022/05/23 - add the paper list of FL on graph data and Graph Neural Networks*
- *2022/05/21 - update all of Federated Learning Framework*



## FL on Graph Data and Graph Neural Networks 

[![dblp](https://img.shields.io/badge/dynamic/json?label=dblp&query=%24.result.hits[%27%40total%27]&url=https%3A%2F%2Fdblp.org%2Fsearch%2Fpubl%2Fapi%3Fq%3DFederated%2520graph%257Csubgraph%257Cgnn%26format%3Djson%26h%3D1000)](https://dblp.uni-trier.de/search?q=Federated%20graph%7Csubgraph%7Cgnn) 

This section partially refers to [DBLP](https://dblp.uni-trier.de/search?q=Federated%20graph%7Csubgraph%7Cgnn) search engine  and repositories [Awesome-Federated-Learning-on-Graph-and-GNN-papers](https://github.com/huweibo/Awesome-Federated-Learning-on-Graph-and-GNN-papers) and [Awesome-Federated-Machine-Learning](https://github.com/innovation-cat/Awesome-Federated-Machine-Learning#16-graph-neural-networks).

| T                                                        | Affiliation       | Venue                  | Year | TL;DR                                               | Materials                                                    |
| ------------------------------------------------------------ | ---------------------- | ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| FedWalk: Communication Efficient Federated Unsupervised Node Embedding with Differential Privacy | Shanghai Jiao Tong University | KDD :mortar_board: | 2022 | FedWalk[^FedWalk] | [[PDF](https://arxiv.org/abs/2205.15896)] |
| EasyFGL: Towards a Unified, Comprehensive and Efficient Platform for Federated Graph Learning :fire: | Alibaba Group | KDD :mortar_board: | 2022 | FederatedScope-GNN [^FederatedScope-GNN] | [[PDF](https://arxiv.org/abs/2204.05562)] [Code](https://github.com/alibaba/FederatedScope) |
| Deep Neural Network Fusion via Graph Matching with Applications to Model Ensemble and Federated Learning | Shanghai Jiao Tong University | ICML :mortar_board: | 2022 | GAMF [^GAMF] | [[PUB.](https://proceedings.mlr.press/v162/liu22k/liu22k.pdf)] [[Code](https://github.com/Thinklab-SJTU/GAMF)] |
| Meta-Learning Based Knowledge Extrapolation for Knowledge Graphs in the Federated Setting  **`kg.`** |    | IJCAI :mortar_board:   | 2022 |  | [[PDF]](https://doi.org/10.48550/arXiv.2205.04692) [[Code](https://github.com/zjukg/maker)] |
| Personalized Federated Learning With a Graph | | IJCAI :mortar_board: | 2022 | | [[PUB](https://www.ijcai.org/proceedings/2022/357).] [[PDF](https://arxiv.org/abs/2203.00829)] [[Code](https://github.com/dawenzi098/SFL-Structural-Federated-Learning)] |
| Vertically Federated Graph Neural Network for Privacy-Preserving Node Classification | | IJCAI :mortar_board: | 2022 | | [[PUB](https://www.ijcai.org/proceedings/2022/272).] [[PDF](https://arxiv.org/abs/2005.11903)] |
| SpreadGNN: Serverless Multi-task Federated Learning for Graph Neural Networks |     | AAAI :mortar_board:    | 2022 |  | [[PDF]](https://arxiv.org/pdf/2106.02743) [[Code]](https://github.com/FedML-AI/SpreadGNN) [[Interpret(zh)](https://zhuanlan.zhihu.com/p/429720860)] |
| A federated graph neural network framework for privacy-preserving personalization |  | Nature Communications | 2022 |  | [[PUB](https://www.nature.com/articles/s41467-022-30714-9).] |
| Efficient Federated Learning on Knowledge Graphs via Privacy-preserving Relation Embedding Aggregation **`kg.`** |            | ACL Workshop           | 2022 |  | [[PDF](https://arxiv.org/format/2203.09553)] [[Code](https://github.com/taokz/FedR)] |
| Power Allocation for Wireless Federated Learning using Graph Neural Networks |          | ICASSP         | 2022 |  | [[PDF](https://arxiv.org/pdf/2111.07480)] [[PUB](https://ieeexplore.ieee.org/document/9747764).] [[Code](https://github.com/bl166/wirelessfl-pdgnet)] |
| Privacy-Preserving Federated Multi-Task Linear Regression: A One-Shot Linear Mixing Approach Inspired By Graph Regularization |  | ICASSP | 2022 |  | [[PUB](https://ieeexplore.ieee.org/document/9746007).] |
| Federated Graph Learning with Periodic Neighbour Sampling |  | IWQoS | 2022 |  | [[PUB](https://ieeexplore.ieee.org/document/9812908).] |
| A Privacy-Preserving Subgraph-Level Federated Graph Neural Network via Differential Privacy |                               | KSEM                   | 2022 |  | [[PDF]](https://arxiv.org/abs/2206.03492) [[PUB](https://link.springer.com/chapter/10.1007/978-3-031-10989-8_14).] |
| Graph-Based Traffic Forecasting via Communication-Efficient Federated Learning |  | WCNC | 2022 |  | [[PUB](https://ieeexplore.ieee.org/document/9771883).] |
| Malicious Transaction Identification in Digital Currency via Federated Graph Deep Learning |  | INFOCOM Workshops | 2022 |  | [[PUB](https://ieeexplore.ieee.org/document/9797992/).] |
| Federated learning of molecular properties with graph neural networks in a heterogeneous setting |  | Patterns | 2022 |  | [[PUB](https://linkinghub.elsevier.com/retrieve/pii/S2666389922001180).] |
| Decentralized Graph Federated Multitask Learning for Streaming Data |                    | CISS                   | 2022 |      | [[PUB.]](https://doi.org/10.1109/CISS53076.2022.9751160) [[[Interpret(zh)]](https://zhuanlan.zhihu.com/p/430508567)] |
| Dynamic Neural Graphs Based Federated Reptile for Semi-Supervised Multi-Tasking in Healthcare Applications |                    | JBHI                   | 2022 |         | [[PDF]](https://ieeexplore.ieee.org/document/9648036)        |
| [Device Sampling for Heterogeneous Federated Learning: Theory, Algorithms, and Implementation.](https://ieeexplore.ieee.org/document/9488906) |  | INFOCOM :mortar_board: | 2021 |  | [PDF](https://arxiv.org/abs/2101.00787) |
| Federated Knowledge Graphs Embedding  **`kg.`**              |                    | CIKM                   | 2021 |  | [[PDF]](https://arxiv.org/pdf/2105.07615) [[Code](https://github.com/HKUST-KnowComp/FKGE)] [[Interpret(zh)](https://zhuanlan.zhihu.com/p/437895959)] |
| Federated Graph Classification over Non-IID Graphs           |  | NeurIPS :mortar_board: | 2021 |  | [[PDF]](https://arxiv.org/pdf/2106.13423) [[PUB.]](https://papers.nips.cc/paper/2021/hash/9c6947bd95ae487c81d4e19d3ed8cd6f-Abstract.html) [[Code](https://github.com/Oxfordblue7/GCFL)] [[Interpret(zh)](https://zhuanlan.zhihu.com/p/430623053)] |
| Decentralized Federated Graph Neural Networks |  | IJCAI Workshop | 2021 |  | [[PDF](https://federated-learning.org/fl-ijcai-2021/FTL-IJCAI21_paper_20.pdf)] |
| FL-DISCO: Federated Generative Adversarial Network for Graph-based Molecule Drug Discovery: Special Session Paper |                   | ICCAD                  | 2021 |     | [[PUB.]](https://doi.org/10.1109/ICCAD51958.2021.9643440)    |
| DAG-FL: Direct Acyclic Graph-based Blockchain Empowers On-Device Federated Learning |                     | ICC                    | 2021 |       | [[PUB.]](https://doi.org/10.1109/ICC42927.2021.9500737)      |
| Graphical Federated Cloud Sharing Markets                    |                   | TSUSC                  | 2021 |          | [[PUB.]](https://doi.org/10.1109/TSUSC.2021.3100010)         |
| Virtual Knowledge Graphs for Federated Log Analysis **`kg.`** |                    | ARES                   | 2021 |             | [[PUB.]](https://doi.org/10.1145/3465481.3465767)            |
| FedE: Embedding Knowledge Graphs in Federated Setting **`kg.`** |                   | IJCKG                  | 2021 |  | [[PDF]](https://arxiv.org/pdf/2010.12882) [[PUB.]](https://doi.org/10.1145/3502223.3502233)[[Code]](https://github.com/AnselCmy/FedE) |
| Federated Knowledge Graph Embeddings with Heterogeneous Data **`kg.`** |                    | CCKS                   | 2021 |         | [[PUB.]](https://doi.org/10.1007/978-981-16-6471-7_2)        |
| A Graph Federated Architecture with Privacy Preserving Learning |                   | SPAWC                  | 2021 |  | [[PDF]](https://arxiv.org/pdf/2104.13215) [[PUB.]](https://doi.org/10.1109/SPAWC51858.2021.9593148) |
| Federated Social Recommendation with Graph Neural Network    |                | ACM TIST               | 2021 |                     | [[PDF](https://arxiv.org/pdf/2111.10778)]                    |
| Subgraph Federated Learning with Missing Neighbor Generation |  | NeurIPS :mortar_board: | 2021 |  | [[PDF]](https://arxiv.org/pdf/2106.13430) [[PUB.]](https://papers.neurips.cc/paper/2021/hash/34adeb8e3242824038aa65460a47c29e-Abstract.html) |
| Cross-Node Federated Graph Neural Network for Spatio-Temporal Data Modeling |      | KDD :mortar_board:     | 2021 |  | [[PDF]](https://arxiv.org/pdf/2106.05223) [[Code]](https://github.com/mengcz13/KDD2021_CNFGNN) |
| FedGraphNN: A Federated Learning System and Benchmark for Graph Neural Networks  :fire:  **`surv.`** |               | ICLR-DPML              | 2021 |  | [[PDF]](https://arxiv.org/pdf/2104.07145) [[Code]](https://github.com/FedML-AI/FedGraphNN)  [[Interpret(zh)](https://zhuanlan.zhihu.com/p/429220636)] |
| Cluster-driven Graph Federated Learning over Multiple Domains |           | CVPR Workshop          | 2021 |                     | [[PDF]](https://arxiv.org/pdf/2104.14628) [[Interpret(zh)](https://zhuanlan.zhihu.com/p/440527314)] |
| Differentially Private Federated Knowledge Graphs Embedding **`kg.`** |                    | CIKM                   | 2021 |  | [[PDF]](https://arxiv.org/pdf/2105.07615) [[Code]](https://github.com/HKUST-KnowComp/FKGE) |
| Glint: Decentralized Federated Graph Learning with Traffic Throttling and Flow Scheduling |                   | IWQoS                  | 2021 |     | [[PUB.]](https://doi.org/10.1109/IWQOS52092.2021.9521331)    |
| A Federated Multigraph Integration Approach for Connectional Brain Template Learning |         | MICCAI Workshop        | 2021 |  | [[PDF]](https://link.springer.com/chapter/10.1007/978-3-030-89847-2_4) |
| FedGraph: Federated Graph Learning with Intelligent Sampling |     | TPDS :mortar_board:    | 2021 |  | [[PDF]](https://ieeexplore.ieee.org/abstract/document/9606516/) |
| Federated Graph Neural Network for Cross-graph Node Classification |                    | CCIS                   | 2021 |      | [[PUB.]](https://doi.org/10.1109/CCIS53392.2021.9754598)     |
| GraFeHTy: Graph Neural Network using Federated Learning for Human Activity Recognition |                   | ICMLA                  | 2021 |       | [[PUB.]](https://doi.org/10.1109/ICMLA52953.2021.00184)      |
| Distributed Training of Graph Convolutional Networks |  | TSIPN | 2021 |  | [[PUB](https://ieeexplore.ieee.org/document/9303371).] [[PDF](https://arxiv.org/abs/2007.06281)] [[[Interpret(zh)]](https://zhuanlan.zhihu.com/p/433329525)] |
| ASFGNN: Automated Separated-Federated Graph Neural Network   |                    | PPNA                   | 2020 |  | [[PDF]](https://arxiv.org/pdf/2011.03248) [[PUB.] ](https://doi.org/10.1007/s12083-021-01074-w) [[Interpret(zh)](https://zhuanlan.zhihu.com/p/431283541)] |
| Towards Federated Graph Learning for Collaborative Financial Crimes Detection |        | NeurIPS Workshop       | 2019 |                     | [[PDF]](https://arxiv.org/pdf/1909.12946)                    |
| FedGNN: Federated Graph Neural Network for Privacy-Preserving Recommendation |    | ICML workshop   | 2021 |                    | [[PDF]](https://arxiv.org/pdf/2102.04925) [[Interpret(zh)](https://zhuanlan.zhihu.com/p/428783383)] |
| SGNN: A Graph Neural Network Based Federated Learning Approach by Hiding Structure |  | BigData | 2019 |  | [[PDF]](https://www.researchgate.net/profile/Shijun_Liu3/publication/339482514_SGNN_A_Graph_Neural_Network_Based_Federated_Learning_Approach_by_Hiding_Structure/links/5f48365d458515a88b790595/SGNN-A-Graph-Neural-Network-Based-Federated-Learning-Approach-by-Hiding-Structure.pdf) [[PUB](https://ieeexplore.ieee.org/document/9005983).] |
| Federated Graph Contrastive Learning | University of Technology Sydney | preprint | 2022 | | [[PDF](https://arxiv.org/abs/2207.11836)] |
| Federated Graph Machine Learning: A Survey of Concepts, Techniques, and Applications **`surv.`** | University of Virginia | preprint | 2022 | FGML [^FGML] | [[PDF](https://arxiv.org/abs/2207.11812)] |
| FD-GATDR: A Federated-Decentralized-Learning Graph Attention Network for Doctor Recommendation Using EHR |  | preprint | 2022 |  | [[PDF](https://arxiv.org/abs/2207.05750)] |
| Privacy-preserving Graph Analytics: Secure Generation and Federated Learning |  | preprint | 2022 |  | [[PDF](https://arxiv.org/abs/2207.00048)] |
| Personalized Subgraph Federated Learning |  | preprint | 2022 |  | [[PDF](https://arxiv.org/abs/2206.10206)] |
| Federated Graph Attention Network for Rumor Detection |  | preprint | 2022 |  | [[PDF]](https://arxiv.org/abs/2206.05713) [[Code](https://github.com/baichuanzheng1/fedgat)] |
| FedRel: An Adaptive Federated Relevance Framework for Spatial Temporal Graph Learning |  | preprint | 2022 |  | [[PDF]](https://arxiv.org/abs/2206.03420) |
| Privatized Graph Federated Learning                          |                | preprint               | 2022 |                     | [[PDF](https://arxiv.org/pdf/2203.07105)]                    |
| Graph-Assisted Communication-Efficient Ensemble Federated Learning |                | preprint               | 2022 |                     | [[PDF](https://arxiv.org/pdf/2202.13447)]                    |
| Federated Graph Neural Networks: Overview, Techniques and Challenges  **`surv.`** |                | preprint               | 2022 |                     | [[PDF](https://arxiv.org/pdf/2202.07256)]                    |
| More is Better (Mostly): On the Backdoor Attacks in Federated Graph Neural Networks |                | preprint               | 2022 |                     | [[PDF](https://arxiv.org/pdf/2202.03195)]                    |
| FedGCN: Convergence and Communication Tradeoffs in Federated Training of Graph Convolutional Networks |                | preprint               | 2022 |  | [[PDF](https://arxiv.org/pdf/2201.12433)] [[Code](https://github.com/yh-yao/FedGCN)] |
| Federated Learning with Heterogeneous Architectures using Graph HyperNetworks |                | preprint               | 2022 |                     | [[PDF](https://arxiv.org/pdf/2201.08459)]                    |
| FedNI: Federated Graph Learning with Network Inpainting for Population-Based Disease Prediction |                | preprint               | 2021 |                     | [[PDF](https://arxiv.org/pdf/2112.10166)]                    |
| STFL: A Temporal-Spatial Federated Learning Framework for Graph Neural Networks |                | preprint               | 2021 |  | [[PDF](https://arxiv.org/pdf/2111.06750)] [[Code](https://github.com/jw9msjwjnpdrlfw/tsfl)] |
| Graph-Fraudster: Adversarial Attacks on Graph Neural Network Based Vertical Federated Learning |  | preprint | 2021 |  | [[PDF](https://arxiv.org/pdf/2110.06468)] [[Code](https://github.com/hgh0545/graph-fraudster)] |
| Leveraging a Federation of Knowledge Graphs to Improve Faceted Search in Digital Libraries **`kg.`** |                | preprint               | 2021 |                     | [[PDF]](https://arxiv.org/pdf/2107.05447)                    |
| Federated Myopic Community Detection with One-shot Communication |                | preprint               | 2021 |                     | [[PDF]](https://arxiv.org/pdf/2106.07255)                    |
| Federated Graph Learning -- A Position Paper  **`surv.`**    |                | preprint               | 2021 |                     | [[PDF]](https://arxiv.org/pdf/2105.11099)                    |
| A Vertical Federated Learning Framework for Graph Convolutional Network |                | preprint               | 2021 |                     | [[PDF]](https://arxiv.org/pdf/2106.11593)                    |
| FedGL: Federated Graph Learning Framework with Global Self-Supervision |                | preprint               | 2021 |                     | [[PDF]](https://arxiv.org/pdf/2105.03170)                    |
| FL-AGCNS: Federated Learning Framework for Automatic Graph Convolutional Network Search |                | preprint               | 2021 |                     | [[PDF]](https://arxiv.org/pdf/2104.04141)                    |
| Towards On-Device Federated Learning: A Direct Acyclic Graph-based Blockchain Approach |  | preprint | 2021 |  | [[PDF](https://arxiv.org/pdf/2104.13092)] |
| GraphFL: A Federated Learning Framework for Semi-Supervised Node Classification on Graphs |                | preprint               | 2020 |                     | [[PDF]](https://arxiv.org/pdf/2012.04187)                    |
| Improving Federated Relational Data Modeling via Basis Alignment and Weight Penalty **`kg.`** |                | preprint               | 2020 |                     | [[PDF]](https://arxiv.org/pdf/2011.11369)                    |
| Federated Dynamic GNN with Secure Aggregation                |                | preprint               | 2020 |                     | [[PDF]](https://arxiv.org/pdf/2009.07351)                    |
| GraphFederator: Federated Visual Analysis for Multi-party Graphs |  | preprint | 2020 |  | [[PDF](https://arxiv.org/pdf/2008.11989)] |
| Privacy-Preserving Graph Neural Network for Node Classification |                | preprint               | 2020 |                     | [[PDF]](https://arxiv.org/pdf/2005.11903)                    |
| Peer-to-peer federated learning on graphs                    |                | preprint               | 2019 |                     | [[PDF]](https://arxiv.org/pdf/1901.11173)                    |




### Private Graph Neural Networks (todo)

- [Arxiv 2021] Privacy-Preserving Graph Convolutional Networks for Text Classification. [[PDF]](https://arxiv.org/pdf/2102.09604)
- [Arxiv 2021] GraphMI: Extracting Private Graph Data from Graph Neural Networks. [[PDF]](https://arxiv.org/pdf/2106.02820)
- [Arxiv 2021] Towards Representation Identical Privacy-Preserving Graph Neural Network via Split Learning. [[PDF]](https://arxiv.org/abs/2107.05917)
- [Arxiv 2020] Locally Private Graph Neural Networks. [[PDF]](https://arxiv.org/pdf/2006.05535)



## FL on Tabular Data

[![dblp](https://img.shields.io/badge/dynamic/json?label=dblp&query=%24.result.hits[%27%40total%27]&url=https%3A//dblp.org/search/publ/api%3Fq%3Dfederate%2520tree%257Cboost%257Cbagging%257Cgbdt%257Ctabular%257Cforest%26format%3Djson%26h%3D1000)](https://dblp.org/search?q=federate%20tree%7Cboost%7Cbagging%7Cgbdt%7Ctabular%7Cforest)

This section refers to [DBLP](https://dblp.org/search?q=federate%20tree%7Cboost%7Cbagging%7Cgbdt%7Ctabular%7Cforest) search engine.

| Title                                                        | Affiliation | Venue                       | Year | TL;DR | Materials                                                    |
| ------------------------------------------------------------ | ----------- | --------------------------- | ---- | ----- | ------------------------------------------------------------ |
| Federated Random Forests can improve local performance of predictive models for various healthcare applications |             | Bioinform.                  | 2022 |       | [[PUB](https://academic.oup.com/bioinformatics/article-abstract/38/8/2278/6525214).] [[Code](https://featurecloud.ai/)] |
| Federated Forest                                             |             | TBD                         | 2022 |       | [[PDF](https://arxiv.org/pdf/1905.10053)] [[PUB](https://ieeexplore.ieee.org/document/9088965).] |
| Federated Functional Gradient Boosting                       |             | AISTATS                     | 2022 |       | [[PDF](https://arxiv.org/pdf/2103.06972)] [[PUB](https://proceedings.mlr.press/v151/shen22a.html).] [[Code](https://github.com/shenzebang/Federated-Learning-Pytorch)] |
| Fed-GBM: a cost-effective federated gradient boosting tree for non-intrusive load monitoring |             | e-Energy                    | 2022 |       | [[PUB](https://dl.acm.org/doi/10.1145/3538637.3538840).]     |
| eFL-Boost: Efficient Federated Learning for Gradient Boosting Decision Trees |             | IEEE Access                 | 2022 |       | [[PUB](https://ieeexplore.ieee.org/document/9761890).]       |
| Random Forest Based on Federated Learning for Intrusion Detection |             | AIAI                        | 2022 |       | [[PUB](https://link.springer.com/chapter/10.1007/978-3-031-08333-4_11).] |
| Cross-silo federated learning based decision trees           |             | SAC                         | 2022 |       | [[PUB](https://dl.acm.org/doi/10.1145/3477314.3507149).]     |
| Leveraging Spanning Tree to Detect Colluding Attackers in Federated Learning |             | INFCOM Workshops            | 2022 |       | [[PUB](https://ieeexplore.ieee.org/document/9798077).]       |
| VF2Boost: Very Fast Vertical Federated Gradient Boosting for Cross-Enterprise Learning |             | SIGMOD :mortar_board:       | 2021 |       | [[PUB](https://dl.acm.org/doi/10.1145/3448016.3457241).]     |
| An Efficiency-Boosting Client Selection Scheme for Federated Learning With Fairness Guarantee |             | TPDS :mortar_board:         | 2021 |       | [[PDF](https://arxiv.org/pdf/2011.01783)] [[PUB](https://ieeexplore.ieee.org/document/9272649/).] |
| A Blockchain-Based Federated Forest for SDN-Enabled In-Vehicle Network Intrusion Detection System |             | IEEE Access                 | 2021 |       | [[PUB](https://ieeexplore.ieee.org/document/9471858).]       |
| Research on privacy protection of multi source data based on improved gbdt federated ensemble method with different metrics |             | Phys.  Commun.              | 2021 |       | [[PUB](https://www.sciencedirect.com/science/article/pii/S1874490721000847?via%3Dihub).] |
| Fed-EINI: An Efficient and Interpretable Inference Framework for Decision Tree Ensembles in Vertical Federated Learning |             | IEEE BigData                | 2021 |       | [[PDF](https://arxiv.org/pdf/2105.09540)] [[PUB](https://ieeexplore.ieee.org/document/9671749).] |
| Gradient Boosting Forest: a Two-Stage Ensemble Method Enabling Federated Learning of GBDTs |             | ICONIP                      | 2021 |       | [[PUB](https://link.springer.com/chapter/10.1007/978-3-030-92270-2_7).] |
| A k-Anonymised Federated Learning Framework with Decision Trees |             | DPM/CBT @ESORICS            | 2021 |       | [[PUB](https://link.springer.com/chapter/10.1007/978-3-030-93944-1_7).] |
| AF-DNDF: Asynchronous Federated Learning of Deep Neural Decision Forests |             | SEAA                        | 2021 |       | [[PUB](https://ieeexplore.ieee.org/document/9582575).]       |
| Compression Boosts Differentially Private Federated Learning |             | EuroS&P                     | 2021 |       | [[PDF](https://arxiv.org/pdf/2011.05578)] [[PUB](https://ieeexplore.ieee.org/document/9581200).] |
| Practical Federated Gradient Boosting Decision Trees         |             | AAAI :mortar_board:         | 2020 |       | [[PDF](https://arxiv.org/pdf/1911.04206)] [[PUB](https://ojs.aaai.org/index.php/AAAI/article/view/5895).] [[Code](https://github.com/Xtra-Computing/SimFL)] |
| Boosting Privately: Federated Extreme Gradient Boosting for Mobile Crowdsensing |             | ICDCS                       | 2020 |       | [[PDF](https://arxiv.org/pdf/1907.10218)] [[PUB](https://ieeexplore.ieee.org/document/9355600).] |
| FedCluster: Boosting the Convergence of Federated Learning via Cluster-Cycling |             | IEEE BigData                | 2020 |       | [[PDF](https://arxiv.org/pdf/2009.10748)] [[PUB](https://ieeexplore.ieee.org/document/9377960).] |
| Bandwidth Slicing to Boost Federated Learning Over Passive Optical Networks |             | IEEE Communications Letters | 2020 |       | [[PUB](https://ieeexplore.ieee.org/document/9044640).]       |
| Privacy Preserving Vertical Federated Learning for Tree-based Models |             | Proc. VLDB Endow.           | 2020 |       | [[PDF](https://arxiv.org/pdf/2008.06170)] [[PUB](http://www.vldb.org/pvldb/vol13/p2090-wu.pdf).] [[Video](https://www.youtube.com/watch?v=sjii8oVCqiY)] |
| DFedForest: Decentralized Federated Forest                   |             | Blockchain                  | 2020 |       | [[PUB](https://ieeexplore.ieee.org/document/9284805/).]      |
| Straggler Remission for Federated Learning via Decentralized Redundant Cayley Tree |             | LATINCOM                    | 2020 |       | [[PUB](https://ieeexplore.ieee.org/document/9282334).]       |
| Federated Soft Gradient Boosting Machine for Streaming Data  |             | Federated Learning          | 2020 |       | [[PUB](https://link.springer.com/chapter/10.1007/978-3-030-63076-8_7).] |
| Federated Learning of Deep Neural Decision Forests           |             | LOD                         | 2019 |       | [[PUB](https://link.springer.com/chapter/10.1007/978-3-030-37599-7_58).] |
| Statistical Detection of Adversarial examples in Blockchain-based Federated Forest In-vehicle Network Intrusion Detection Systems |             | preprint                    | 2022 |       | [[PDF](https://arxiv.org/abs/2207.04843)]                    |
| Hercules: Boosting the Performance of Privacy-preserving Federated Learning |             | preprint                    | 2022 |       | [[PDF](https://arxiv.org/abs/2207.04620)]                    |
| FedGBF: An efficient vertical federated learning framework via gradient boosting and bagging |             | preprint                    | 2022 |       | [[PDF](https://arxiv.org/pdf/2204.00976)]                    |
| An Efficient and Robust System for Vertically Federated Random Forest |             | preprint                    | 2022 |       | [[PDF](https://arxiv.org/pdf/2201.10761)]                    |
| Guess what? You can boost Federated Learning for free        |             | preprint                    | 2021 |       | [[PDF](https://arxiv.org/pdf/2110.11486)]                    |
| SecureBoost+ : A High Performance Gradient Boosting Tree Framework for Large Scale Vertical Federated Learning :fire: |             | preprint                    | 2021 |       | [[PDF](https://arxiv.org/pdf/2110.10927)] [[Code](https://github.com/FederatedAI/FATE)] |
| Fed-TGAN: Federated Learning Framework for Synthesizing Tabular Data |             | preprint                    | 2021 |       | [[PDF](https://arxiv.org/pdf/2108.07927)]                    |
| A Tree-based Federated Learning Approach for Personalized Treatment Effect Estimation from Heterogeneous Data Sources |             | preprint                    | 2021 |       | [[PDF](https://arxiv.org/pdf/2103.06261)] [[Code](https://github.com/ellenxtan/ifedtree)] |
| Adaptive Histogram-Based Gradient Boosted Trees for Federated Learning |             | preprint                    | 2020 |       | [[PDF](https://arxiv.org/pdf/2012.06670)]                    |
| FederBoost: Private Federated Learning for GBDT              |             | preprint                    | 2020 |       | [[PDF](https://arxiv.org/pdf/2011.02796)]                    |
| Privacy Preserving Text Recognition with Gradient-Boosting for Federated Learning |             | preprint                    | 2020 |       | [[PDF](https://arxiv.org/pdf/2007.07296)] [[Code](https://github.com/rand2ai/fedboost)] |
| Cloud-based Federated Boosting for Mobile Crowdsensing       |             | preprint                    | 2020 |       | [[arxiv](https://arxiv.org/abs/2005.05304)]                  |
| Federated Extra-Trees with Privacy Preserving                |             | preprint                    | 2020 |       | [[PDF](https://arxiv.org/pdf/2002.07323.pdf)]                |
| Bandwidth Slicing to Boost Federated Learning in Edge Computing |             | preprint                    | 2019 |       | [[PDF](https://arxiv.org/pdf/1911.07615)]                    |
| Revocable Federated Learning: A Benchmark of Federated Forest |             | preprint                    | 2019 |       | [[PDF](https://arxiv.org/pdf/1911.03242)]                    |



## FL in top-tier journal

List of papers in the field of federated learning in Nature(and its sub-journals), Cell, Science(and Science Advances) and PANS refers to [WOS](https://www.webofscience.com/wos/woscc/summary/ed3f4552-5450-4de7-bf2c-55d01e20d5de-4301299e/relevance/1) search engine.

| Title                                                        | Affiliation | Venue                 | Year | TL;DR | Materials                                                    |
| ------------------------------------------------------------ | ----------- | --------------------- | ---- | ----- | ------------------------------------------------------------ |
| Shifting machine learning for healthcare from development to deployment and from models to data |             | Nat. Biomed. Eng      | 2022 |       | [[PUB](https://www.nature.com/articles/s41551-022-00898-y).] |
| Communication-efficient federated learning via knowledge distillation |             | Nat Commun            | 2022 |       | [[PUB](https://www.nature.com/articles/s41467-022-29763-x).] |
| A federated graph neural network framework for privacy-preserving personalization |             | Nat Commun            | 2022 |       | [[PUB](https://www.nature.com/articles/s41467-022-30714-9).] [[Code](https://github.com/wuch15/FedPerGNN)] |
| Swarm Learning for decentralized and confidential clinical machine learning |             | Nature :mortar_board: | 2021 |       | [[PUB](https://www.nature.com/articles/s41586-021-03583-3).] |
| Adversarial interference and its mitigations in privacy-preserving collaborative machine learning |             | Nat. Mach. Intell.    | 2021 |       | [[PUB](https://www.nature.com/articles/s42256-021-00390-3).] |
| End-to-end privacy preserving deep learning on multi-institutional medical imaging |             | Nat. Mach. Intell.    | 2021 |       | [[PUB](https://www.nature.com/articles/s42256-021-00337-8).] |
| Federated learning for predicting clinical outcomes in patients with COVID-19 |             | Nat Med               | 2021 |       | [[PUB](https://www.nature.com/articles/s41591-021-01506-3).] |
| Communication-efficient federated learning                   |             | PANS                  | 2021 |       | [[PUB](https://www.pnas.org/doi/full/10.1073/pnas.2024789118).] [[Code](https://github.com/mzchen0/Communication-Efficient-Federated-Learning)] |
| Advancing COVID-19 diagnosis with privacy-preserving collaboration in artificial intelligence |             | Nat. Mach. Intell.    | 2021 |       | [[PUB](https://www.nature.com/articles/s42256-021-00421-z).] |
| Secure, privacy-preserving and federated machine learning in medical imaging |             | Nat Mach Intell       | 2020 |       | [[PUB](https://www.nature.com/articles/s42256-020-0186-1).]  |
| Breaking medical data sharing boundaries by using synthesized radiographs |             | Science Advances      | 2020 |       | [[PUB](https://www.science.org/doi/10.1126/sciadv.abb7973).] |





## FL in top AI Conferences

In this section, we will summarize Federated Learning papers accepted by top AI(Artificial Intelligence)  conference, Including [IJCAI](https://dblp.org/db/conf/ijcai/index.html)(International Joint Conference on Artificial Intelligence), [AAAI](https://dblp.uni-trier.de/db/conf/aaai/index.html)(AAAI Conference on Artificial Intelligence), [AISTATS](https://dblp.uni-trier.de/db/conf/aistats/index.html)(Artificial Intelligence and Statistics).

- [IJCAI](https://dblp.uni-trier.de/search?q=federate%20venue%3AIJCAI%3A)  2022,[2021](https://ijcai-21.org/program-main-track/#),2020,[2019](https://www.ijcai19.org/accepted-papers.html)
- [AAAI](https://dblp.uni-trier.de/search?q=federate%20venue%3AAAAI%3A) [2022](https://aaai.org/Conferences/AAAI-22/wp-content/uploads/2021/12/AAAI-22_Accepted_Paper_List_Main_Technical_Track.pdf),[2021](https://aaai.org/Conferences/AAAI-21/wp-content/uploads/2020/12/AAAI-21_Accepted-Paper-List.Main_.Technical.Track_.pdf),[2020](https://aaai.org/Conferences/AAAI-20/wp-content/uploads/2020/01/AAAI-20-Accepted-Paper-List.pdf)
- [AISTATS](https://dblp.uni-trier.de/search?q=federate%20venue%3AAISTATS%3A) [2022](http://proceedings.mlr.press/v151/), [2021](http://proceedings.mlr.press/v130/),[2020](http://proceedings.mlr.press/v108/)



| Title                                                        | Affiliation                                                  | Venue   | Year | TL;DR | Materials                                                    |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------- | ---- | ----- | ------------------------------------------------------------ |
| [Towards Understanding Biased Client Selection in Federated Learning.](https://proceedings.mlr.press/v151/jee-cho22a.html) |                                                              | AISTATS | 2022 |       |                                                              |
| [FLIX: A Simple and Communication-Efficient Alternative to Local Methods in Federated Learning](https://proceedings.mlr.press/v151/gasanov22a.html) |                                                              | AISTATS | 2022 |       |                                                              |
| [Sharp Bounds for Federated Averaging (Local SGD) and Continuous Perspective.](https://proceedings.mlr.press/v151/glasgow22a.html) |                                                              | AISTATS | 2022 |       |                                                              |
| [Federated Reinforcement Learning with Environment Heterogeneity.](https://proceedings.mlr.press/v151/jin22a.html) |                                                              | AISTATS | 2022 |       |                                                              |
| [Federated Myopic Community Detection with One-shot Communication](https://proceedings.mlr.press/v151/ke22a.html) |                                                              | AISTATS | 2022 |       |                                                              |
| [Asynchronous Upper Confidence Bound Algorithms for Federated Linear Bandits.](https://proceedings.mlr.press/v151/li22e.html) |                                                              | AISTATS | 2022 |       |                                                              |
| [Towards Federated Bayesian Network Structure Learning with Continuous Optimization.](https://proceedings.mlr.press/v151/ng22a.html) |                                                              | AISTATS | 2022 |       |                                                              |
| [Federated Learning with Buffered Asynchronous Aggregation](https://proceedings.mlr.press/v151/nguyen22b.html) |                                                              | AISTATS | 2022 |       |                                                              |
| [Differentially Private Federated Learning on Heterogeneous Data.](https://proceedings.mlr.press/v151/noble22a.html) |                                                              | AISTATS | 2022 |       |                                                              |
| [SparseFed: Mitigating Model Poisoning Attacks in Federated Learning with Sparsification](https://proceedings.mlr.press/v151/panda22a.html) |                                                              | AISTATS | 2022 |       |                                                              |
| [Basis Matters: Better Communication-Efficient Second Order Methods for Federated Learning](https://proceedings.mlr.press/v151/qian22a.html) |                                                              | AISTATS | 2022 |       |                                                              |
| [Federated Functional Gradient Boosting.](https://proceedings.mlr.press/v151/shen22a.html) |                                                              | AISTATS | 2022 |       |                                                              |
| [QLSD: Quantised Langevin Stochastic Dynamics for Bayesian Federated Learning.](https://proceedings.mlr.press/v151/vono22a.html) |                                                              | AISTATS | 2022 |       |                                                              |
| Meta-Learning Based Knowledge Extrapolation for Knowledge Graphs in the Federated Setting  **`kg.`** |                                                              | IJCAI   | 2022 |       | [[PDF]](https://doi.org/10.48550/arXiv.2205.04692) [[Code](https://github.com/zjukg/maker)] |
| Personalized Federated Learning With a Graph                 |                                                              | IJCAI   | 2022 |       | [[PUB](https://www.ijcai.org/proceedings/2022/357).] [[PDF](https://arxiv.org/abs/2203.00829)] [[Code](https://github.com/dawenzi098/SFL-Structural-Federated-Learning)] |
| Vertically Federated Graph Neural Network for Privacy-Preserving Node Classification |                                                              | IJCAI   | 2022 |       | [[PUB](https://www.ijcai.org/proceedings/2022/272).] [[PDF](https://arxiv.org/abs/2005.11903)] |
| [Adapt to Adaptation: Learning Personalization for Cross-Silo Federated Learning](https://www.ijcai.org/proceedings/2022/301) |                                                              | IJCAI   | 2022 |       | [Code](https://github.com/ljaiverson/pFL-APPLE)              |
| [Heterogeneous Ensemble Knowledge Transfer for Training Large Models in Federated Learning](https://www.ijcai.org/proceedings/2022/399) |                                                              | IJCAI   | 2022 |       |                                                              |
| [Private Semi-Supervised Federated Learning.](https://www.ijcai.org/proceedings/2022/279) |                                                              | IJCAI   | 2022 |       |                                                              |
| [Continual Federated Learning Based on Knowledge Distillation.](https://doi.org/10.24963/ijcai.2022/306) |                                                              | IJCAI   | 2022 |       |                                                              |
| [Federated Learning on Heterogeneous and Long-Tailed Data via Classifier Re-Training with Federated Features](https://www.ijcai.org/proceedings/2022/308) |                                                              | IJCAI   | 2022 |       | [Code](https://github.com/shangxinyi/CReFF-FL)               |
| [Federated Multi-Task Attention for Cross-Individual Human Activity Recognition](https://www.ijcai.org/proceedings/2022/475) |                                                              | IJCAI   | 2022 |       |                                                              |
| [Personalized Federated Learning with Contextualized Generalization.](https://www.ijcai.org/proceedings/2022/311) |                                                              | IJCAI   | 2022 |       |                                                              |
| [Shielding Federated Learning: Robust Aggregation with Adaptive Client Selection](https://www.ijcai.org/proceedings/2022/106). |                                                              | IJCAI   | 2022 |       |                                                              |
| [FedCG: Leverage Conditional GAN for Protecting Privacy and Maintaining Competitive Performance in Federated Learning](https://www.ijcai.org/proceedings/2022/324) |                                                              | IJCAI   | 2022 |       |                                                              |
| [FedDUAP: Federated Learning with Dynamic Update and Adaptive Pruning Using Shared Data on the Server.](https://www.ijcai.org/proceedings/2022/385) |                                                              | IJCAI   | 2022 |       |                                                              |
| [Towards Verifiable Federated Learning](https://www.ijcai.org/proceedings/2022/792)  **`surv.`** |                                                              | IJCAI   | 2022 |       |                                                              |
| [HarmoFL: Harmonizing Local and Global Drifts in Federated Learning on Heterogeneous Medical Images](https://arxiv.org/pdf/2112.10775.pdf) | The Chinese University of Hong Kong; Beihang University      | AAAI    | 2022 |       | [[Code]](https://github.com/med-air/HarmoFL)                 |
| [Federated Learning for Face Recognition with Gradient Correction](https://arxiv.org/pdf/2112.07246.pdf) | Beijing University of Posts and Telecommunications           | AAAI    | 2022 |       |                                                              |
| [SpreadGNN: Decentralized Multi-Task Federated Learning for Graph Neural Networks on Molecular Data](https://arxiv.org/pdf/2106.02743.pdf) | university of Southern California                            | AAAI    | 2022 |       | [[Code]](https://github.com/FedML-AI/SpreadGNN)              |
| [SmartIdx: Reducing Communication Cost in Federated Learning by Exploiting the CNNs Structures](https://ojs.aaai.org/index.php/AAAI/article/view/20345) | Harbin Institute of Technology; Peng Cheng Laboratory        | AAAI    | 2022 |       |                                                              |
| [Bridging between Cognitive Processing Signals and Linguistic Features via a Unified Attentional Network](https://arxiv.org/pdf/2112.08831.pdf) | Tianjin University                                           | AAAI    | 2022 |       |                                                              |
| [Seizing Critical Learning Periods in Federated Learning](https://arxiv.org/pdf/2109.05613.pdf) | SUNY-Binghamton University; Louisiana State University       | AAAI    | 2022 |       |                                                              |
| [Coordinating Momenta for Cross-silo Federated Learning](https://arxiv.org/pdf/2102.03970.pdf) | University of Pittsburgh                                     | AAAI    | 2022 |       |                                                              |
| [FedProto: Federated Prototype Learning over Heterogeneous Devices](https://arxiv.org/pdf/2105.00243.pdf) | University of Technology Sydney; University of Washington    | AAAI    | 2022 |       | [[Code]](https://github.com/yuetan031/fedproto)              |
| [FedSoft: Soft Clustered Federated Learning with Proximal Local Updating](https://arxiv.org/pdf/2112.06053.pdf) | Carnegie Mellon University                                   | AAAI    | 2022 |       |                                                              |
| [Federated Dynamic Sparse Training: Computing Less, Communicating Less, Yet Learning Better](https://arxiv.org/pdf/2112.09824.pdf) | The University of Texas at Austin                            | AAAI    | 2022 |       | [[Code]](https://github.com/bibikar/feddst)                  |
| [FedFR: Joint Optimization Federated Framework for Generic and Personalized Face Recognition](https://arxiv.org/pdf/2112.12496.pdf) | National Taiwan University                                   | AAAI    | 2022 |       | [[Code]](https://github.com/jackie840129/fedfr)              |
| [SplitFed: When Federated Learning Meets Split Learning](https://arxiv.org/pdf/2004.12088.pdf) | CSIRO; Lehigh University                                     | AAAI    | 2022 |       | [[Code]](https://github.com/chandra2thapa/SplitFed-When-Federated-Learning-Meets-Split-Learning) |
| [Efficient Device Scheduling with Multi-Job Federated Learning](https://arxiv.org/pdf/2112.05928.pdf) | Soochow University; Baidu                                    | AAAI    | 2022 |       |                                                              |
| [Implicit Gradient Alignment in Distributed and Federated Learning](https://arxiv.org/pdf/2106.13897.pdf) | IIT Kanpur; EPFL                                             | AAAI    | 2022 |       |                                                              |
| [Federated Nearest Neighbor Classification with a Colony of Fruit-Flies](https://arxiv.org/pdf/2112.07157.pdf) | IBM Research; Wichita State University                       | AAAI    | 2022 |       |                                                              |
| [Federated Learning with Sparsification-Amplified Privacy and Adaptive Optimization](https://www.ijcai.org/proceedings/2021/202) |                                                              | IJCAI   | 2021 |       |                                                              |
| [Behavior Mimics Distribution: Combining Individual and Group Behaviors for Federated Learning](https://www.ijcai.org/proceedings/2021/352) |                                                              | IJCAI   | 2021 |       |                                                              |
| [FedSpeech: Federated Text-to-Speech with Continual Learning](https://www.ijcai.org/proceedings/2021/527) |                                                              | IJCAI   | 2021 |       |                                                              |
| [Practical One-Shot Federated Learning for Cross-Silo Setting](https://www.ijcai.org/proceedings/2021/205) |                                                              | IJCAI   | 2021 |       |                                                              |
| [Federated Model Distillation with Noise-Free Differential Privacy](https://www.ijcai.org/proceedings/2021/216) |                                                              | IJCAI   | 2021 |       |                                                              |
| [LDP-FL: Practical Private Aggregation in Federated Learning with Local Differential Privacy](https://www.ijcai.org/proceedings/2021/217) |                                                              | IJCAI   | 2021 |       |                                                              |
| [Federated Learning with Fair Averaging.](https://www.ijcai.org/proceedings/2021/223) |                                                              | IJCAI   | 2021 |       |                                                              |
| [H-FL: A Hierarchical Communication-Efficient and Privacy-Protected Architecture for Federated Learning.](https://www.ijcai.org/proceedings/2021/67) |                                                              | IJCAI   | 2021 |       |                                                              |
| [Communication-efficient and Scalable Decentralized Federated Edge Learning.](https://www.ijcai.org/proceedings/2021/720) |                                                              | IJCAI   | 2021 |       |                                                              |
| [Secure Bilevel Asynchronous Vertical Federated Learning with Backward Updating](https://arxiv.org/pdf/2103.00958.pdf) | Xidian University; JD Tech                                   | AAAI    | 2021 |       | [video](https://slideslive.com/38947765/secure-bilevel-asynchronous-vertical-federated-learning-with-backward-updating) |
| [FedRec++: Lossless Federated Recommendation with Explicit Feedback](https://ojs.aaai.org/index.php/AAAI/article/view/16546) | Shenzhen University                                          | AAAI    | 2021 |       | [video](https://slideslive.com/38947798/fedrec-lossless-federated-recommendation-with-explicit-feedback) |
| [Federated Multi-Armed Bandits](https://arxiv.org/pdf/2101.12204.pdf) | University of Virginia                                       | AAAI    | 2021 |       | [[Code]](https://github.com/ShenGroup/FMAB) [video](https://slideslive.com/38947985/federated-multiarmed-bandits) |
| [On the Convergence of Communication-Efficient Local SGD for Federated Learning](https://ojs.aaai.org/index.php/AAAI/article/view/16920) | Temple University; University of Pittsburgh                  | AAAI    | 2021 |       | [video](https://slideslive.com/38948341/on-the-convergence-of-communicationefficient-local-sgd-for-federated-learning) |
| [FLAME: Differentially Private Federated Learning in the Shuffle Model](https://arxiv.org/pdf/2009.08063.pdf) | Renmin University of China; Kyoto University                 | AAAI    | 2021 |       | [video](https://slideslive.com/38948496/flame-differentially-private-federated-learning-in-the-shuffle-model) [[Code]](https://github.com/Rachelxuan11/FLAME) |
| [Toward Understanding the Influence of Individual Clients in Federated Learning](https://arxiv.org/pdf/2012.10936.pdf) | Shanghai Jiao Tong University; The University of Texas at Dallas | AAAI    | 2021 |       | [video](https://slideslive.com/38948549/toward-understanding-the-influence-of-individual-clients-in-federated-learning) |
| [Provably Secure Federated Learning against Malicious Clients](https://arxiv.org/pdf/2102.01854.pdf) | Duke University                                              | AAAI    | 2021 |       | [video](https://www.youtube.com/watch?v=LP4uqW18yA0&ab_channel=PurdueCERIAS) [slides](https://people.duke.edu/~zg70/code/Secure_Federated_Learning.pdf) |
| [Personalized Cross-Silo Federated Learning on Non-IID Data](https://arxiv.org/pdf/2007.03797.pdf) | Simon Fraser University; McMaster University                 | AAAI    | 2021 |       | [video](https://slideslive.com/38948676/personalized-crosssilo-federated-learning-on-noniid-data) |
| [Model-Sharing Games: Analyzing Federated Learning under Voluntary Participation](https://arxiv.org/pdf/2010.00753.pdf) | Cornell University                                           | AAAI    | 2021 |       | [[Code]](https://github.com/kpdonahue/model_sharing_games) [video](https://slideslive.com/38948684/modelsharing-games-analyzing-federated-learning-under-voluntary-participation) |
| [Curse or Redemption? How Data Heterogeneity Affects the Robustness of Federated Learning](https://arxiv.org/pdf/2102.00655.pdf) | University of Nevada; IBM Research                           | AAAI    | 2021 |       | [video](https://slideslive.com/38949098/curse-or-redemption-how-data-heterogeneity-affects-the-robustness-of-federated-learning) |
| [Game of Gradients: Mitigating Irrelevant Clients in Federated Learning](https://ojs.aaai.org/index.php/AAAI/article/view/17093) | IIT Bombay; IBM Research                                     | AAAI    | 2021 |       | [video](https://slideslive.com/38949109/game-of-gradients-mitigating-irrelevant-clients-in-federated-learning) [Supplementary](https://github.com/nlokeshiisc/SFedAvg-AAAI21) |
| [Federated Block Coordinate Descent Scheme for Learning Global and Personalized Models](https://arxiv.org/pdf/2012.13900.pdf) | The Chinese University of Hong Kong; Arizona State University | AAAI    | 2021 |       | [video](https://slideslive.com/38949195/federated-block-coordinate-descent-scheme-for-learning-global-and-personalized-models) [[Code]](https://github.com/REIYANG/FedBCD) |
| [Addressing Class Imbalance in Federated Learning](https://arxiv.org/pdf/2008.06217.pdf) | Northwestern University                                      | AAAI    | 2021 |       | [video](https://slideslive.com/38949283/adressing-class-imbalance-in-federated-learning) [[Code]](https://github.com/balanced-fl/Addressing-Class-Imbalance-FL) [[[Interpret(zh)]](https://zhuanlan.zhihu.com/p/443009189)] |
| [Defending against Backdoors in Federated Learning with Robust Learning Rate](https://arxiv.org/pdf/2007.03767.pdf) | The University of Texas at Dallas                            | AAAI    | 2021 |       | [video](https://slideslive.com/38949344/defending-against-backdoors-in-federated-learning-with-robust-learning-rate) [[Code]](https://github.com/TinfoilHat0/Defending-Against-Backdoors-with-Robust-Learning-Rate) |
| [Free-rider Attacks on Model Aggregation in Federated Learning](http://proceedings.mlr.press/v130/fraboni21a/fraboni21a.pdf) | Accenture Labs                                               | AISTAT  | 2021 |       | [video](https://papertalk.org/papertalks/27640) [Supplementary](http://proceedings.mlr.press/v130/fraboni21a/fraboni21a-supp.pdf) |
| [Federated f-differential privacy](http://proceedings.mlr.press/v130/zheng21a/zheng21a.pdf) | University of Pennsylvania                                   | AISTAT  | 2021 |       | [[Code]](https://github.com/enosair/federated-fdp) [video](https://papertalk.org/papertalks/27595) [Supplementary](http://proceedings.mlr.press/v130/zheng21a/zheng21a-supp.pdf) |
| [Federated learning with compression: Unified analysis and sharp guarantees](http://proceedings.mlr.press/v130/haddadpour21a/haddadpour21a.pdf) :fire: | The Pennsylvania State University; The University of Texas at Austin | AISTAT  | 2021 |       | [[Code]](https://github.com/MLOPTPSU/FedTorch) [video](https://papertalk.org/papertalks/27584) [Supplementary](http://proceedings.mlr.press/v130/haddadpour21a/haddadpour21a-supp.pdf) |
| [Shuffled Model of Differential Privacy in Federated Learning](http://proceedings.mlr.press/v130/girgis21a/girgis21a.pdf) | UCLA; Google                                                 | AISTAT  | 2021 |       | [video](https://papertalk.org/papertalks/27565) [Supplementary](http://proceedings.mlr.press/v130/girgis21a/girgis21a-supp.pdf) |
| [Convergence and Accuracy Trade-Offs in Federated Learning and Meta-Learning](http://proceedings.mlr.press/v130/charles21a/charles21a.pdf) | Google                                                       | AISTAT  | 2021 |       | [video](https://papertalk.org/papertalks/27559) [Supplementary](http://proceedings.mlr.press/v130/charles21a/charles21a-supp.pdf) |
| [Federated Multi-armed Bandits with Personalization](http://proceedings.mlr.press/v130/shi21c/shi21c.pdf) | University of Virginia; The Pennsylvania State University    | AISTAT  | 2021 |       | [[Code]](https://github.com/ShenGroup/PF_MAB) [video](https://papertalk.org/papertalks/27521) [Supplementary](http://proceedings.mlr.press/v130/shi21c/shi21c-supp.pdf) |
| [Towards Flexible Device Participation in Federated Learning](http://proceedings.mlr.press/v130/ruan21a/ruan21a.pdf) | CMU;  Sun Yat-Sen University                                 | AISTAT  | 2021 |       | [video](https://papertalk.org/papertalks/27467) [Supplementary](http://proceedings.mlr.press/v130/ruan21a/ruan21a-supp.pdf) |
| [Federated Meta-Learning for Fraudulent Credit Card Detection](https://www.ijcai.org/proceedings/2020/642) |                                                              | IJCAI   | 2020 |       | [Video](https://www.ijcai.org/proceedings/2020/video/23994)  |
| [A Multi-player Game for Studying Federated Learning Incentive Schemes](https://www.ijcai.org/proceedings/2020/769) |                                                              | IJCAI   | 2020 |       |                                                              |
| [Practical Federated Gradient Boosting Decision Trees](https://arxiv.org/pdf/1911.04206.pdf) | National University of Singapore;  The University of Western Australia | AAAI    | 2020 |       | [[Code]](https://github.com/Xtra-Computing/PrivML)           |
| [Federated Learning for Vision-and-Language Grounding Problems](https://ojs.aaai.org/index.php/AAAI/article/view/6824) | Peking University; Tencent                                   | AAAI    | 2020 |       |                                                              |
| [Federated Latent Dirichlet Allocation: A Local Differential Privacy Based Framework](https://ojs.aaai.org/index.php/AAAI/article/view/6096) | Beihang University                                           | AAAI    | 2020 |       |                                                              |
| [Federated Patient Hashing](https://ojs.aaai.org/index.php/AAAI/article/view/6121) | Cornell University                                           | AAAI    | 2020 |       |                                                              |
| [Robust Federated Learning via Collaborative Machine Teaching](https://arxiv.org/pdf/1905.02941.pdf) | Symantec Research Labs; KAUST                                | AAAI    | 2020 |       |                                                              |
| [FedPAQ: A Communication-Efficient Federated Learning Method with Periodic Averaging and Quantization](http://proceedings.mlr.press/v108/reisizadeh20a/reisizadeh20a.pdf) | UC Santa Barbara;  UT Austin                                 | AISTAT  | 2020 |       | [video](https://papertalk.org/papertalks/7961) [Supplementary](http://proceedings.mlr.press/v108/reisizadeh20a/reisizadeh20a-supp.pdf) |
| [How To Backdoor Federated Learning](http://proceedings.mlr.press/v108/bagdasaryan20a/bagdasaryan20a.pdf) :fire: | Cornell Tech                                                 | AISTAT  | 2020 |       | [video](https://papertalk.org/papertalks/8046) [[Code]](https://github.com/ebagdasa/backdoor_federated_learning) [Supplementary](http://proceedings.mlr.press/v108/bagdasaryan20a/bagdasaryan20a-supp.pdf) |
| [Federated Heavy Hitters Discovery with Differential Privacy](http://proceedings.mlr.press/v108/zhu20a/zhu20a.pdf) | RPI; Google                                                  | AISTAT  | 2020 |       | [video](https://papertalk.org/papertalks/8129) [Supplementary](http://proceedings.mlr.press/v108/zhu20a/zhu20a-supp.pdf) |
| [Multi-Agent Visualization for Explaining Federated Learning](https://www.ijcai.org/proceedings/2019/960) | WeBank                                                       | IJCAI   | 2019 |       | [Video](https://youtu.be/NPGf_OJrzOg)                        |





## FL in top ML conferences

In this section, we will summarize Federated Learning papers accepted by top ML(machine learning) conference, Including [NeurIPS](https://dblp.uni-trier.de/db/conf/nips/index.html)(Annual Conference on Neural Information Processing Systems), [ICML](https://dblp.uni-trier.de/db/conf/icml/index.html)(International Conference on Machine Learning), [ICLR](https://dblp.uni-trier.de/db/conf/iclr/index.html)(International Conference on Learning Representations), [COLT](https://dblp.org/db/conf/colt/index.html)(Annual Conference Computational Learning Theory) and [UAI](https://dblp.org/db/conf/uai/index.html)(Conference on Uncertainty in Artificial Intelligence).

- [NeurIPS](https://dblp.uni-trier.de/search?q=federate%20venue%3ANeurIPS%3A) [2021](https://papers.nips.cc/paper/2021), [2020](https://papers.nips.cc/paper/2020), [2018](https://papers.nips.cc/paper/2018), [2017](https://papers.nips.cc/paper/2017)
- [ICML](https://dblp.uni-trier.de/search?q=federate%20venue%3AICML%3A) [2022](https://icml.cc/Conferences/2022/Schedule?type=Poster), [2021](https://icml.cc/Conferences/2021/Schedule?type=Poster), [2020](https://icml.cc/Conferences/2020/Schedule?type=Poster), [2019](https://icml.cc/Conferences/2019/Schedule?type=Poster)
- [ICLR](https://dblp.uni-trier.de/search?q=federate%20venue%3AICLR%3A) [2022](https://openreview.net/group?id=ICLR.cc/2022/Conference),[2021](https://openreview.net/group?id=ICLR.cc/2021/Conference), [2020](https://openreview.net/group?id=ICLR.cc/2020/Conference)
- [COLT](https://dblp.org/search?q=federated%20venue%3ACOLT%3A) NULL
- [UAI](https://dblp.org/search?q=federated%20venue%3AUAI%3A) 2021



| Title                                                        | Affiliation                                                  | Venue          | Year | TL;DR | Materials                                                    |
| ------------------------------------------------------------ | ------------------------------------------------------------ | -------------- | ---- | ----- | ------------------------------------------------------------ |
| [Fast Composite Optimization and Statistical Recovery in Federated Learning](https://proceedings.mlr.press/v162/bao22b.html) | Shanghai Jiao Tong University                                | ICML           | 2022 |       |                                                              |
| [Personalization Improves Privacy-Accuracy Tradeoffs in Federated Learning](https://proceedings.mlr.press/v162/bietti22a.html) | New York University                                          | ICML           | 2022 |       |                                                              |
| [The Fundamental Price of Secure Aggregation in Differentially Private Federated Learning](https://proceedings.mlr.press/v162/chen22c.html) :fire: | Stanford University;  Google Research                        | ICML           | 2022 |       | [code](https://github.com/google-research/federated/tree/master/private_linear_compression) [slides](https://icml.cc/media/icml-2022/Slides/17529.pdf) |
| [The Poisson Binomial Mechanism for Unbiased Federated Learning with Secure Aggregation](https://proceedings.mlr.press/v162/chen22s.html) | Stanford University;  Google Research                        | ICML           | 2022 |       |                                                              |
| [DisPFL: Towards Communication-Efficient Personalized Federated Learning via Decentralized Sparse Training](https://proceedings.mlr.press/v162/dai22b.html) | University of Science and Technology of China                | ICML           | 2022 |       | [code](https://github.com/rong-dai/DisPFL)                   |
| [FedNew: A Communication-Efficient and Privacy-Preserving Newton-Type Method for Federated Learning](https://proceedings.mlr.press/v162/elgabli22a.html) | University of Oulu                                           | ICML           | 2022 |       | [code](https://github.com/aelgabli/FedNew)                   |
| [DAdaQuant: Doubly-adaptive quantization for communication-efficient Federated Learning](https://proceedings.mlr.press/v162/honig22a.html) | University of Cambridge                                      | ICML           | 2022 |       | [slides](https://icml.cc/media/icml-2022/Slides/16009.pdf)   |
| [Accelerated Federated Learning with Decoupled Adaptive Optimization](https://proceedings.mlr.press/v162/jin22e.html) | Auburn University                                            | ICML           | 2022 |       |                                                              |
| [Federated Reinforcement Learning: Linear Speedup Under Markovian Sampling](https://proceedings.mlr.press/v162/khodadadian22a.html) | Geogia Institute of Technology                               | ICML           | 2022 |       |                                                              |
| [Multi-Level Branched Regularization for Federated Learning](https://proceedings.mlr.press/v162/kim22a.html) | Seoul National University                                    | ICML           | 2022 |       | [HomePage](http://cvlab.snu.ac.kr/research/FedMLB/)          |
| [FedScale: Benchmarking Model and System Performance of Federated Learning at Scale](https://proceedings.mlr.press/v162/lai22a.html) :fire: | University of Michigan                                       | ICML           | 2022 |       | [code](https://github.com/SymbioticLab/FedScale)             |
| [Federated Learning with Positive and Unlabeled Data](https://proceedings.mlr.press/v162/lin22b.html) | Xi’an Jiaotong University                                    | ICML           | 2022 |       |                                                              |
| [Deep Neural Network Fusion via Graph Matching with Applications to Model Ensemble and Federated Learning](https://proceedings.mlr.press/v162/liu22k.html) | Shanghai Jiao Tong University                                | ICML           | 2022 |       | [code](https://github.com/Thinklab-SJTU/GAMF)                |
| [Orchestra: Unsupervised Federated Learning via Globally Consistent Clustering](https://proceedings.mlr.press/v162/lubana22a.html) | University of Michigan                                       | ICML           | 2022 |       | [code](https://github.com/akhilmathurs/orchestra)            |
| [Disentangled Federated Learning for Tackling Attributes Skew via Invariant Aggregation and Diversity Transferring](https://proceedings.mlr.press/v162/luo22b.html) | University of Science and Technology of China                | ICML           | 2022 |       | [slides](https://icml.cc/media/icml-2022/Slides/16881.pdf)   |
| [Architecture Agnostic Federated Learning for Neural Networks](https://proceedings.mlr.press/v162/makhija22a.html) | The University of Texas at Austin                            | ICML           | 2022 |       |                                                              |
| [Personalized Federated Learning through Local Memorization](https://proceedings.mlr.press/v162/marfoq22a.html) | Inria                                                        | ICML           | 2022 |       | [code](https://github.com/omarfoq/knn-per)                   |
| [Proximal and Federated Random Reshuffling](https://proceedings.mlr.press/v162/mishchenko22a.html) | KAUST                                                        | ICML           | 2022 |       | [code](https://github.com/konstmish/rr_prox_fed)             |
| [Federated Learning with Partial Model Personalization](https://proceedings.mlr.press/v162/pillutla22a.html) | University of Washington                                     | ICML           | 2022 |       | [code](https://github.com/krishnap25/FL_partial_personalization) |
| [Generalized Federated Learning via Sharpness Aware Minimization](https://proceedings.mlr.press/v162/qu22a.html) | University of South Florida                                  | ICML           | 2022 |       |                                                              |
| [FedNL: Making Newton-Type Methods Applicable to Federated Learning](https://proceedings.mlr.press/v162/safaryan22a.html) | KAUST                                                        | ICML           | 2022 |       | [video](https://www.youtube.com/watch?v=_VYCEWT17R0&ab_channel=FederatedLearningOneWorldSeminar) |
| [Federated Minimax Optimization: Improved Convergence Analyses and Algorithms](https://proceedings.mlr.press/v162/sharma22c.html) | Carnegie Mellon University                                   | ICML           | 2022 |       | [slides](https://icml.cc/media/icml-2022/Slides/17435.pdf)   |
| [Virtual Homogeneity Learning: Defending against Data Heterogeneity in Federated Learning](https://proceedings.mlr.press/v162/tang22d.html) | Hong Kong Baptist University                                 | ICML           | 2022 |       | [code](https://github.com/wizard1203/VHL)                    |
| [FedNest: Federated Bilevel, Minimax, and Compositional Optimization](https://proceedings.mlr.press/v162/tarzanagh22a.html) | University of Michigan                                       | ICML           | 2022 |       | [code](https://github.com/mc-nya/FedNest)                    |
| [EDEN: Communication-Efficient and Robust Distributed Mean Estimation for Federated Learning](https://proceedings.mlr.press/v162/vargaftik22a.html) | VMware Research                                              | ICML           | 2022 |       | [code](https://github.com/amitport/EDEN-Distributed-Mean-Estimation) |
| [Communication-Efficient Adaptive Federated Learning](https://proceedings.mlr.press/v162/wang22o.html) | Pennsylvania State University                                | ICML           | 2022 |       |                                                              |
| [ProgFed: Effective, Communication, and Computation Efficient Federated Learning by Progressive Training](https://proceedings.mlr.press/v162/wang22y.html) | CISPA Helmholz Center for Information Security               | ICML           | 2022 |       | [code](https://github.com/a514514772/ProgFed)                |
| [Fishing for User Data in Large-Batch Federated Learning via Gradient Magnification](https://proceedings.mlr.press/v162/wen22a.html) :fire: | University of Maryland                                       | ICML           | 2022 |       | [code](https://github.com/JonasGeiping/breaching)            |
| [Anarchic Federated Learning](https://proceedings.mlr.press/v162/yang22r.html) | The Ohio State University                                    | ICML           | 2022 |       |                                                              |
| [QSFL: A Two-Level Uplink Communication Optimization Framework for Federated Learning](https://proceedings.mlr.press/v162/yi22a.html) | Nankai University                                            | ICML           | 2022 |       | [code](https://github.com/LipingYi/QSFL)                     |
| [Bitwidth Heterogeneous Federated Learning with Progressive Weight Dequantization](https://proceedings.mlr.press/v162/yoon22a.html) | KAIST                                                        | ICML           | 2022 |       |                                                              |
| [Neural Tangent Kernel Empowered Federated Learning](https://proceedings.mlr.press/v162/yue22a.html) | NC State University                                          | ICML           | 2022 |       | [code](https://github.com/KAI-YUE/ntk-fed)                   |
| [Understanding Clipping for Federated Learning: Convergence and Client-Level Differential Privacy](https://proceedings.mlr.press/v162/zhang22b.html) | University of Minnesota                                      | ICML           | 2022 |       |                                                              |
| [Personalized Federated Learning via Variational Bayesian Inference](https://proceedings.mlr.press/v162/zhang22o.html) | Chinese Academy of Sciences                                  | ICML           | 2022 |       |                                                              |
| [Federated Learning with Label Distribution Skew via Logits Calibration](https://proceedings.mlr.press/v162/zhang22p.html) | Zhejiang University                                          | ICML           | 2022 |       |                                                              |
| [Neurotoxin: Durable Backdoors in Federated Learning](https://proceedings.mlr.press/v162/zhang22w.html) | Southeast University;Princeton University                    | ICML           | 2022 |       | [code](https://github.com/jhcknzzm/Federated-Learning-Backdoor/) |
| [Resilient and Communication Efficient Learning for Heterogeneous Federated Systems](https://proceedings.mlr.press/v162/zhu22e.html) | Michigan State University                                    | ICML           | 2022 |       |                                                              |
| [Bayesian Framework for Gradient Leakage](https://arxiv.org/pdf/2111.04706.pdf) | ETH Zurich                                                   | ICLR           | 2022 |       | [[Code]](https://github.com/eth-sri/bayes-framework-leakage) |
| [Federated Learning from only unlabeled data with class-conditional-sharing clients](https://openreview.net/pdf?id=WHA8009laxu) | The University of Tokyo; The Chinese University of Hong Kong | ICLR           | 2022 |       | [[Code]](https://github.com/lunanbit/FedUL)                  |
| [FedChain: Chained Algorithms for Near-Optimal Communication Cost in Federated Learning](https://arxiv.org/pdf/2108.06869.pdf) | Carnegie Mellon University; University of Illinois at Urbana-Champaign; University of Washington | ICLR           | 2022 |       |                                                              |
| [Acceleration of Federated Learning with Alleviated Forgetting in Local Training](https://openreview.net/pdf?id=541PxiEKN3F) | Tsinghua University                                          | ICLR           | 2022 |       | [[Code]](https://github.com/Zoesgithub/FedReg)               |
| [FedPara: Low-rank Hadamard Product for Communication-Efficient Federated Learning](https://arxiv.org/pdf/2108.06098.pdf) | POSTECH                                                      | ICLR           | 2022 |       | [[Code]](https://github.com/South-hw/FedPara_ICLR22)         |
| [An Agnostic Approach to Federated Learning with Class Imbalance](https://openreview.net/pdf?id=Xo0lbDt975) | University of Pennsylvania                                   | ICLR           | 2022 |       | [[Code]](https://github.com/shenzebang/Federated-Learning-Pytorch) |
| [Efficient Split-Mix Federated Learning for On-Demand and In-Situ Customization](https://openreview.net/pdf?id=_QLmakITKg) | Michigan State University; The University of Texas at Austin | ICLR           | 2022 |       | [[Code]](https://github.com/illidanlab/SplitMix)             |
| [Robbing the Fed: Directly Obtaining Private Data in Federated Learning with Modified Models](https://openreview.net/pdf?id=fwzUgo0FM9v) :fire: | University of Maryland; New York University                  | ICLR           | 2022 |       | [[Code] (Minimum)](https://github.com/lhfowl/robbing_the_fed) [[Code] (Comprehensive)](https://github.com/JonasGeiping/breaching) |
| [ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity](https://openreview.net/pdf?id=2sDQwC_hmnM) | University of Cambridge; University of Oxford                | ICLR           | 2022 |       |                                                              |
| [Diverse Client Selection for Federated Learning via Submodular Maximization](https://openreview.net/pdf?id=nwKXyFvaUm) | Intel; Carnegie Mellon University                            | ICLR           | 2022 |       | [[Code]](https://github.com/melodi-lab/divfl)                |
| [Recycling Model Updates in Federated Learning: Are Gradient Subspaces Low-Rank? ](https://arxiv.org/pdf/2202.00280.pdf) | Purdue University                                            | ICLR           | 2022 |       | [[Code]](https://github.com/shams-sam/FedOptim)              |
| [Diurnal or Nocturnal? Federated Learning of Multi-branch Networks from Periodically Shifting Distributions ](https://openreview.net/pdf?id=E4EE_ohFGz) :fire: | University of Maryland; Google                               | ICLR           | 2022 |       | [[Code]](https://github.com/google-research/federated/tree/7525c36324cb022bc05c3fce88ef01147cae9740/periodic_distribution_shift) |
| [Towards Model Agnostic Federated Learning Using Knowledge Distillation](https://arxiv.org/pdf/2110.15210.pdf) | EPFL                                                         | ICLR           | 2022 |       |                                                              |
| [Divergence-aware Federated Self-Supervised Learning](https://openreview.net/pdf?id=oVE1z8NlNe) | Nanyang Technological University; SenseTime                  | ICLR           | 2022 |       |                                                              |
| [What Do We Mean by Generalization in Federated Learning? ](https://arxiv.org/pdf/2110.14216.pdf) :fire: | Stanford University; Google                                  | ICLR           | 2022 |       | [[Code]](https://github.com/google-research/federated/tree/master/generalization) |
| [FedBABU: Toward Enhanced Representation for Federated Image Classification ](https://arxiv.org/pdf/2106.06042.pdf) | KAIST                                                        | ICLR           | 2022 |       | [[Code]](https://github.com/jhoon-oh/FedBABU)                |
| [Byzantine-Robust Learning on Heterogeneous Datasets via Bucketing ](https://arxiv.org/pdf/2006.09365.pdf) | EPFL                                                         | ICLR           | 2022 |       | [[Code]](https://github.com/liehe/byzantine-robust-noniid-optimizer) |
| [Improving Federated Learning Face Recognition via Privacy-Agnostic Clusters](https://arxiv.org/pdf/2201.12467.pdf) | Aibee                                                        | ICLR Spotlight | 2022 |       | [Homepage](https://irvingmeng.github.io/projects/privacyface/) |
| [Hybrid Local SGD for Federated Learning with Heterogeneous Communications ](https://openreview.net/pdf?id=H0oaWl6THa) | University of Texas; 	Pennsylvania State University       | ICLR           | 2022 |       |                                                              |
| [On Bridging Generic and Personalized Federated Learning for Image Classification ](https://arxiv.org/pdf/2107.00778.pdf) | The Ohio State University                                    | ICLR           | 2022 |       | [[Code]](https://github.com/hongyouc/Fed-RoD)                |
| [Minibatch vs Local SGD with Shuffling: Tight Convergence Bounds and Beyond](https://arxiv.org/pdf/2110.10342.pdf) | KAIST; MIT                                                   | ICLR           | 2022 |       |                                                              |
| [Constrained differentially private federated learning for low-bandwidth devices](https://proceedings.mlr.press/v161/kerkouche21a.html) |                                                              | UAI            | 2021 |       |                                                              |
| [Federated stochastic gradient Langevin dynamics](https://proceedings.mlr.press/v161/mekkaoui21a.html) |                                                              | UAI            | 2021 |       |                                                              |
| [Federated Learning Based on Dynamic Regularization](https://openreview.net/pdf?id=B7v4QMR6Z9w) | Boston University; ARM                                       | ICLR           | 2021 |       |                                                              |
| [Achieving Linear Speedup with Partial Worker Participation in Non-IID Federated Learning](https://openreview.net/pdf?id=jDdzh5ul-d) | The Ohio State University                                    | ICLR           | 2021 |       |                                                              |
| [HeteroFL: Computation and Communication Efficient Federated Learning for Heterogeneous Clients](https://arxiv.org/pdf/2010.01264.pdf) | Duke University                                              | ICLR           | 2021 |       | [[Code]](https://github.com/dem123456789/HeteroFL-Computation-and-Communication-Efficient-Federated-Learning-for-Heterogeneous-Clients) |
| [FedMix: Approximation of Mixup under Mean Augmented Federated Learning](https://openreview.net/pdf?id=Ogga20D2HO-) | KAIST                                                        | ICLR           | 2021 |       |                                                              |
| [Federated Learning via Posterior Averaging: A New Perspective and Practical Algorithms](https://arxiv.org/pdf/2010.05273.pdf) :fire: | CMU; Google                                                  | ICLR           | 2021 |       | [[Code]](https://github.com/alshedivat/fedpa)                |
| [Adaptive Federated Optimization](https://arxiv.org/pdf/2003.00295.pdf) | Google                                                       | ICLR           | 2021 |       | [[Code]](https://github.com/google-research/federated/tree/master/optimization) |
| [Personalized Federated Learning with First Order Model Optimization](https://openreview.net/pdf?id=ehJqJQk9cw) | Stanford University; NVIDIA                                  | ICLR           | 2021 |       |                                                              |
| [FedBN: Federated Learning on Non-IID Features via Local Batch Normalization](https://openreview.net/pdf?id=6YEQUn0QICG) :fire: | Princeton University                                         | ICLR           | 2021 |       | [[Code]](https://github.com/med-air/FedBN)                   |
| [FedBE: Making Bayesian Model Ensemble Applicable to Federated Learning](https://arxiv.org/pdf/2009.01974.pdf) | The Ohio State University                                    | ICLR           | 2021 |       |                                                              |
| [Federated Semi-Supervised Learning with Inter-Client Consistency & Disjoint Learning](https://openreview.net/pdf?id=ce6CFXBh30h) | KAIST                                                        | ICLR           | 2021 |       | [[Code]](https://github.com/wyjeong/FedMatch)                |
| [Gradient Disaggregation: Breaking Privacy in Federated Learning by Reconstructing the User Participant Matrix](https://arxiv.org/pdf/2106.06089.pdf) | Harvard University                                           | ICML           | 2021 |       | [video](https://slideslive.com/38958558/gradient-disaggregation-breaking-privacy-in-federated-learning-by-reconstructing-the-user-participant-matrix) [[Code]](https://github.com/gdisag/gradient_disaggregation) |
| [FL-NTK: A Neural Tangent Kernel-based Framework for Federated Learning Analysis](https://arxiv.org/pdf/2105.05001.pdf) | Peking University;  Princeton University                     | ICML           | 2021 |       | [video](https://slideslive.com/38959650/flntk-a-neural-tangent-kernelbased-framework-for-federated-learning-analysis) |
| [Personalized Federated Learning using Hypernetworks](https://arxiv.org/pdf/2103.04628.pdf) :fire: | Bar-Ilan University;  NVIDIA                                 | ICML           | 2021 |       | [[Code]](https://github.com/AvivSham/pFedHN) [HomePage](https://avivsham.github.io/pfedhn/) [video](https://slideslive.com/38959583/personalized-federated-learning-using-hypernetworks) [[Interpret(zh)](https://zhuanlan.zhihu.com/p/431130945)] |
| [Federated Composite Optimization](https://arxiv.org/pdf/2011.08474.pdf) | Stanford University;  Google                                 | ICML           | 2021 |       | [[Code]](https://github.com/hongliny/FCO-ICML21) [video](https://www.youtube.com/watch?v=tKDbc60XJks&ab_channel=FederatedLearningOneWorldSeminar) [slides](https://hongliny.github.io/files/FCO_ICML21/FCO_ICML21_slides.pdf) |
| [Exploiting Shared Representations for Personalized Federated Learning](https://arxiv.org/pdf/2102.07078.pdf) | University of Texas at Austin;  University of Pennsylvania   | ICML           | 2021 |       | [[Code]](https://github.com/lgcollins/FedRep) [video](https://slideslive.com/38959519/exploiting-shared-representations-for-personalized-federated-learning) |
| [Data-Free Knowledge Distillation for Heterogeneous Federated Learning](https://arxiv.org/pdf/2105.10056.pdf) :fire: | Michigan State University                                    | ICML           | 2021 |       | [[Code]](https://github.com/zhuangdizhu/FedGen) [video](https://slideslive.com/38959429/datafree-knowledge-distillation-for-heterogeneous-federated-learning) |
| [Federated Continual Learning with Weighted Inter-client Transfer](https://arxiv.org/pdf/2003.03196.pdf) | KAIST                                                        | ICML           | 2021 |       | [[Code]](https://github.com/wyjeong/FedWeIT) [video](https://slideslive.com/38959323/federated-continual-learning-with-weighted-interclient-transfer) |
| [Federated Deep AUC Maximization for Hetergeneous Data with a Constant Communication Complexity](https://arxiv.org/pdf/2102.04635.pdf) | The University of Iowa                                       | ICML           | 2021 |       | [video](https://slideslive.com/38959235/federated-deep-auc-maximization-for-hetergeneous-data-with-a-constant-communication-complexity) |
| [Bias-Variance Reduced Local SGD for Less Heterogeneous Federated Learning](https://arxiv.org/pdf/2102.03198.pdf) | The University of Tokyo                                      | ICML           | 2021 |       | [video](https://slideslive.com/38959169/biasvariance-reduced-local-sgd-for-less-heterogeneous-federated-learning) |
| [Federated Learning of User Verification Models Without Sharing Embeddings](https://arxiv.org/pdf/2104.08776.pdf) | Qualcomm                                                     | ICML           | 2021 |       | [video](https://slideslive.com/38958858/federated-learning-of-user-verification-models-without-sharing-embeddings) |
| [Clustered Sampling: Low-Variance and Improved Representativity for Clients Selection in Federated Learning](https://arxiv.org/pdf/2105.05883.pdf) | Accenture                                                    | ICML           | 2021 |       | [[Code]](https://github.com/Accenture//Labs-Federated-Learning/tree/clustered_sampling) [video](https://slideslive.com/38959618/clustered-sampling-lowvariance-and-improved-representativity-for-clients-selection-in-federated-learning) |
| [Ditto: Fair and Robust Federated Learning Through Personalization](https://arxiv.org/pdf/2012.04221.pdf) | CMU;  Facebook AI                                            | ICML           | 2021 |       | [[Code]](https://github.com/litian96/ditto) [video](https://slideslive.com/38955195/ditto-fair-and-robust-federated-learning-through-personalization) |
| [Heterogeneity for the Win: One-Shot Federated Clustering](https://arxiv.org/pdf/2103.00697.pdf) | CMU                                                          | ICML           | 2021 |       | [video](https://slideslive.com/38959380/heterogeneity-for-the-win-oneshot-federated-clustering) |
| [The Distributed Discrete Gaussian Mechanism for Federated Learning with Secure Aggregation](https://arxiv.org/pdf/2102.06387.pdf) | Google                                                       | ICML           | 2021 |       | [video](https://slideslive.com/38959306/the-distributed-discrete-gaussian-mechanism-for-federated-learning-with-secure-aggregation) |
| [Debiasing Model Updates for Improving Personalized Federated Training](http://proceedings.mlr.press/v139/acar21a/acar21a.pdf) | Boston University;  Arm                                      | ICML           | 2021 |       | [video](https://slideslive.com/38959212/debiasing-model-updates-for-improving-personalized-federated-training) |
| [One for One, or All for All: Equilibria and Optimality of Collaboration in Federated Learning](https://arxiv.org/pdf/2103.03228.pdf) | Toyota; Berkeley;  Cornell University                        | ICML           | 2021 |       | [[Code]](https://github.com/rlphilli/Collaborative-Incentives) [video](https://slideslive.com/38959135/one-for-one-or-all-for-all-equilibria-and-optimality-of-collaboration-in-federated-learning) |
| [CRFL: Certifiably Robust Federated Learning against Backdoor Attacks](https://arxiv.org/pdf/2106.08283.pdf) | UIUC; IBM                                                    | ICML           | 2021 |       | [[Code]](https://github.com/AI-secure/CRFL) [video](https://slideslive.com/38959047/crfl-certifiably-robust-federated-learning-against-backdoor-attacks) |
| [Federated Learning under Arbitrary Communication Patterns](https://assets.amazon.science/11/23/3e0cfaf1456d80ecf3f37a2cd812/federated-learning-under-arbitrary-communication-patterns.pdf) | Indiana University;  Amazon                                  | ICML           | 2021 |       | [video](https://slideslive.com/38959048/federated-learning-under-arbitrary-communication-patterns) |
| [Sageflow: Robust Federated Learning against Both Stragglers and Adversaries](https://proceedings.neurips.cc/paper/2021/file/076a8133735eb5d7552dc195b125a454-Paper.pdf) | KAIST                                                        | NeurIPS        | 2021 |       | [HomePage](https://papers.nips.cc/paper/2021/hash/076a8133735eb5d7552dc195b125a454-Abstract.html) |
| [CAFE: Catastrophic Data Leakage in Vertical Federated Learning](https://papers.neurips.cc/paper/2021/file/08040837089cdf46631a10aca5258e16-Paper.pdf) | Rensselaer Polytechnic Institute; IBM Research               | NeurIPS        | 2021 |       | [[Code]](https://github.com/DeRafael/CAFE) [HomePage](https://papers.nips.cc/paper/2021/hash/08040837089cdf46631a10aca5258e16-Abstract.html) |
| [Fault-Tolerant Federated Reinforcement Learning with Theoretical Guarantee](https://papers.neurips.cc/paper/2021/file/080acdcce72c06873a773c4311c2e464-Paper.pdf) | NUS                                                          | NeurIPS        | 2021 |       | [[Code]](https://github.com/flint-xf-fan/Byzantine-Federeated-RL) [HomePage](https://papers.nips.cc/paper/2021/hash/080acdcce72c06873a773c4311c2e464-Abstract.html) |
| [Optimality and Stability in Federated Learning: A Game-theoretic Approach](https://papers.neurips.cc/paper/2021/file/09a5e2a11bea20817477e0b1dfe2cc21-Paper.pdf) | Cornell University                                           | NeurIPS        | 2021 |       | [[Code]](https://github.com/kpdonahue/model_sharing_games) [HomePage](https://papers.nips.cc/paper/2021/hash/09a5e2a11bea20817477e0b1dfe2cc21-Abstract.html) |
| [QuPeD: Quantized Personalization via Distillation with Applications to Federated Learning](https://papers.neurips.cc/paper/2021/file/1dba3025b159cd9354da65e2d0436a31-Paper.pdf) | UCLA                                                         | NeurIPS        | 2021 |       | [HomePage](https://papers.nips.cc/paper/2021/hash/1dba3025b159cd9354da65e2d0436a31-Abstract.html)  [[Code](https://github.com/zkhku/fedsage)] [[Interpret(zh)](https://zhuanlan.zhihu.com/p/430789355)] |
| [The Skellam Mechanism for Differentially Private Federated Learning](https://papers.neurips.cc/paper/2021/file/285baacbdf8fda1de94b19282acd23e2-Paper.pdf) | Google Research; CMU                                         | NeurIPS        | 2021 |       | [HomePage](https://papers.neurips.cc/paper/2021/hash/285baacbdf8fda1de94b19282acd23e2-Abstract.html) |
| [No Fear of Heterogeneity: Classifier Calibration for Federated Learning with Non-IID Data](https://papers.neurips.cc/paper/2021/file/2f2b265625d76a6704b08093c652fd79-Paper.pdf) | NUS;   Huawei                                                | NeurIPS        | 2021 |       | [HomePage](https://papers.neurips.cc/paper/2021/hash/2f2b265625d76a6704b08093c652fd79-Abstract.html) |
| [STEM:  A Stochastic Two-Sided Momentum Algorithm Achieving Near-Optimal Sample  and Communication Complexities for Federated Learning](https://papers.neurips.cc/paper/2021/file/3016a447172f3045b65f5fc83e04b554-Paper.pdf) | University of Minnesota                                      | NeurIPS        | 2021 |       | [HomePage](https://papers.neurips.cc/paper/2021/hash/3016a447172f3045b65f5fc83e04b554-Abstract.html) |
| [Subgraph Federated Learning with Missing Neighbor Generation](https://papers.neurips.cc/paper/2021/file/34adeb8e3242824038aa65460a47c29e-Paper.pdf) | Emory University;   University of British Columbia;   Lehigh University | NeurIPS        | 2021 |       | [HomePage](https://papers.neurips.cc/paper/2021/hash/34adeb8e3242824038aa65460a47c29e-Abstract.html) |
| [Evaluating Gradient Inversion Attacks and Defenses in Federated Learning](https://papers.neurips.cc/paper/2021/file/3b3fff6463464959dcd1b68d0320f781-Paper.pdf) | Princeton University                                         | NeurIPS        | 2021 |       | [HomePage](https://papers.neurips.cc/paper/2021/hash/3b3fff6463464959dcd1b68d0320f781-Abstract.html) |
| [Personalized Federated Learning With Gaussian Processes](https://arxiv.org/pdf/2106.15482.pdf) | Bar-Ilan University                                          | NeurIPS        | 2021 |       | [[Code]](https://github.com/IdanAchituve/pFedGP) [HomePage](https://papers.nips.cc/paper/2021/hash/46d0671dd4117ea366031f87f3aa0093-Abstract.html) |
| [Differentially Private Federated Bayesian Optimization with Distributed Exploration](https://papers.nips.cc/paper/2021/file/4c27cea8526af8cfee3be5e183ac9605-Paper.pdf) | MIT; NUS                                                     | NeurIPS        | 2021 |       | [[Code]](https://github.com/daizhongxiang/Differentially-Private-Federated-Bayesian-Optimization) [HomePage](https://papers.nips.cc/paper/2021/hash/4c27cea8526af8cfee3be5e183ac9605-Abstract.html) |
| [Parameterized Knowledge Transfer for Personalized Federated Learning](https://papers.nips.cc/paper/2021/file/5383c7318a3158b9bc261d0b6996f7c2-Paper.pdf) | Hong Kong Polytechnic University;                            | NeurIPS        | 2021 |       | [HomePage](https://papers.nips.cc/paper/2021/hash/5383c7318a3158b9bc261d0b6996f7c2-Abstract.html) |
| [Federated Reconstruction: Partially Local Federated Learning](https://papers.nips.cc/paper/2021/file/5d44a2b0d85aa1a4dd3f218be6422c66-Paper.pdf) | Google Research                                              | NeurIPS        | 2021 |       | [HomePage](https://papers.nips.cc/paper/2021/hash/5d44a2b0d85aa1a4dd3f218be6422c66-Abstract.html) |
| [Fast Federated Learning in the Presence of Arbitrary Device Unavailability](https://papers.nips.cc/paper/2021/file/64be20f6dd1dd46adf110cf871e3ed35-Paper.pdf) | Tsinghua University; Princeton University; MIT               | NeurIPS        | 2021 |       | [[Code]](https://github.com/hmgxr128/MIFA_code/) [HomePage](https://papers.nips.cc/paper/2021/hash/64be20f6dd1dd46adf110cf871e3ed35-Abstract.html) |
| [FL-WBC: Enhancing Robustness against Model Poisoning Attacks in Federated Learning from a Client Perspective](https://papers.nips.cc/paper/2021/file/692baebec3bb4b53d7ebc3b9fabac31b-Paper.pdf) | Duke University; Accenture Labs                              | NeurIPS        | 2021 |       | [[Code]](https://github.com/jeremy313/FL-WBC) [HomePage](https://papers.nips.cc/paper/2021/hash/692baebec3bb4b53d7ebc3b9fabac31b-Abstract.html) |
| [FjORD: Fair and Accurate Federated Learning under heterogeneous targets with Ordered Dropout](https://papers.nips.cc/paper/2021/file/6aed000af86a084f9cb0264161e29dd3-Paper.pdf) | KAUST; Samsung AI Center                                     | NeurIPS        | 2021 |       | [HomePage](https://papers.nips.cc/paper/2021/hash/6aed000af86a084f9cb0264161e29dd3-Abstract.html) |
| [Linear Convergence in Federated Learning: Tackling Client Heterogeneity and Sparse Gradients](https://papers.nips.cc/paper/2021/file/6aed000af86a084f9cb0264161e29dd3-Paper.pdf) | University of Pennsylvania                                   | NeurIPS        | 2021 |       | [HomePage](https://papers.nips.cc/paper/2021/hash/7a6bda9ad6ffdac035c752743b7e9d0e-Abstract.html) |
| [Federated Multi-Task Learning under a Mixture of Distributions](https://papers.nips.cc/paper/2021/file/82599a4ec94aca066873c99b4c741ed8-Paper.pdf) | INRIA; Accenture Labs                                        | NeurIPS        | 2021 |       | [[Code]](https://github.com/omarfoq/FedEM) [HomePage](https://papers.nips.cc/paper/2021/hash/82599a4ec94aca066873c99b4c741ed8-Abstract.html) |
| [Federated Graph Classification over Non-IID Graphs](https://papers.nips.cc/paper/2021/file/9c6947bd95ae487c81d4e19d3ed8cd6f-Paper.pdf) | Emory University                                             | NeurIPS        | 2021 |       | [HomePage](https://papers.nips.cc/paper/2021/hash/9c6947bd95ae487c81d4e19d3ed8cd6f-Abstract.html) |
| [Federated Hyperparameter Tuning: Challenges, Baselines, and Connections to Weight-Sharing](https://papers.nips.cc/paper/2021/file/a0205b87490c847182672e8d371e9948-Paper.pdf) | CMU; Hewlett Packard Enterprise                              | NeurIPS        | 2021 |       | [[Code]](https://github.com/mkhodak/fedex) [HomePage](https://papers.nips.cc/paper/2021/hash/a0205b87490c847182672e8d371e9948-Abstract.html) |
| [On Large-Cohort Training for Federated Learning ](https://papers.nips.cc/paper/2021/file/ab9ebd57177b5106ad7879f0896685d4-Paper.pdf):fire: | Google; CMU                                                  | NeurIPS        | 2021 |       | [[Code]](https://github.com/google-research/federated/tree/f4e26c1b9b47ac320e520a8b9943ea2c5324b8c2/large_cohort) [HomePage](https://papers.nips.cc/paper/2021/hash/ab9ebd57177b5106ad7879f0896685d4-Abstract.html) |
| [DeepReduce: A Sparse-tensor Communication Framework for Federated Deep Learning](https://papers.nips.cc/paper/2021/file/b0ab42fcb7133122b38521d13da7120b-Paper.pdf) | KAUST; Columbia University; University of Central Florida    | NeurIPS        | 2021 |       | [[Code]](https://github.com/hangxu0304/DeepReduce) [HomePage](https://papers.nips.cc/paper/2021/hash/b0ab42fcb7133122b38521d13da7120b-Abstract.html) |
| [PartialFed: Cross-Domain Personalized Federated Learning via Partial Initialization](https://papers.nips.cc/paper/2021/file/c429429bf1f2af051f2021dc92a8ebea-Paper.pdf) | Huawei                                                       | NeurIPS        | 2021 |       | [HomePage](https://papers.nips.cc/paper/2021/hash/c429429bf1f2af051f2021dc92a8ebea-Abstract.html) |
| [Federated Split Task-Agnostic Vision Transformer for COVID-19 CXR Diagnosis](https://papers.nips.cc/paper/2021/file/ceb0595112db2513b9325a85761b7310-Paper.pdf) | KAIST                                                        | NeurIPS        | 2021 |       | [HomePage](https://papers.nips.cc/paper/2021/hash/ceb0595112db2513b9325a85761b7310-Abstract.html) |
| [Addressing Algorithmic Disparity and Performance Inconsistency in Federated Learning](https://papers.nips.cc/paper/2021/file/db8e1af0cb3aca1ae2d0018624204529-Paper.pdf) | Tsinghua University;  Alibaba; Weill Cornell Medicine        | NeurIPS        | 2021 |       | [[Code]](https://github.com/cuis15/FCFL) [HomePage](https://papers.nips.cc/paper/2021/hash/db8e1af0cb3aca1ae2d0018624204529-Abstract.html) |
| [Federated Linear Contextual Bandits](https://papers.nips.cc/paper/2021/file/e347c51419ffb23ca3fd5050202f9c3d-Paper.pdf) | The Pennsylvania State University;  Facebook; University of Virginia | NeurIPS        | 2021 |       | [HomePage](https://papers.nips.cc/paper/2021/hash/e347c51419ffb23ca3fd5050202f9c3d-Abstract.html) |
| [Few-Round Learning for Federated Learning](https://papers.nips.cc/paper/2021/file/f065d878ccfb4cc4f4265a4ff8bafa9a-Paper.pdf) | KAIST                                                        | NeurIPS        | 2021 |       | [HomePage](https://papers.nips.cc/paper/2021/hash/f065d878ccfb4cc4f4265a4ff8bafa9a-Abstract.html) |
| [Breaking the centralized barrier for cross-device federated learning](https://papers.nips.cc/paper/2021/file/f0e6be4ce76ccfa73c5a540d992d0756-Paper.pdf) | EPFL; Google Research                                        | NeurIPS        | 2021 |       | [[Code]](https://fedjax.readthedocs.io/en/latest/fedjax.algorithms.html#module-fedjax.algorithms.mime) [HomePage](https://papers.nips.cc/paper/2021/hash/f0e6be4ce76ccfa73c5a540d992d0756-Abstract.html) [Video](https://papertalk.org/papertalks/37564) |
| [Federated-EM with heterogeneity mitigation and variance reduction](https://papers.nips.cc/paper/2021/file/f740c8d9c193f16d8a07d3a8a751d13f-Paper.pdf) | Ecole Polytechnique; Google Research                         | NeurIPS        | 2021 |       | [HomePage](https://papers.nips.cc/paper/2021/hash/f740c8d9c193f16d8a07d3a8a751d13f-Abstract.html) |
| [Delayed Gradient Averaging: Tolerate the Communication Latency for Federated Learning](https://papers.nips.cc/paper/2021/file/fc03d48253286a798f5116ec00e99b2b-Paper.pdf) | MIT; Amazon; Google                                          | NeurIPS        | 2021 |       | [HomePage](https://dga.hanlab.ai/)                           |
| [FedDR – Randomized Douglas-Rachford Splitting Algorithms for Nonconvex Federated Composite Optimization](https://papers.nips.cc/paper/2021/file/fe7ee8fc1959cc7214fa21c4840dff0a-Paper.pdf) | University of North Carolina at Chapel Hill; IBM Research    | NeurIPS        | 2021 |       | [[Code]](https://github.com/unc-optimization/FedDR) [HomePage](https://papers.nips.cc/paper/2021/hash/fe7ee8fc1959cc7214fa21c4840dff0a-Abstract.html) |
| [Gradient Inversion with Generative Image Prior](https://papers.nips.cc/paper/2021/file/fa84632d742f2729dc32ce8cb5d49733-Paper.pdf) | Pohang University of Science and Technology; University of Wisconsin-Madison; University of Washington | NeurIPS        | 2021 |       | [[Code]](https://github.com/ml-postech/gradient-inversion-generative-image-prior) [HomePage](https://papers.nips.cc/paper/2021/hash/fa84632d742f2729dc32ce8cb5d49733-Abstract.html) |
| [Federated Adversarial Domain Adaptation](https://openreview.net/pdf?id=HJezF3VYPB) | Boston University; Columbia University; Rutgers University   | ICLR           | 2020 |       |                                                              |
| [DBA: Distributed Backdoor Attacks against Federated Learning](https://openreview.net/pdf?id=rkgyS0VFvr) | Zhejiang University; IBM Research                            | ICLR           | 2020 |       | [[Code]](https://github.com/AI-secure/DBA)                   |
| [Fair Resource Allocation in Federated Learning](https://openreview.net/pdf?id=ByexElSYDr) :fire: | CMU; Facebook AI                                             | ICLR           | 2020 |       | [[Code]](https://github.com/litian96/fair_flearn)            |
| [Federated Learning with Matched Averaging](https://openreview.net/pdf?id=BkluqlSFDS) :fire: | University of Wisconsin-Madison; IBM Research                | ICLR           | 2020 |       | [[Code]](https://github.com/IBM/FedMA)                       |
| [Differentially Private Meta-Learning](https://openreview.net/pdf?id=rJgqMRVYvr) | CMU                                                          | ICLR           | 2020 |       |                                                              |
| [Generative Models for Effective ML on Private, Decentralized Datasets](https://openreview.net/pdf?id=SJgaRA4FPH) :fire: | Google                                                       | ICLR           | 2020 |       | [[Code](https://github.com/google-research/federated/tree/master/gans)] |
| [On the Convergence of FedAvg on Non-IID Data](https://openreview.net/pdf?id=HJxNAnVtDS) :fire: | Peking University                                            | ICLR           | 2020 |       | [[Code]](https://github.com/lx10077/fedavgpy) [[Interpret(zh)](https://zhuanlan.zhihu.com/p/500005337)] |
| [FedBoost: A Communication-Efficient Algorithm for Federated Learning](http://proceedings.mlr.press/v119/hamer20a/hamer20a.pdf) | Google                                                       | ICML           | 2020 |       | [Video](https://slideslive.com/38928463/fedboost-a-communicationefficient-algorithm-for-federated-learning?ref=speaker-16993-latest) |
| [FetchSGD: Communication-Efficient Federated Learning with Sketching](https://arxiv.org/pdf/2007.07682.pdf) | UC Berkeley; Johns Hopkins University; Amazon                | ICML           | 2020 |       | [Video](https://slideslive.com/38928454/fetchsgd-communicationefficient-federated-learning-with-sketching) [[Code]](https://github.com/kiddyboots216/CommEfficient) |
| [SCAFFOLD: Stochastic Controlled Averaging for Federated Learning](https://arxiv.org/pdf/1910.06378.pdf) | EPFL; Google                                                 | ICML           | 2020 |       | [Video](https://slideslive.com/38927610/scaffold-stochastic-controlled-averaging-for-federated-learning) |
| [Federated Learning with Only Positive Labels](https://arxiv.org/abs/2004.10342) | Google                                                       | ICML           | 2020 |       | [Video](https://slideslive.com/38928322/federated-learning-with-only-positive-labels) |
| [From Local SGD to Local Fixed-Point Methods for Federated Learning](https://arxiv.org/pdf/2004.01442.pdf) | Moscow Institute of Physics and Technology; KAUST            | ICML           | 2020 |       | [Slide](https://icml.cc/media/Slides/icml/2020/virtual(no-parent)-15-18-00UTC-6590-from_local_sgd.pdf) [Video](https://slideslive.com/38928320/from-local-sgd-to-local-fixed-point-methods-for-federated-learning) |
| [Acceleration for Compressed Gradient Descent in Distributed and Federated Optimization](https://arxiv.org/abs/2002.11364) | KAUST                                                        | ICML           | 2020 |       | [Slide](https://icml.cc/media/Slides/icml/2020/virtual(no-parent)-15-19-00UTC-6191-acceleration_fo.pdf) [Video](https://slideslive.com/38927921/acceleration-for-compressed-gradient-descent-in-distributed-optimization) |
| [Differentially-Private Federated Linear Bandits](https://arxiv.org/abs/2010.11425) | MIT                                                          | NeurIPS        | 2020 |       | [[Code]](https://github.com/abhimanyudubey/private_federated_linear_bandits) |
| [Federated Principal Component Analysis](https://arxiv.org/abs/1907.08059) | University of Cambridge; Quine Technologies                  | NeurIPS        | 2020 |       | [[Code]](https://github.com/andylamp/federated_pca)          |
| [FedSplit: an algorithmic framework for fast federated optimization](https://arxiv.org/abs/2005.05238) | UC Berkeley                                                  | NeurIPS        | 2020 |       |                                                              |
| [Federated Bayesian Optimization via Thompson Sampling](https://arxiv.org/abs/2010.10154) | NUS; MIT                                                     | NeurIPS        | 2020 |       |                                                              |
| [Lower Bounds and Optimal Algorithms for Personalized Federated Learning](https://arxiv.org/abs/2010.02372) | KAUST                                                        | NeurIPS        | 2020 |       |                                                              |
| [Robust Federated Learning: The Case of Affine Distribution Shifts](https://arxiv.org/abs/2006.08907) | UC Santa Barbara; MIT                                        | NeurIPS        | 2020 |       |                                                              |
| [An Efficient Framework for Clustered Federated Learning](https://arxiv.org/abs/2006.04088) | UC Berkeley; DeepMind                                        | NeurIPS        | 2020 |       | [[Code]](https://github.com/jichan3751/ifca)                 |
| [Distributionally Robust Federated Averaging](https://papers.nips.cc/paper/2020/file/ac450d10e166657ec8f93a1b65ca1b14-Paper.pdf) :fire: | Pennsylvania State University                                | NeurIPS        | 2020 |       | [[Code]](https://github.com/MLOPTPSU/FedTorch)               |
| [Personalized Federated Learning with Moreau Envelopes](https://arxiv.org/abs/2006.08848) :fire: | The University of Sydney                                     | NeurIPS        | 2020 |       | [[Code]](https://github.com/CharlieDinh/pFedMe)              |
| [Personalized Federated Learning with Theoretical Guarantees: A Model-Agnostic Meta-Learning Approach](https://arxiv.org/abs/2002.07948) | MIT; UT Austin                                               | NeurIPS        | 2020 |       |                                                              |
| [Group Knowledge Transfer: Federated Learning of Large CNNs at the Edge](https://arxiv.org/abs/2007.14513) | University of Southern California                            | NeurIPS        | 2020 |       | [[Code]](https://github.com/FedML-AI/FedML/tree/master/fedml_experiments/distributed/fedgkt) [[Interpret(zh)](https://zhuanlan.zhihu.com/p/536901871)] |
| [Tackling the Objective Inconsistency Problem in Heterogeneous Federated Optimization](https://arxiv.org/abs/2007.07481) | CMU; Princeton University                                    | NeurIPS        | 2020 |       |                                                              |
| [Attack of the Tails: Yes, You Really Can Backdoor Federated Learning](https://arxiv.org/abs/2007.05084) | University of Wisconsin-Madison                              | NeurIPS        | 2020 |       |                                                              |
| [Federated Accelerated Stochastic Gradient Descent](https://arxiv.org/abs/2006.08950) | Stanford University                                          | NeurIPS        | 2020 |       | [[Code]](https://github.com/hongliny/FedAc-NeurIPS20)        |
| [Inverting Gradients - How easy is it to break privacy in federated learning?](https://arxiv.org/abs/2003.14053) :fire: | University of Siegen                                         | NeurIPS        | 2020 |       | [[Code]](https://github.com/JonasGeiping/invertinggradients) |
| [Ensemble Distillation for Robust Model Fusion in Federated Learning](https://arxiv.org/pdf/2006.07242.pdf) | EPFL                                                         | NeurIPS        | 2020 |       |                                                              |
| [Throughput-Optimal Topology Design for Cross-Silo Federated Learning](https://arxiv.org/pdf/2010.12229.pdf) | INRIA                                                        | NeurIPS        | 2020 |       | [[Code]](https://github.com/omarfoq/communication-in-cross-silo-fl) |
| [Bayesian Nonparametric Federated Learning of Neural Networks](https://arxiv.org/pdf/1905.12022.pdf) :fire: | IBM                                                          | ICML           | 2019 |       | [[Code]](https://github.com/IBM/probabilistic-federated-neural-matching) |
| [Analyzing Federated Learning through an Adversarial Lens](https://arxiv.org/abs/1811.12470) :fire: | Princeton University; IBM                                    | ICML           | 2019 |       | [[Code]](https://github.com/inspire-group/ModelPoisoning)    |
| [Agnostic Federated Learning](https://arxiv.org/pdf/1902.00146.pdf) | Google                                                       | ICML           | 2019 |       |                                                              |
| [cpSGD: Communication-efficient and differentially-private distributed SGD](https://arxiv.org/pdf/1805.10559.pdf) | Princeton University; Google                                 | NeurIPS        | 2018 |       |                                                              |
| [Federated Multi-Task Learning](https://arxiv.org/pdf/1705.10467.pdf) :fire: | Stanford;   USC;   CMU                                       | NeurIPS        | 2018 |       | [[Code]](https://github.com/gingsmith/fmtl)                  |





## FL in top DM conferences

In this section, we will summarize Federated Learning papers accepted by top DM(Data Mining) conference, Including [KDD](https://dblp.uni-trier.de/db/conf/kdd/index.html)(ACM SIGKDD Conference on Knowledge Discovery and Data Mining) and [WSDM](https://dblp.uni-trier.de/db/conf/wsdm/index.html)(Web Search and Data Mining).

- [KDD](https://dblp.uni-trier.de/search?q=federate%20venue%3AKDD%3A) 2022([Research Track](https://kdd.org/kdd2022/paperRT.html), [Applied Data Science track](https://kdd.org/kdd2022/paperADS.html)) , [2021](https://kdd.org/kdd2021/accepted-papers/index),[2020](https://www.kdd.org/kdd2020/accepted-papers)
- [WSDM](https://dblp.uni-trier.de/search?q=federate%20venue%3AWSDM%3A) 2022, 2021, 2019



| Title                                                        | Affiliation                                                | Venue | Year | TL;DR                                    | Materials                                                    |
| ------------------------------------------------------------ | ---------------------------------------------------------- | ----- | ---- | ---------------------------------------- | ------------------------------------------------------------ |
| Collaboration Equilibrium in Federated Learning              | Department of Automation, Tsinghua University              | KDD   | 2022 | CE[^CE]                                  | [[PDF](https://arxiv.org/abs/2108.07926)] [Code](https://github.com/cuis15/learning-to-collaborate) |
| Connected Low-Loss Subspace Learning for a Personalization in Federated Learning | Ulsan National Institute of Science and Technology         | KDD   | 2022 |                                          |                                                              |
| FedMSplit: Correlation-Adaptive Federated Multi-Task Learning across Multimodal Split Networks | University of Virginia                                     | KDD   | 2022 |                                          |                                                              |
| Communication-Efficient Robust Federated Learning with Noisy Labels | University of Pittsburgh                                   | KDD   | 2022 | Comm-FedBiO[^Comm-FedBiO]                | [[PDF](https://arxiv.org/abs/2206.05558)]                    |
| FLDetector: Detecting Malicious Clients in Federated Learning via Checking Model-Updates Consistency | University of Science and Technology of China              | KDD   | 2022 | FLDetector[^FLDetector]                  | [[PDF](https://arxiv.org/abs/2207.09209)] [Code](https://github.com/zaixizhang/FLDetector) |
| Practical Lossless Federated Singular Vector Decomposition Over Billion-Scale Data | HKUST                                                      | KDD   | 2022 | FedSVD [^FedSVD]                         | [[PDF](https://arxiv.org/abs/2105.08925)] [Code](https://github.com/Di-Chai/FedEval) |
| FedWalk: Communication Efficient Federated Unsupervised Node Embedding with Differential Privacy | Shanghai Jiao Tong University                              | KDD   | 2022 | FedWalk[^FedWalk]                        | [[PDF](https://arxiv.org/abs/2205.15896)]                    |
| EasyFGL: Towards a Unified, Comprehensive and Efficient Platform for Federated Graph Learning :fire: | Alibaba Group                                              | KDD   | 2022 | FederatedScope-GNN [^FederatedScope-GNN] | [[PDF](https://arxiv.org/abs/2204.05562)] [Code](https://github.com/alibaba/FederatedScope) |
| Fed-LTD: Towards Cross-Platform Ride Hailing via Federated Learning to Dispatch | Beihang University                                         | KDD   | 2022 | Fed-LTD [^Fed-LTD]                       | [[PDF](https://hufudb.com/static/paper/2022/SIGKDD2022_Fed-LTD%20Towards%20Cross-Platform%20Ride%20Hailing%20via.pdf)] <br />[[Interpret(zh)](https://zhuanlan.zhihu.com/p/544183874)] |
| Felicitas: Federated Learning in Distributed Cross Device Collaborative Frameworks | USTC                                                       | KDD   | 2022 |                                          | [[PDF](https://arxiv.org/abs/2202.08036)]                    |
| No One Left Behind: Inclusive Federated Learning over Heterogeneous Devices | Renmin University of China                                 | KDD   | 2022 | InclusiveFL [^InclusiveFL]               | [[PDF](https://arxiv.org/abs/2202.08036)]                    |
| FedAttack: Effective and Covert Poisoning Attack on Federated Recommendation via Hard Sampling | Tsinghua University                                        | KDD   | 2022 | FedAttack [^FedAttack]                   | [[PDF](https://arxiv.org/abs/2202.04975)]                    |
| [PipAttack: Poisoning Federated Recommender Systems for Manipulating Item Promotion](https://dl.acm.org/doi/10.1145/3488560.3498386) |                                                            | WSDM  | 2022 |                                          |                                                              |
| Fed2: Feature-Aligned Federated Learning                     | George Mason University; Microsoft; University of Maryland | KDD   | 2021 |                                          | [PDF](https://arxiv.org/abs/2111.14248)                      |
| [FedRS: Federated Learning with Restricted Softmax for Label Distribution Non-IID Data](http://www.lamda.nju.edu.cn/lixc/papers/FedRS-KDD2021-Lixc.pdf) | Nanjing University                                         | KDD   | 2021 |                                          | [Code](https://github.com/lxcnju/FedRepo)                    |
| [Federated Adversarial Debiasing for Fair and Trasnferable Representations](https://jyhong.gitlab.io/publication/fade2021kdd/slides.pdf) | Michigan State University                                  | KDD   | 2021 |                                          | [HomePage](https://jyhong.gitlab.io/publication/fade2021kdd/) [Code](https://github.com/illidanlab/FADE) |
| [Cross-Node Federated Graph Neural Network for Spatio-Temporal Data Modeling](https://dl.acm.org/doi/pdf/10.1145/3447548.3467371) | University of Southern California                          | KDD   | 2021 |                                          | [[Code]](https://github.com/mengcz13/KDD2021_CNFGNN)  [[Interpret(zh)](https://zhuanlan.zhihu.com/p/434839878)] |
| [AsySQN: Faster Vertical Federated Learning Algorithms with Better Computation Resource Utilization](https://arxiv.org/pdf/2109.12519.pdf) | Xidian University;JD Tech                                  | KDD   | 2021 |                                          | [PDF](https://arxiv.org/abs/2109.12519)                      |
| [FLOP: Federated Learning on Medical Datasets using Partial Networks](https://arxiv.org/pdf/2102.05218.pdf) | Duke University                                            | KDD   | 2021 |                                          | [[Code]](https://github.com/jianyizhang123/FLOP)             |
| [A Practical Federated Learning Framework for Small Number of Stakeholders](https://dl.acm.org/doi/10.1145/3437963.3441702) |                                                            | WSDM  | 2021 |                                          |                                                              |
| [Federated Deep Knowledge Tracing](https://dl.acm.org/doi/10.1145/3437963.3441747) |                                                            | WSDM  | 2021 |                                          |                                                              |
| [FedFast: Going Beyond Average for Faster Training of Federated Recommender Systems](https://dl.acm.org/doi/pdf/10.1145/3394486.3403176) | University College Dublin                                  | KDD   | 2020 |                                          | [video](https://papertalk.org/papertalks/23422)              |
| [Federated Doubly Stochastic Kernel Learning for Vertically Partitioned Data](https://arxiv.org/pdf/2008.06197.pdf) | JD Tech                                                    | KDD   | 2020 |                                          | [PDF](https://arxiv.org/abs/2008.06197) [video](https://papertalk.org/papertalks/23301) |
| [Federated Online Learning to Rank with Evolution Strategies](https://dl.acm.org/doi/10.1145/3289600.3290968) |                                                            | WSDM  | 2019 |                                          |                                                              |



## FL in top Secure conferences

In this section, we will summarize Federated Learning papers accepted by top Secure conferences, Including [S&P](https://dblp.uni-trier.de/db/conf/sp/index.html)(IEEE Symposium on Security and Privacy), [CCS](https://dblp.uni-trier.de/db/conf/ccs/index.html)(Conference on Computer and Communications Security), [USENIX Security](https://dblp.uni-trier.de/db/conf/uss/index.html)(Usenix Security Symposium) and [NDSS](https://dblp.uni-trier.de/db/conf/ndss/index.html)(Network and Distributed System Security Symposium).

- [S&P](https://dblp.uni-trier.de/search?q=federate%20venue%3AIEEE%20Symposium%20on%20Security%20and%20Privacy%3A) 2019
- [CCS](https://dblp.uni-trier.de/search?q=federate%20venue%3ACCS%3A) 2021, 2019
- [USENIX Security](https://dblp.uni-trier.de/search?q=federate%20venue%3AUSENIX%20Security%20Symposium%3A)  [2022](https://www.usenix.org/conference/usenixsecurity22/technical-sessions), 2020
- [NDSS](https://dblp.uni-trier.de/search?q=federate%20venue%3ANDSS%3A) 2021


| Title                                                        | Affiliation                                                  | Venue | Year | TL;DR                                               | Materials                                                    |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ----- | ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| [SIMC: ML Inference Secure Against Malicious Clients at Semi-Honest Cost](https://www.usenix.org/conference/usenixsecurity22/presentation/chandran) | Microsoft Research | USENIX Security | 2022 |  | [PUB.](https://www.usenix.org/system/files/sec22summer_chandran.pdf) [PDF](https://eprint.iacr.org/2021/1538) [code](https://github.com/shahakash28/simc) |
| [Efficient Differentially Private Secure Aggregation for Federated Learning via Hardness of Learning with Errors](https://www.usenix.org/conference/usenixsecurity22/presentation/stevens) | University of Vermont | USENIX Security | 2022 |  | [PUB.](https://www.usenix.org/system/files/sec22fall_stevens.pdf) |
| [Label Inference Attacks Against Vertical Federated Learning](https://www.usenix.org/conference/usenixsecurity22/presentation/fu-chong) | Zhejiang University | USENIX Security | 2022 |  | [PUB.](https://www.usenix.org/system/files/sec22summer_fu.pdf) [code](https://github.com/FuChong-cyber/label-inference-attacks) |
| [FLAME: Taming Backdoors in Federated Learning](https://www.usenix.org/conference/usenixsecurity22/presentation/nguyen) | Technical University of Darmstadt | USENIX Security | 2022 |  | [PUB.](https://www.usenix.org/system/files/sec22fall_nguyen.pdf) [PDF](https://arxiv.org/abs/2101.02281) |
|Local and Central Differential Privacy for Robustness and Privacy in Federated Learning| University at Buffalo, SUNY| NDSS | 2022 |  | [PDF](https://arxiv.org/pdf/2009.03561) [Unofficial code](https://github.com/wenzhu23333/Differential-Privacy-Based-Federated-Learning) |
|[Interpretable Federated Transformer Log Learning for Cloud Threat Forensics](https://www.ndss-symposium.org/wp-content/uploads/2022-102-paper.pdf)|University of the Incarnate Word, TX, USA | NDSS | 2022 |  | [Unofficial code](https://github.com/cyberthreat-datasets/ctdd-2021-os-syslogs) |
|[FedCRI: Federated Mobile Cyber-Risk Intelligence](https://www.ndss-symposium.org/wp-content/uploads/2022-153-paper.pdf)| Technical University of Darmstadt| NDSS | 2022 |  |  |
|DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection| Technical University of Darmstadt| NDSS | 2022 ||[PDF](https://arxiv.org/pdf/2201.00763)|
| [Private Hierarchical Clustering in Federated Networks](https://dl.acm.org/doi/10.1145/3460120.3484822) | National University Of Singapore | CCS             | 2021 |                                                              |                                                              |
| [FLTrust: Byzantine-robust Federated Learning via Trust Bootstrapping](https://www.ndss-symposium.org/ndss-paper/fltrust-byzantine-robust-federated-learning-via-trust-bootstrapping/) | Duke University | NDSS            | 2021 |  | [PDF](https://arxiv.org/abs/2012.13995) [code](https://people.duke.edu/~zg70/code/fltrust.zip) [Video](https://www.youtube.com/watch?v=zhhdPgKPCN0&list=PLfUWWM-POgQvaqlGPwlOa0JR3bryB1KCS&index=2) [Slides](https://people.duke.edu/~zg70/code/Secure_Federated_Learning.pdf) |
| [POSEIDON: Privacy-Preserving Federated Neural Network Learning](https://www.ndss-symposium.org/ndss-paper/poseidon-privacy-preserving-federated-neural-network-learning/) | Laboratory for Data Security, EPFL | NDSS            | 2021 |  | [Video](https://www.youtube.com/watch?v=kX6-PMzxZ3c&list=PLfUWWM-POgQvaqlGPwlOa0JR3bryB1KCS&index=1) |
| [Manipulating the Byzantine: Optimizing Model Poisoning Attacks and Defenses for Federated Learning](https://www.ndss-symposium.org/ndss-paper/manipulating-the-byzantine-optimizing-model-poisoning-attacks-and-defenses-for-federated-learning/) | University of Massachusetts Amherst | NDSS            | 2021 |  | [code](https://github.com/vrt1shjwlkr/NDSS21-Model-Poisoning) [Video](https://www.youtube.com/watch?v=G2VYRnLqAXE&list=PLfUWWM-POgQvaqlGPwlOa0JR3bryB1KCS&index=3) |
| [Local Model Poisoning Attacks to Byzantine-Robust Federated Learning](https://www.usenix.org/conference/usenixsecurity20/presentation/fang) | The Ohio State University | USENIX Security | 2020 |  | [PDF](https://arxiv.org/abs/1911.11815) [code](https://people.duke.edu/~zg70/code/fltrust.zip) [Video](https://www.youtube.com/watch?v=SQ12UpYrUVU&feature=emb_imp_woyt) [Slides](https://www.usenix.org/system/files/sec20_slides_fang.pdf) |
| [Poster: A Reliable and Accountable Privacy-Preserving Federated Learning Framework using the Blockchain](https://dl.acm.org/doi/10.1145/3319535.3363256) | University of Kansas | CCS             | 2019 |                                                              |                                                              |
| [IOTFLA : A Secured and Privacy-Preserving Smart Home Architecture Implementing Federated Learning](https://ieeexplore.ieee.org/document/8844592) | Université du Québéc á Montréal | S&P             | 2019 |                                                              |                                                              |
| [Comprehensive Privacy Analysis of Deep Learning: Passive and Active White-box Inference Attacks against Centralized and Federated Learning](https://ieeexplore.ieee.org/document/8835245) :fire: | University of Massachusetts Amherst | S&P             | 2019 |  | [code](https://github.com/privacytrustlab/ml_privacy_meter) |


## FL in top CV conferences

In this section, we will summarize Federated Learning papers accepted by top CV(computer vision) conference, Including [CVPR](https://dblp.uni-trier.de/db/conf/cvpr/index.html)(Computer Vision and Pattern Recognition), [ICCV](https://dblp.uni-trier.de/db/conf/iccv/index.html)(IEEE International Conference on Computer Vision), [ECCV](https://dblp.uni-trier.de/db/conf/eccv/index.html)(European Conference on Computer Vision), [MM](https://dblp.org/db/conf/mm/index.html)(ACM International Conference on Multimedia).

- [CVPR](https://dblp.uni-trier.de/search?q=federate%20venue%3ACVPR%3A) [2022](https://openaccess.thecvf.com/CVPR2022), 2021
- [ICCV](https://dblp.uni-trier.de/search?q=federate%20venue%3AICCV%3A) 2021
- [ECCV](https://dblp.uni-trier.de/search?q=federate%20venue%3AECCV%3A) 2020
- [MM](https://dblp.uni-trier.de/search?q=federate%20venue%3AACM%20Multimedia%3A) [2021](https://2021.acmmm.org/main-track-list), [2020](https://2020.acmmm.org/main-track-list.html)

| Title                                                        | Affiliation                                                  | Venue | Year | TL;DR                                       | Materials                                                    |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ----- | ---- | ------------------------------------------- | ------------------------------------------------------------ |
| Personalizing Federated Medical Image Segmentation via Local Calibration | Xiamen University                                            | ECCV  | 2022 | LC-Fed [^LC-Fed]                            | [[PDF](https://arxiv.org/abs/2207.04655)] [Code](https://github.com/jcwang123/fedlc) |
| Improving Generalization in Federated Learning by Seeking Flat Minima | Politecnico di Torino                                        | ECCV  | 2022 | FedSAM [^FedSAM]                            | [[PDF](https://arxiv.org/abs/2203.11834)] [Code](https://github.com/debcaldarola/fedsam) |
| [ATPFL: Automatic Trajectory Prediction Model Design Under Federated Learning Framework](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_ATPFL_Automatic_Trajectory_Prediction_Model_Design_Under_Federated_Learning_Framework_CVPR_2022_paper.html) | Harbin Institute of Technology                               | CVPR  | 2022 | ATPFL [^ATPFL]                              | [[PUB](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ATPFL_Automatic_Trajectory_Prediction_Model_Design_Under_Federated_Learning_Framework_CVPR_2022_paper.pdf).] |
| [Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning](https://openaccess.thecvf.com/content/CVPR2022/html/Qu_Rethinking_Architecture_Design_for_Tackling_Data_Heterogeneity_in_Federated_Learning_CVPR_2022_paper.html) | Stanford University                                          | CVPR  | 2022 | ViT-FL [^ViT-FL]                            | [[PUB.](https://openaccess.thecvf.com/content/CVPR2022/papers/Qu_Rethinking_Architecture_Design_for_Tackling_Data_Heterogeneity_in_Federated_Learning_CVPR_2022_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Qu_Rethinking_Architecture_Design_CVPR_2022_supplemental.pdf)] [[PDF](http://arxiv.org/abs/2106.06047)] [[Code]](https://github.com/Liangqiong/ViT-FL-main) [video](https://www.youtube.com/watch?v=Ae1CDi0_Nok&ab_channel=StanfordMedAI) |
| [FedCorr: Multi-Stage Federated Learning for Label Noise Correction](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_FedCorr_Multi-Stage_Federated_Learning_for_Label_Noise_Correction_CVPR_2022_paper.html) | Singapore University of Technology and Design                | CVPR  | 2022 | FedCorr[^FedCorr]                           | [[PUB.](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_FedCorr_Multi-Stage_Federated_Learning_for_Label_Noise_Correction_CVPR_2022_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_FedCorr_Multi-Stage_Federated_CVPR_2022_supplemental.pdf)] [[PDF](http://arxiv.org/abs/2204.04677)] [[Code]](https://github.com/xu-jingyi/fedcorr) [video](https://www.youtube.com/watch?v=GA22ct1LgRA&ab_channel=ZihanChen) |
| [FedCor: Correlation-Based Active Client Selection Strategy for Heterogeneous Federated Learning](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_FedCor_Correlation-Based_Active_Client_Selection_Strategy_for_Heterogeneous_Federated_Learning_CVPR_2022_paper.html) | Duke University                                              | CVPR  | 2022 | FedCor [^FedCor]                            | [[PUB.](https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_FedCor_Correlation-Based_Active_Client_Selection_Strategy_for_Heterogeneous_Federated_Learning_CVPR_2022_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tang_FedCor_Correlation-Based_Active_CVPR_2022_supplemental.zip)] [[PDF](http://arxiv.org/abs/2103.13822)] |
| [Layer-Wised Model Aggregation for Personalized Federated Learning](https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Layer-Wised_Model_Aggregation_for_Personalized_Federated_Learning_CVPR_2022_paper.html) | The Hong Kong Polytechnic University                         | CVPR  | 2022 | pFedLA [^pFedLA]                            | [[PUB.](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Layer-Wised_Model_Aggregation_for_Personalized_Federated_Learning_CVPR_2022_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ma_Layer-Wised_Model_Aggregation_CVPR_2022_supplemental.pdf)] [[PDF](http://arxiv.org/abs/2205.03993)] |
| [Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning](https://openaccess.thecvf.com/content/CVPR2022/html/Mendieta_Local_Learning_Matters_Rethinking_Data_Heterogeneity_in_Federated_Learning_CVPR_2022_paper.html) | University of Central Florida                                | CVPR  | 2022 | FedAlign[^FedAlign]                         | [[PUB.](https://openaccess.thecvf.com/content/CVPR2022/papers/Mendieta_Local_Learning_Matters_Rethinking_Data_Heterogeneity_in_Federated_Learning_CVPR_2022_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mendieta_Local_Learning_Matters_CVPR_2022_supplemental.pdf)] [[PDF](http://arxiv.org/abs/2111.14213)] [[Code]](https://github.com/mmendiet/FedAlign) |
| [Federated Learning With Position-Aware Neurons](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Federated_Learning_With_Position-Aware_Neurons_CVPR_2022_paper.html) | Nanjing University                                           | CVPR  | 2022 | PANs [^PANs]                                | [[PUB.](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Federated_Learning_With_Position-Aware_Neurons_CVPR_2022_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Federated_Learning_With_CVPR_2022_supplemental.pdf)] [[PDF](http://arxiv.org/abs/2203.14666)] |
| [RSCFed: Random Sampling Consensus Federated Semi-Supervised Learning](https://openaccess.thecvf.com/content/CVPR2022/html/Liang_RSCFed_Random_Sampling_Consensus_Federated_Semi-Supervised_Learning_CVPR_2022_paper.html) | The Hong Kong University of Science and Technology           | CVPR  | 2022 | RSCFed  [^RSCFed]                           | [[PUB.](https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_RSCFed_Random_Sampling_Consensus_Federated_Semi-Supervised_Learning_CVPR_2022_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liang_RSCFed_Random_Sampling_CVPR_2022_supplemental.pdf)] [[PDF](http://arxiv.org/abs/2203.13993)] [[Code]](https://github.com/xmed-lab/rscfed) |
| [Learn From Others and Be Yourself in Heterogeneous Federated Learning](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Learn_From_Others_and_Be_Yourself_in_Heterogeneous_Federated_Learning_CVPR_2022_paper.html) | Wuhan University                                             | CVPR  | 2022 | FCCL[^FCCL]                                 | [[PUB.](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Learn_From_Others_and_Be_Yourself_in_Heterogeneous_Federated_Learning_CVPR_2022_paper.pdf)] [[code](https://github.com/wenkehuang/fccl)] [video](https://www.youtube.com/watch?v=zZoASA71qwQ&ab_channel=HuangWenke) |
| [Robust Federated Learning With Noisy and Heterogeneous Clients](https://openaccess.thecvf.com/content/CVPR2022/html/Fang_Robust_Federated_Learning_With_Noisy_and_Heterogeneous_Clients_CVPR_2022_paper.html) | Wuhan University                                             | CVPR  | 2022 | RHFL [^RHFL]                                | [[PUB.](https://openaccess.thecvf.com/content/CVPR2022/papers/Fang_Robust_Federated_Learning_With_Noisy_and_Heterogeneous_Clients_CVPR_2022_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fang_Robust_Federated_Learning_CVPR_2022_supplemental.pdf)] [[Code]](https://github.com/FangXiuwen/Robust_FL) |
| [ResSFL: A Resistance Transfer Framework for Defending Model Inversion Attack in Split Federated Learning](https://openaccess.thecvf.com/content/CVPR2022/html/Li_ResSFL_A_Resistance_Transfer_Framework_for_Defending_Model_Inversion_Attack_CVPR_2022_paper.html) | Arizona State University                                     | CVPR  | 2022 | ResSFL [^ResSFL]                            | [[PUB.](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_ResSFL_A_Resistance_Transfer_Framework_for_Defending_Model_Inversion_Attack_CVPR_2022_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_ResSFL_A_Resistance_CVPR_2022_supplemental.pdf)] [[PDF](http://arxiv.org/abs/2205.04007)] [[Code]](https://github.com/zlijingtao/ResSFL) |
| [FedDC: Federated Learning With Non-IID Data via Local Drift Decoupling and Correction](https://openaccess.thecvf.com/content/CVPR2022/html/Gao_FedDC_Federated_Learning_With_Non-IID_Data_via_Local_Drift_Decoupling_CVPR_2022_paper.html) | National University of Defense Technology                    | CVPR  | 2022 | FedDC [^FedDC]                              | [[PUB.](https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_FedDC_Federated_Learning_With_Non-IID_Data_via_Local_Drift_Decoupling_CVPR_2022_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gao_FedDC_Federated_Learning_CVPR_2022_supplemental.pdf)] [[PDF](http://arxiv.org/abs/2203.11751)] [[Code](https://github.com/gaoliang13/FedDC)] [[Interpret(zh)](https://zhuanlan.zhihu.com/p/505889549)] |
| [Federated Class-Incremental Learning](https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Federated_Class-Incremental_Learning_CVPR_2022_paper.html) | Chinese Academy of Sciences; Northwestern University;  University of Technology Sydney | CVPR  | 2022 | GLFC [^GLFC]                                | [[PUB.](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Federated_Class-Incremental_Learning_CVPR_2022_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dong_Federated_Class-Incremental_Learning_CVPR_2022_supplemental.pdf)] [[PDF](http://arxiv.org/abs/2203.11473)] [[Code]](https://github.com/conditionWang/FCIL) |
| [Fine-Tuning Global Model via Data-Free Knowledge Distillation for Non-IID Federated Learning](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Fine-Tuning_Global_Model_via_Data-Free_Knowledge_Distillation_for_Non-IID_Federated_CVPR_2022_paper.html) | Peking University;   JD Explore Academy;   The University of Sydney | CVPR  | 2022 | FedFTG [^FedFTG]                            | [[PUB.](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Fine-Tuning_Global_Model_via_Data-Free_Knowledge_Distillation_for_Non-IID_Federated_CVPR_2022_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Fine-Tuning_Global_Model_CVPR_2022_supplemental.pdf)] [[PDF](http://arxiv.org/abs/2203.09249)] |
| [Differentially Private Federated Learning With Local Regularization and Sparsification](https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Differentially_Private_Federated_Learning_With_Local_Regularization_and_Sparsification_CVPR_2022_paper.html) | Chinese Academy of Sciences                                  | CVPR  | 2022 | DP-FedAvg +BLUR + LUS [^DP-FedAvg+BLUR+LUS] | [[PUB.](https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Differentially_Private_Federated_Learning_With_Local_Regularization_and_Sparsification_CVPR_2022_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cheng_Differentially_Private_Federated_CVPR_2022_supplemental.pdf)] [[PDF](http://arxiv.org/abs/2203.03106)] |
| [Auditing Privacy Defenses in Federated Learning via Generative Gradient Leakage](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Auditing_Privacy_Defenses_in_Federated_Learning_via_Generative_Gradient_Leakage_CVPR_2022_paper.html) | University of Tennessee; Oak Ridge National Laboratory; Google Research | CVPR  | 2022 | GGL [^GGL]                                  | [[PUB.](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Auditing_Privacy_Defenses_in_Federated_Learning_via_Generative_Gradient_Leakage_CVPR_2022_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Auditing_Privacy_Defenses_CVPR_2022_supplemental.pdf)] [[PDF](http://arxiv.org/abs/2203.15696)] [[Code]](https://github.com/zhuohangli/GGL) [video](https://www.youtube.com/watch?v=rphFSGDlGPY&ab_channel=MoSISLab) |
| [CD2-pFed: Cyclic Distillation-Guided Channel Decoupling for Model Personalization in Federated Learning](https://openaccess.thecvf.com/content/CVPR2022/html/Shen_CD2-pFed_Cyclic_Distillation-Guided_Channel_Decoupling_for_Model_Personalization_in_Federated_CVPR_2022_paper.html) | Shanghai Jiao Tong University                                | CVPR  | 2022 | CD2-pFed [^CD2-pFed]                        | [[PUB.](https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_CD2-pFed_Cyclic_Distillation-Guided_Channel_Decoupling_for_Model_Personalization_in_Federated_CVPR_2022_paper.pdf)] [[PDF](https://arxiv.org/abs/2204.03880)] |
| [Closing the Generalization Gap of Cross-Silo Federated Medical Image Segmentation](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Closing_the_Generalization_Gap_of_Cross-Silo_Federated_Medical_Image_Segmentation_CVPR_2022_paper.html) | Univ. of Pittsburgh; NVIDIA                                  | CVPR  | 2022 | FedSM [^FedSM]                              | [[PUB.](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Closing_the_Generalization_Gap_of_Cross-Silo_Federated_Medical_Image_Segmentation_CVPR_2022_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_Closing_the_Generalization_CVPR_2022_supplemental.pdf)] [[PDF](http://arxiv.org/abs/2203.10144)] |
| [Multi-Institutional  Collaborations for Improving Deep Learning-Based Magnetic Resonance  Image Reconstruction Using Federated Learning](https://arxiv.org/pdf/2103.02148.pdf) | Johns Hopkins University                                     | CVPR  | 2021 | FL-MRCM [^FL-MRCM]                          | [[Code]](https://github.com/guopengf/FL-MRCM)                |
| [Model-Contrastive Federated Learning](https://arxiv.org/pdf/2103.16257.pdf) :fire: | National University of Singapore; UC Berkeley                | CVPR  | 2021 | MOON [^MOON]                                | [[pdf](https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Model-Contrastive_Federated_Learning_CVPR_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2021/supplemental/Li_Model-Contrastive_Federated_Learning_CVPR_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2103.16257)] [[Code]](https://github.com/QinbinLi/MOON) [[Interpret(zh)](https://weisenhui.top/posts/17666.html)] |
| [FedDG: Federated Domain Generalization on Medical Image Segmentation via Episodic Learning in Continuous Frequency Space](https://arxiv.org/pdf/2103.06030.pdf) :fire: | The Chinese University of Hong Kong                          | CVPR  | 2021 | FedDG-ELCFS [^FedDG-ELCFS]                  | [[Code]](https://github.com/liuquande/FedDG-ELCFS)           |
| [Soteria: Provable Defense Against Privacy Leakage in Federated Learning From Representation Perspective](https://arxiv.org/pdf/2012.06043.pdf) | Duke University                                              | CVPR  | 2021 | Soteria [^Soteria]                          | [[Code]](https://github.com/jeremy313/Soteria)               |
| [Federated Learning for Non-IID Data via Unified Feature Learning and Optimization Objective Alignment](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Federated_Learning_for_Non-IID_Data_via_Unified_Feature_Learning_and_ICCV_2021_paper.pdf) | Peking University                                            | ICCV  | 2021 | FedUFO [^FedUFO]                            |                                                              |
| [Ensemble Attention Distillation for Privacy-Preserving Federated Learning](https://openaccess.thecvf.com/content/ICCV2021/papers/Gong_Ensemble_Attention_Distillation_for_Privacy-Preserving_Federated_Learning_ICCV_2021_paper.pdf) | University at Buffalo                                        | ICCV  | 2021 | FedAD [^FedAD]                              | [[PUB](https://ieeexplore.ieee.org/document/9710586).]       |
| [Collaborative Unsupervised Visual Representation Learning from Decentralized Data](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhuang_Collaborative_Unsupervised_Visual_Representation_Learning_From_Decentralized_Data_ICCV_2021_paper.pdf) | Nanyang Technological University; SenseTime                  | ICCV  | 2021 | FedU [^FedU]                                | [PDF](https://arxiv.org/abs/2108.06492)                      |
| Joint Optimization in Edge-Cloud Continuum for Federated Unsupervised Person Re-identification | Nanyang Technological University                             | MM    | 2021 | FedUReID [^FedUReID]                        | [[PUB](https://dl.acm.org/doi/10.1145/3474085.3475182).] [[PDF](https://arxiv.org/abs/2108.06493)] |
| [Federated Visual Classification with Real-World Data Distribution](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123550086.pdf) | MIT; Google                                                  | ECCV  | 2020 | FedVC+FedIR [^FedVC+FedIR]                  | [PDF](https://arxiv.org/abs/2003.08082) [Video](https://www.youtube.com/watch?v=Rc67rZzPDDY&ab_channel=TzuMingHsu) |
| InvisibleFL: Federated Learning over Non-Informative Intermediate Updates against Multimedia Privacy Leakages |                                                              | MM    | 2020 | InvisibleFL [^InvisibleFL]                  | [[PUB](https://dl.acm.org/doi/10.1145/3394171.3413923).]     |
| Performance Optimization of Federated Person Re-identification via Benchmark Analysis **`data.`** | Nanyang Technological University                             | MM    | 2020 | FedReID [^FedReID]                          | [[PUB](https://dl.acm.org/doi/10.1145/3394171.3413814).] [[PDF](https://arxiv.org/abs/2008.11560)] [Code ](https://github.com/cap-ntu/FedReID) [[Interpret(zh)](https://zhuanlan.zhihu.com/p/265987079)] |



## FL in top NLP conferences

In this section, we will summarize Federated Learning papers accepted by top AI and NLP conference, including [ACL](https://dblp.uni-trier.de/db/conf/acl/index.html)(Annual Meeting of the Association for Computational Linguistics), [NAACL](https://dblp.uni-trier.de/db/conf/naacl/index.html)(North American Chapter of the Association for Computational Linguistics), [EMNLP](https://dblp.uni-trier.de/db/conf/emnlp/index.html)(Conference on Empirical Methods in Natural Language Processing) and [COLING](https://dblp.uni-trier.de/db/conf/coling/index.html)(International Conference on Computational Linguistics).

- ACL [2022](https://aclanthology.org/events/acl-2022/), [2021](https://aclanthology.org/events/acl-2021/), [2019](https://aclanthology.org/events/acl-2019/)
- [NAACL](https://dblp.uni-trier.de/search?q=federate%20venue%3ANAACL-HLT%3A) [2022](https://aclanthology.org/events/naacl-2022/), [2021](https://aclanthology.org/events/naacl-2021/)
- [EMNLP](https://dblp.uni-trier.de/search?q=federate%20venue%3AEMNLP%3A) [2021](https://aclanthology.org/events/emnlp-2021/), [2020](https://aclanthology.org/events/emnlp-2020/)
- [COLING](https://dblp.uni-trier.de/search?q=federate%20venue%3ACOLING%3A) [2020](https://aclanthology.org/events/coling-2020/)



| Title                                                        | Affiliation                                       | Venue          | Year | TL;DR | Materials                                                    |
| ------------------------------------------------------------ | ------------------------------------------------- | -------------- | ---- | ----- | ------------------------------------------------------------ |
| [Scaling Language Model Size in Cross-Device Federated Learning](https://aclanthology.org/2022.fl4nlp-1.2.pdf) | Google                                            | ACL workshop   | 2022 |       | [PDF](https://arxiv.org/abs/2204.09715)                      |
| [Intrinsic Gradient Compression for Scalable and Efficient Federated Learning](https://aclanthology.org/2022.fl4nlp-1.4.pdf) | Oxford, UK                                        | ACL workshop   | 2022 |       | [PDF](https://arxiv.org/abs/2112.02656)                      |
| [ActPerFL: Active Personalized Federated Learning](https://aclanthology.org/2022.fl4nlp-1.1.pdf) | Alexa AI, Amazon                                  | ACL workshop   | 2022 |       | [HomePage](https://www.amazon.science/publications/actperfl-active-personalized-federated-learning) |
| [FedNLP: Benchmarking Federated Learning Methods for Natural Language Processing Tasks ](https://openreview.net/forum?id=ru-l-scWHWq) :fire: | USC                                               | NAACL          | 2022 |       | [PDF](https://arxiv.org/abs/2104.08815) [Code](https://github.com/FedML-AI/FedNLP) |
| [Federated Learning with Noisy User Feedback](https://aclanthology.org/2022.naacl-main.196.pdf) | USC, Amazon                                       | NAACL          | 2022 |       | [PDF](https://arxiv.org/abs/2205.03092)                      |
| [Training Mixed-Domain Translation Models via Federated Learning](https://aclanthology.org/2022.naacl-main.186.pdf) | Amazon                                            | NAACL          | 2022 |       | [HomePage](https://www.amazon.science/publications/training-mixed-domain-translation-models-via-federated-learning) [PDF](https://arxiv.org/abs/2205.01557) |
| [Pretrained Models for Multilingual Federated Learning](https://aclanthology.org/2022.naacl-main.101.pdf) | Johns Hopkins University                          | NAACL          | 2022 |       | [PDF](https://arxiv.org/abs/2206.02291)                      |
| [Training Mixed-Domain Translation Models via Federated Learning](https://aclanthology.org/2022.naacl-main.186.pdf) | Amazon                                            | NAACL          | 2022 |       | [HomePage](https://www.amazon.science/publications/training-mixed-domain-translation-models-via-federated-learning) [PDF](https://arxiv.org/abs/2205.01557) |
| [Federated Chinese Word Segmentation with Global Character Associations](https://aclanthology.org/2021.findings-acl.376.pdf) | University of Washington                          | ACL workshop   | 2021 |       | [code](https://github.com/cuhksz-nlp/GCASeg)                 |
| [Efficient-FedRec: Efficient Federated Learning Framework for Privacy-Preserving News Recommendation](https://aclanthology.org/2021.emnlp-main.223.pdf) | University of Science and Technology of China     | EMNLP          | 2021 |       | [PDF](https://arxiv.org/abs/2109.05446) [code](https://github.com/yjw1029/Efficient-FedRec) |
| [Improving Federated Learning for Aspect-based Sentiment Analysis via Topic Memories](https://aclanthology.org/2021.emnlp-main.321/) | The Chinese University of Hong Kong (Shenzhen)    | EMNLP          | 2021 |       | [Video](https://aclanthology.org/2021.emnlp-main.321.mp4) [code](https://github.com/cuhksz-nlp/ASA-TM) |
| [A Secure and Efficient Federated Learning Framework for NLP](https://aclanthology.org/2021.emnlp-main.606.pdf) | University of Connecticut                         | EMNLP          | 2021 |       | [PDF](https://arxiv.org/abs/2201.11934)                      |
| [Distantly Supervised Relation Extraction in Federated Settings](https://aclanthology.org/2021.findings-emnlp.52.pdf) | Institute of Automation, CAS                      | EMNLP workshop | 2021 |       | [PDF](https://arxiv.org/abs/2008.05049) [Code](https://github.com/DianboWork/FedDS) |
| [Federated Learning with Noisy User Feedback](https://aclanthology.org/2022.naacl-main.196.pdf) | USC, Amazon                                       | NAACL workshop | 2021 |       | [PDF](https://arxiv.org/abs/2205.03092)                      |
| [An Investigation towards Differentially Private Sequence Tagging in a Federated Framework](https://aclanthology.org/2021.privatenlp-1.4.pdf) | Universität Hamburg, Germany                      | NAACL workshop | 2021 |       |                                                              |
| [Understanding Unintended Memorization in Language Models Under Federated Learning](https://aclanthology.org/2021.privatenlp-1.1/) | Google                                            | NAACL workshop | 2021 |       | [PDF](https://arxiv.org/abs/2006.07490)                      |
| [FedED: Federated Learning via Ensemble Distillation for Medical Relation Extraction](https://aclanthology.org/2020.emnlp-main.165/) | Institute of Automation, CAS                      | EMNLP          | 2020 |       |                                                              |
| [Empirical Studies of Institutional Federated Learning For Natural Language Processing](https://aclanthology.org/2020.findings-emnlp.55/) | Shenzhen, P.R.China                               | EMNLP workshop | 2020 |       |                                                              |
| [Federated Learning for Spoken Language Understanding](https://aclanthology.org/2020.coling-main.310/) | Peking University                                 | COLING         | 2020 |       |                                                              |
| [Two-stage Federated Phenotyping and Patient Representation Learning](https://aclanthology.org/W19-5030.pdf) | Boston Children’s Hospital Harvard Medical School | ACL workshop   | 2019 |       | [PDF](https://arxiv.org/abs/1908.05596)                      |



## FL in top IR conferences

In this section, we will summarize Federated Learning papers accepted by top Information Retrieval conference, including [SIGIR](https://dblp.org/db/conf/sigir/index.html)(Annual International ACM SIGIR Conference on Research and Development in Information Retrieval).

- [SIGIR](https://dblp.uni-trier.de/search?q=federate%20venue%3ASIGIR%3A) 2022

| Title                                                        | Affiliation | Venue | Year | TL;DR | Materials |
| ------------------------------------------------------------ | ----------- | ----- | ---- | ----- | --------- |
| [Is Non-IID Data a Threat in Federated Online Learning to Rank?](https://dl.acm.org/doi/10.1145/3477495.3531709) |             | SIGIR | 2022 |       |           |
| [FedCT: Federated Collaborative Transfer for Recommendation](https://dl.acm.org/doi/10.1145/3404835.3462825) |             | SIGIR | 2021 |       |           |
| [On the Privacy of Federated Pipelines](https://dl.acm.org/doi/10.1145/3404835.3462996) |             | SIGIR | 2021 |       |           |
| [FedCMR: Federated Cross-Modal Retrieval.](https://dl.acm.org/doi/10.1145/3404835.3462989) |             | SIGIR | 2021 |       |           |
| [Meta Matrix Factorization for Federated Rating Predictions.](https://dl.acm.org/doi/10.1145/3397271.3401081) |             | SIGIR | 2020 |       |           |



## FL in top DB conferences

In this section, we will summarize Federated Learning papers accepted by top Database conference, including [SIGMOD](https://dblp.uni-trier.de/db/conf/sigmod/index.html)(ACM SIGMOD Conference) , [ICDE](https://dblp.uni-trier.de/db/conf/icde/index.html)(IEEE International Conference on Data Engineering) and [VLDB](https://dblp.uni-trier.de/db/conf/vldb/index.html)(Very Large Data Bases Conference).

- [SIGMOD](https://dblp.uni-trier.de/search?q=federate%20venue%3ASIGMOD%20Conference%3A) 2022,2021
- [ICDE](https://dblp.uni-trier.de/search?q=federate%20venue%3AICDE%3A) 2021
- [VLDB](https://dblp.org/search?q=federate%20venue%3AProc%20VLDB%20Endow%3A) [2021](https://vldb.org/pvldb/vol15-volume-info/), [2021](http://www.vldb.org/pvldb/vol14/),[2020](http://vldb.org/pvldb/vol13-volume-info/)

| Title                                                        | Affiliation                      | Venue            | Year | TL;DR | Materials                                                |
| ------------------------------------------------------------ | -------------------------------- | ---------------- | ---- | ----- | -------------------------------------------------------- |
| [An Introduction to Federated Computation](https://dl.acm.org/doi/10.1145/3514221.3522561) |                                  | SIGMOD           | 2022 |       |                                                          |
| [BlindFL: Vertical Federated Machine Learning without Peeking into Your Data](https://dl.acm.org/doi/10.1145/3514221.3526127) |                                  | SIGMOD           | 2022 |       |                                                          |
| [An Efficient Approach for Cross-Silo Federated Learning to Rank](https://ieeexplore.ieee.org/document/9458704) |                                  | ICDE             | 2021 |       |                                                          |
| [Feature Inference Attack on Model Predictions in Vertical Federated Learning](https://ieeexplore.ieee.org/document/9458672/) |                                  | ICDE             | 2021 |       |                                                          |
| [Efficient Federated-Learning Model Debugging](https://ieeexplore.ieee.org/document/9458829) |                                  | ICDE             | 2021 |       |                                                          |
| [Federated Matrix Factorization with Privacy Guarantee](https://www.vldb.org/pvldb/vol15/p900-li.pdf) | Purdue University                | VLDB             | 2021 |       |                                                          |
| [Projected Federated Averaging with Heterogeneous Differential Privacy.](https://dl.acm.org/doi/10.14778/3503585.3503592) | Renmin University of China       | VLDB             | 2021 |       | [Code](https://github.com/Emory-AIMS/PFA)                |
| [Enabling SQL-based Training Data Debugging for Federated Learning](http://www.vldb.org/pvldb/vol15/p388-wu.pdf) | Simon Fraser University          | VLDB             | 2021 |       | [Code](https://github.com/sfu-db/FedRain-and-Frog)       |
| [Refiner: A Reliable Incentive-Driven Federated Learning System Powered by Blockchain](http://vldb.org/pvldb/vol14/p2659-jiang.pdf) | Zhejiang University              | VLDB             | 2021 |       |                                                          |
| [Tanium Reveal: A Federated Search Engine for Querying Unstructured File Data on Large Enterprise Networks](http://www.vldb.org/pvldb/vol14/p3096-stoddard.pdf) | Tanium Inc.                      | VLDB             | 2021 |       |                                                          |
| VF2Boost: Very Fast Vertical Federated Gradient Boosting for Cross-Enterprise Learning |                                  | SIGMOD           | 2021 |       | [[PUB](https://dl.acm.org/doi/10.1145/3448016.3457241).] |
| [ExDRa: Exploratory Data Science on Federated Raw Data](https://dl.acm.org/doi/10.1145/3448016.3457549) |                                  | SIGMOD           | 2021 |       |                                                          |
| [Joint blockchain and federated learning-based offloading in harsh edge computing environments](https://dl.acm.org/doi/10.1145/3460866.3461765) |                                  | SIGMOD  workshop | 2021 |       |                                                          |
| [Privacy Preserving Vertical Federated Learning for Tree-based Models](http://vldb.org/pvldb/vol13/p2090-wu.pdf) | National University of Singapore | VLDB             | 2020 |       | [[Video](https://www.youtube.com/watch?v=sjii8oVCqiY)]   |



## FL in top Network conferences

In this section, we will summarize Federated Learning papers accepted by top Database conference, including [SIGCOMM](https://dblp.org/db/conf/sigcomm/index.html)(Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication), [INFOCOM](https://dblp.org/db/conf/infocom/index.html)(IEEE Conference on Computer Communications), [MobiCom](https://dblp.org/db/conf/mobicom/index.html)(ACM/IEEE International Conference on Mobile Computing and Networking), [NSDI](https://dblp.org/db/conf/nsdi/index.html)(Symposium on Networked Systems Design and Implementation) and  [WWW](https://dblp.org/db/conf/www/index.html)(The Web Conference).

- [SIGCOMM](https://dblp.uni-trier.de/search?q=federate%20venue%3ASIGCOMM%3A) NULL

- [INFOCOM](https://dblp.uni-trier.de/search?q=federate%20venue%3AINFOCOM%3A) 2022, 2021, 2020, 2019
- [MobiCom](https://dblp.uni-trier.de/search?q=federate%20venue%3AMobiCom%3A) 2021, 2020
- [NSDI](https://dblp.uni-trier.de/search?q=federate%20venue%3ANSDI%3A) NULL
- [WWW](https://dblp.uni-trier.de/search?q=federate%20venue%3AWWW%3A)  2022, 2021

| Title                                                        | Affiliation | Venue      | Year | TL;DR | Materials                               |
| ------------------------------------------------------------ | ----------- | ---------- | ---- | ----- | --------------------------------------- |
| [Joint Superposition Coding and Training for Federated Learning over Multi-Width Neural Networks](https://ieeexplore.ieee.org/document/9796733) |             | INFOCOM    | 2022 |       |                                         |
| [Towards Optimal Multi-Modal Federated Learning on Non-IID Data with Hierarchical Gradient Blending](https://ieeexplore.ieee.org/document/9796724) |             | INFOCOM    | 2022 |       |                                         |
| [Optimal Rate Adaption in Federated Learning with Compressed Communications](https://ieeexplore.ieee.org/document/9796982) |             | INFOCOM    | 2022 |       |                                         |
| [The Right to be Forgotten in Federated Learning: An Efficient Realization with Rapid Retraining.](https://ieeexplore.ieee.org/document/9796721) |             | INFOCOM    | 2022 |       |                                         |
| [Tackling System and Statistical Heterogeneity for Federated Learning with Adaptive Client Sampling.](https://ieeexplore.ieee.org/document/9796935) |             | INFOCOM    | 2022 |       |                                         |
| [Communication-Efficient Device Scheduling for Federated Learning Using Stochastic Optimization](https://ieeexplore.ieee.org/document/9796818) |             | INFOCOM    | 2022 |       |                                         |
| [FLASH: Federated Learning for Automated Selection of High-band mmWave Sectors](https://ieeexplore.ieee.org/document/9796865/) |             | INFOCOM    | 2022 |       |                                         |
| [A Profit-Maximizing Model Marketplace with Differentially Private Federated Learning]() |             | INFOCOM    | 2022 |       |                                         |
| [Protect Privacy from Gradient Leakage Attack in Federated Learning](https://ieeexplore.ieee.org/document/9796841/) |             | INFOCOM    | 2022 |       |                                         |
| [FedFPM: A Unified Federated Analytics Framework for Collaborative Frequent Pattern Mining.](https://ieeexplore.ieee.org/document/9796719) |             | INFOCOM    | 2022 |       | [Code](https://github.com/HuskyW/FFPA)  |
| [An Accuracy-Lossless Perturbation Method for Defending Privacy Attacks in Federated Learning](https://dl.acm.org/doi/10.1145/3485447.3512233) |             | WWW        | 2022 |       |                                         |
| [LocFedMix-SL: Localize, Federate, and Mix for Improved Scalability, Convergence, and Latency in Split Learning](https://dl.acm.org/doi/10.1145/3485447.3512153) |             | WWW        | 2022 |       |                                         |
| [Federated Unlearning via Class-Discriminative Pruning](https://dl.acm.org/doi/10.1145/3485447.3512222) |             | WWW        | 2022 |       |                                         |
| [FedKC: Federated Knowledge Composition for Multilingual Natural Language Understanding](https://dl.acm.org/doi/10.1145/3485447.3511988) |             | WWW        | 2022 |       |                                         |
| [Federated Bandit: A Gossiping Approach](https://dl.acm.org/doi/10.1145/3447380) |             | SIGMETRICS | 2021 |       |                                         |
| [Hermes: an efficient federated learning framework for heterogeneous mobile clients](https://dl.acm.org/doi/10.1145/3447993.3483278) |             | MobiCom    | 2021 |       |                                         |
| [Federated mobile sensing for activity recognition](https://dl.acm.org/doi/10.1145/3447993.3488031) |             | MobiCom    | 2021 |       |                                         |
| [Learning for Learning: Predictive Online Control of Federated Learning with Edge Provisioning.](https://ieeexplore.ieee.org/document/9488733/) |             | INFOCOM    | 2021 |       |                                         |
| [Device Sampling for Heterogeneous Federated Learning: Theory, Algorithms, and Implementation.](https://ieeexplore.ieee.org/document/9488906) |             | INFOCOM    | 2021 |       | [PDF](https://arxiv.org/abs/2101.00787) |
| [FAIR: Quality-Aware Federated Learning with Precise User Incentive and Model Aggregation](https://ieeexplore.ieee.org/document/9488743) |             | INFOCOM    | 2021 |       |                                         |
| [Sample-level Data Selection for Federated Learning](https://ieeexplore.ieee.org/document/9488723) |             | INFOCOM    | 2021 |       |                                         |
| [To Talk or to Work: Flexible Communication Compression for Energy Efficient Federated Learning over Heterogeneous Mobile Edge Devices](https://ieeexplore.ieee.org/document/9488839) |             | INFOCOM    | 2021 |       |                                         |
| [Cost-Effective Federated Learning Design](https://ieeexplore.ieee.org/document/9488679) |             | INFOCOM    | 2021 |       |                                         |
| [An Incentive Mechanism for Cross-Silo Federated Learning: A Public Goods Perspective](https://ieeexplore.ieee.org/document/9488705) |             | INFOCOM    | 2021 |       |                                         |
| [Resource-Efficient Federated Learning with Hierarchical Aggregation in Edge Computing](https://ieeexplore.ieee.org/document/9488756/) |             | INFOCOM    | 2021 |       |                                         |
| [FedServing: A Federated Prediction Serving Framework Based on Incentive Mechanism.](https://ieeexplore.ieee.org/document/9488807) |             | INFOCOM    | 2021 |       |                                         |
| [Federated Learning over Wireless Networks: A Band-limited Coordinated Descent Approach](https://ieeexplore.ieee.org/document/9488818) |             | INFOCOM    | 2021 |       |                                         |
| [Dual Attention-Based Federated Learning for Wireless Traffic Prediction](https://ieeexplore.ieee.org/document/9488883) |             | INFOCOM    | 2021 |       |                                         |
| [FedSens: A Federated Learning Approach for Smart Health Sensing with Class Imbalance in Resource Constrained Edge Computing](https://ieeexplore.ieee.org/document/9488776/) |             | INFOCOM    | 2021 |       |                                         |
| [P-FedAvg: Parallelizing Federated Learning with Theoretical Guarantees](https://ieeexplore.ieee.org/document/9488877) |             | INFOCOM    | 2021 |       |                                         |
| [Meta-HAR: Federated Representation Learning for Human Activity Recognition.](https://dl.acm.org/doi/10.1145/3442381.3450006) |             | WWW        | 2021 |       |                                         |
| [PFA: Privacy-preserving Federated Adaptation for Effective Model Personalization](https://dl.acm.org/doi/10.1145/3442381.3449847) |             | WWW        | 2021 |       | [Code](https://github.com/lebyni/PFA)   |
| [Communication Efficient Federated Generalized Tensor Factorization for Collaborative Health Data Analytics](https://dl.acm.org/doi/10.1145/3442381.3449832) |             | WWW        | 2021 |       |                                         |
| [Hierarchical Personalized Federated Learning for User Modeling](https://dl.acm.org/doi/10.1145/3442381.3449926) |             | WWW        | 2021 |       |                                         |
| [Characterizing Impacts of Heterogeneity in Federated Learning upon Large-Scale Smartphone Data](https://dl.acm.org/doi/10.1145/3442381.3449851) |             | WWW        | 2021 |       |                                         |
| [Incentive Mechanism for Horizontal Federated Learning Based on Reputation and Reverse Auction](https://dl.acm.org/doi/10.1145/3442381.3449888) |             | WWW        | 2021 |       |                                         |
| [Physical-Layer Arithmetic for Federated Learning in Uplink MU-MIMO Enabled Wireless Networks.](https://ieeexplore.ieee.org/document/9155479) |             | INFOCOM    | 2020 |       |                                         |
| [Optimizing Federated Learning on Non-IID Data with Reinforcement Learning](https://ieeexplore.ieee.org/document/9155494) |             | INFOCOM    | 2020 |       |                                         |
| [Enabling Execution Assurance of Federated Learning at Untrusted Participants](https://ieeexplore.ieee.org/document/9155414) |             | INFOCOM    | 2020 |       |                                         |
| [Billion-scale federated learning on mobile clients: a submodel design with tunable privacy](https://dl.acm.org/doi/10.1145/3372224.3419188) |             | MobiCom    | 2020 |       |                                         |
| [Federated Learning over Wireless Networks: Optimization Model Design and Analysis](https://ieeexplore.ieee.org/document/8737464) |             | INFOCOM    | 2019 |       |                                         |
| [Beyond Inferring Class Representatives: User-Level Privacy Leakage From Federated Learning](https://ieeexplore.ieee.org/document/8737416) |             | INFOCOM    | 2019 |       |                                         |



## FL in top System conferences

In this section, we will summarize Federated Learning papers accepted by top Database conference, including [OSDI](https://dblp.org/db/conf/osdi/index.html)(USENIX Symposium on Operating Systems Design and Implementation), [SOSP](https://dblp.org/db/conf/sosp/index.html)(Symposium on Operating Systems Principles), [ISCA](https://dblp.org/db/conf/isca/index.html)(International Symposium on Computer Architecture), [MLSys](https://dblp.org/db/conf/mlsys/index.html)(Conference on Machine Learning and Systems).

- [OSDI](https://dblp.org/search?q=federated%20venue%3AOSDI%3A) 2021

- [SOSP](https://dblp.org/search?q=federated%20venue%3ASOSP%3A) 2021

- [ISCA](https://dblp.org/search?q=federated%20venue%3AISCA%3A) NULL

- [MLSys](https://dblp.org/search?q=federated%20venue%3AMLSys%3A) 2022,2020,2019


| Title                                                        | Affiliation | Venue         | Year | TL;DR | Materials                                                    |
| ------------------------------------------------------------ | ----------- | ------------- | ---- | ----- | ------------------------------------------------------------ |
| [PAPAYA: Practical, Private, and Scalable Federated Learning.](https://proceedings.mlsys.org/paper/2022/hash/f340f1b1f65b6df5b5e3f94d95b11daf-Abstract.html) |             | MLSys         | 2022 |       | [[PDF](https://arxiv.org/abs/2111.04877)]                    |
| [LightSecAgg: a Lightweight and Versatile Design for Secure Aggregation in Federated Learning](https://proceedings.mlsys.org/paper/2022/hash/d2ddea18f00665ce8623e36bd4e3c7c5-Abstract.html) |             | MLSys         | 2022 |       | [[PDF](https://arxiv.org/abs/2109.14236)]                    |
| [Oort: Efficient Federated Learning via Guided Participant Selection](https://www.usenix.org/conference/osdi21/presentation/lai) |             | OSDI          | 2021 |       | [[PDF](https://arxiv.org/abs/2010.06081)] [Code](https://github.com/SymbioticLab/Oort) [Slides](https://www.usenix.org/system/files/osdi21_slides_lai.pdf) [Video](https://www.youtube.com/watch?v=5npOel4T4Mw) |
| [FedScale: Benchmarking Model and System Performance of Federated Learning](https://dl.acm.org/doi/10.1145/3477114.3488760) |             | SOSP workshop | 2021 |       |                                                              |
| [Redundancy in cost functions for Byzantine fault-tolerant federated learning](https://dl.acm.org/doi/10.1145/3477114.3488761) |             | SOSP workshop | 2021 |       |                                                              |
| [Towards an Efficient System for Differentially-private, Cross-device Federated Learning](https://dl.acm.org/doi/10.1145/3477114.3488762) |             | SOSP workshop | 2021 |       |                                                              |
| [GradSec: a TEE-based Scheme Against Federated Learning Inference Attacks](https://dl.acm.org/doi/10.1145/3477114.3488763) |             | SOSP workshop | 2021 |       |                                                              |
| [Community-Structured Decentralized Learning for Resilient EI.](https://dl.acm.org/doi/10.1145/3477114.3488764) |             | SOSP workshop | 2021 |       |                                                              |
| [Separation of Powers in Federated Learning (Poster Paper)](https://dl.acm.org/doi/10.1145/3477114.3488765) |             | SOSP workshop | 2021 |       |                                                              |
| [Federated Optimization in Heterogeneous Networks](https://proceedings.mlsys.org/paper/2020/hash/38af86134b65d0f10fe33d30dd76442e-Abstract.html) |             | MLSys         | 2020 |       | [[PDF](https://arxiv.org/abs/1812.06127)] [Code](https://github.com/litian96/FedProx) |
| [Towards Federated Learning at Scale: System Design](https://proceedings.mlsys.org/paper/2019/hash/bd686fd640be98efaae0091fa301e613-Abstract.html) |             | MLSys         | 2019 |       | [[PDF](https://arxiv.org/abs/1902.01046)]                    |



# Framework

## Federated Learning Framework

| Platform                                                     | Papers                                                       | Affiliations                                                 |      Graph data and algorithms       |     Tabular data and algorithms      | Materials                                                    |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | :----------------------------------: | :----------------------------------: | ------------------------------------------------------------ |
| [PySyft](https://github.com/OpenMined/PySyft)<br />[![Stars](https://img.shields.io/github/stars/OpenMined/PySyft.svg?color=red)](https://github.com/OpenMined/PySyft/stargazers)<br />![](https://img.shields.io/github/last-commit/OpenMined/PySyft) | [A generic framework for privacy preserving deep learning](https://arxiv.org/abs/1811.04017) | [OpenMined](https://www.openmined.org/)                      |                                      |                                      | [Doc](https://pysyft.readthedocs.io/en/latest/installing.html) |
| [FATE](https://github.com/FederatedAI/FATE)<br />[![Stars](https://img.shields.io/github/stars/FederatedAI/FATE.svg?color=red)](https://github.com/FederatedAI/FATE/stargazers)<br />![](https://img.shields.io/github/last-commit/FederatedAI/FATE) | [FATE: An Industrial Grade Platform for Collaborative Learning With Data Protection](https://www.jmlr.org/papers/volume22/20-815/20-815.pdf) | [WeBank](https://fedai.org/)                                 |                                      | :white_check_mark::white_check_mark: | [Doc](https://fate.readthedocs.io/en/latest/)<br />[Doc(zh)](https://fate.readthedocs.io/en/latest/zh/) |
| [MindSpore Federated](https://github.com/mindspore-ai/mindspore/tree/master/tests/st/fl)<br />[![Stars](https://img.shields.io/github/stars/mindspore-ai/mindspore.svg?color=red)](https://github.com/mindspore-ai/mindspore/stargazers)<br />![](https://img.shields.io/github/last-commit/mindspore-ai/mindspore) |                                                              | HUAWEI                                                       |                                      |                                      | [Doc](https://mindspore.cn/federated/docs/zh-CN/r1.6/index.html) <br />[Homepage](https://mindspore.cn/federated) |
| [TFF(Tensorflow-Federated)](https://github.com/tensorflow/federated) <br />[![Stars](https://img.shields.io/github/stars/tensorflow/federated.svg?color=red)](https://github.com/tensorflow/federated/stargazers)<br />![](https://img.shields.io/github/last-commit/tensorflow/federated) | [Towards Federated Learning at Scale: System Design](https://arxiv.org/abs/1902.01046) | Google                                                       |                                      |                                      | [Doc](https://www.tensorflow.org/federated) <br />[Homepage](https://www.tensorflow.org/federated) |
| [FedML](https://github.com/FedML-AI/FedML)<br />[![Stars](https://img.shields.io/github/stars/FedML-AI/FedML.svg?color=red)](https://github.com/FedML-AI/FedML/stargazers)<br />![](https://img.shields.io/github/last-commit/FedML-AI/FedML) | [FedML: A Research Library and Benchmark for Federated Machine Learning](https://arxiv.org/abs/2007.13518) | [FedML](https://fedml.ai/)                                   | :white_check_mark::white_check_mark: |          :white_check_mark:          | [Doc](https://doc.fedml.ai/)                                 |
| [Flower](https://github.com/adap/flower)<br />[![Stars](https://img.shields.io/github/stars/adap/flower.svg?color=red)](https://github.com/adap/flower/stargazers)<br />![](https://img.shields.io/github/last-commit/adap/flower) | [Flower: A Friendly Federated Learning Research Framework](https://arxiv.org/pdf/2104.03042.pdf) | [flower.dev](https://flower.dev/) [adap](https://adap.com/en) |                                      |                                      | [Doc](https://flower.dev/docs/)                              |
| [Fedlearner](https://github.com/bytedance/fedlearner)<br />[![Stars](https://img.shields.io/github/stars/bytedance/fedlearner.svg?color=blue)](https://github.com/bytedance/fedlearner/stargazers)<br />![](https://img.shields.io/github/last-commit/bytedance/fedlearner) |                                                              | [Bytedance](https://github.com/bytedance)                    |                                      |                                      |                                                              |
| [SecretFlow](https://github.com/secretflow/secretflow) <br />[![Stars](https://img.shields.io/github/stars/secretflow/secretflow.svg?color=blue)](https://github.com/secretflow/secretflow/stargazers)<br />![](https://img.shields.io/github/last-commit/secretflow/secretflow) |                                                              | [Ant group](https://www.antgroup.com/)                       |                                      |          :white_check_mark:          | [Doc](https://secretflow.readthedocs.io/en/latest/getting_started/index.html) |
| [LEAF](https://github.com/TalwalkarLab/leaf)<br />[![Stars](https://img.shields.io/github/stars/TalwalkarLab/leaf.svg?color=blue)](https://github.com/TalwalkarLab/leaf/stargazers)<br />![](https://img.shields.io/github/last-commit/TalwalkarLab/leaf) | [LEAF: A Benchmark for Federated Settings](https://arxiv.org/pdf/1812.01097.pdf) | [CMU](https://leaf.cmu.edu/)                                 |                                      |                                      |                                                              |
| [FederatedScope](https://github.com/alibaba/FederatedScope)<br />[![Stars](https://img.shields.io/github/stars/alibaba/FederatedScope.svg?color=blue)](https://github.com/alibaba/FederatedScope/stargazers)<br />![](https://img.shields.io/github/last-commit/alibaba/FederatedScope) | [FederatedScope: A Flexible Federated Learning Platform for Heterogeneity](https://arxiv.org/abs/2204.05011) | [Alibaba DAMO Academy](https://damo.alibaba.com/labs/data-analytics-and-intelligence) | :white_check_mark::white_check_mark: |                                      | [Doc](https://federatedscope.io/refs/index)  <br />[Homepage](https://federatedscope.io/) |
| [Rosetta](https://github.com/LatticeX-Foundation/Rosetta)<br />[![Stars](https://img.shields.io/github/stars/LatticeX-Foundation/Rosetta.svg?color=blue)](https://github.com/LatticeX-Foundation/Rosetta/stargazers)<br />![](https://img.shields.io/github/last-commit/LatticeX-Foundation/Rosetta) |                                                              | [matrixelements](https://www.matrixelements.com/product/rosetta) |                                      |                                      | [Doc](https://github.com/LatticeX-Foundation/Rosetta/blob/master/doc/DEPLOYMENT.md) <br />[Homepage](https://github.com/LatticeX-Foundation/Rosetta) |
| [PaddleFL](https://github.com/PaddlePaddle/PaddleFL)<br />[![Stars](https://img.shields.io/github/stars/PaddlePaddle/PaddleFL.svg?color=blue)](https://github.com/PaddlePaddle/PaddleFL/stargazers)<br />![](https://img.shields.io/github/last-commit/PaddlePaddle/PaddleFL) |                                                              | Baidu                                                        |                                      |                                      | [Doc](https://paddlefl.readthedocs.io/en/latest/index.html)  |
| [OpenFL](https://github.com/intel/openfl)<br />[![Stars](https://img.shields.io/github/stars/intel/openfl.svg?color=blue)](https://github.com/intel/openfl/stargazers)<br />![](https://img.shields.io/github/last-commit/intel/openfl) | [OpenFL: An open-source framework for Federated Learning](https://arxiv.org/abs/2105.06413) | [Intel](https://github.com/intel)                            |                                      |                                      | [Doc](https://openfl.readthedocs.io/en/latest/install.html)  |
| [IBM Federated Learning](https://github.com/IBM/federated-learning-lib)<br />[![Stars](https://img.shields.io/github/stars/IBM/federated-learning-lib.svg?color=blue)](https://github.com/IBM/federated-learning-lib/stargazers)<br />![](https://img.shields.io/github/last-commit/IBM/federated-learning-lib) | [IBM Federated Learning: an Enterprise Framework White Paper](https://arxiv.org/pdf/2007.10987.pdf) | [IBM](https://github.com/IBM)                                |                                      |          :white_check_mark:          | [Papers](https://github.com/IBM/federated-learning-lib/blob/main/docs/papers.md) |
| [KubeFATE](https://github.com/FederatedAI/KubeFATE)<br />[![Stars](https://img.shields.io/github/stars/FederatedAI/KubeFATE.svg?color=blue)](https://github.com/FederatedAI/KubeFATE/stargazers)<br />![](https://img.shields.io/github/last-commit/FederatedAI/KubeFATE) |                                                              | [WeBank](https://fedai.org/)                                 |                                      |                                      | [Wiki](https://github.com/FederatedAI/KubeFATE/wiki/#faqs)   |
| [Privacy Meter](https://github.com/privacytrustlab/ml_privacy_meter)<br />[![Stars](https://img.shields.io/github/stars/privacytrustlab/ml_privacy_meter.svg?color=blue)](https://github.com/PaddlePaddle/privacytrustlab/ml_privacy_meter)<br />![](https://img.shields.io/github/last-commit/privacytrustlab/ml_privacy_meter) | [Comprehensive Privacy Analysis of Deep Learning: Passive and Active White-box Inference Attacks against Centralized and Federated Learning](https://ieeexplore.ieee.org/document/8835245) | University of Massachusetts Amherst                          |                                      |                                      |                                                              |
| [Fedlab](https://github.com/SMILELab-FL/FedLab)<br />[![Stars](https://img.shields.io/github/stars/SMILELab-FL/FedLab.svg?color=blue)](https://github.com/SMILELab-FL/FedLab/stargazers)<br />![](https://img.shields.io/github/last-commit/SMILELab-FL/FedLab) | [FedLab: A Flexible Federated Learning Framework](https://arxiv.org/abs/2107.11621) | [SMILELab](https://github.com/SMILELab-FL/)                  |                                      |                                      | [Doc](https://fedlab.readthedocs.io/en/master/)<br />[Doc(zh)](https://fedlab.readthedocs.io/zh_CN/latest/) <br />[Homepage](https://github.com/SMILELab-FL/FedLab-benchmarks) |
| [Differentially Private Federated Learning: A Client-level Perspective](https://github.com/SAP-samples/machine-learning-diff-private-federated-learning) <br />[![Stars](https://img.shields.io/github/stars/SAP-samples/machine-learning-diff-private-federated-learning.svg?color=blue)](https://github.comSAP-samples/machine-learning-diff-private-federated-learning/stargazers)<br />![](https://img.shields.io/github/last-commit/SAP-samples/machine-learning-diff-private-federated-learning) | [Differentially Private Federated Learning: A Client Level Perspective](https://arxiv.org/abs/1712.07557) | [SAP-samples](https://github.com/SAP-samples)                |                                      |                                      |                                                              |
| [NVFlare](https://github.com/NVIDIA/NVFlare)<br />[![Stars](https://img.shields.io/github/stars/NVIDIA/NVFlare.svg?color=blue)](https://github.com/NVIDIA/NVFlare/stargazers)<br />![](https://img.shields.io/github/last-commit/NVIDIA/NVFlare) |                                                              | [NVIDIA](https://github.com/NVIDIA)                          |                                      |                                      | [Doc](https://nvflare.readthedocs.io/en/2.1.1/)              |
| [FedNLP](https://github.com/FedML-AI/FedNLP)<br />[![Stars](https://img.shields.io/github/stars/FedML-AI/FedNLP.svg?color=blue)](https://github.com/FedML-AI/FedNLP/stargazers)<br />![](https://img.shields.io/github/last-commit/FedML-AI/FedNLP) | [FedNLP: Benchmarking Federated Learning Methods for Natural Language  Processing Tasks](https://arxiv.org/abs/2104.08815) | [FedML](https://fedml.ai/)                                   |                                      |                                      |                                                              |
| [FedScale](https://github.com/SymbioticLab/FedScale)<br />[![Stars](https://img.shields.io/github/stars/SymbioticLab/FedScale.svg?color=blue)](https://github.com/SymbioticLab/FedScale/stargazers)<br />![](https://img.shields.io/github/last-commit/SymbioticLab/FedScale) | [FedScale: Benchmarking Model and System Performance of Federated Learning at Scale](https://arxiv.org/pdf/2105.11367.pdf) | [SymbioticLab(U-M)](https://symbioticlab.org/)               |                                      |                                      |                                                              |
| [Backdoors 101](https://github.com/ebagdasa/backdoors101)<br />[![Stars](https://img.shields.io/github/stars/ebagdasa/backdoors101.svg?color=blue)](https://github.com/ebagdasa/backdoors101/stargazers)<br />![](https://img.shields.io/github/last-commit/ebagdasa/backdoors101) | [Blind Backdoors in Deep Learning Models](https://arxiv.org/abs/2005.03823) | Cornell Tech                                                 |                                      |                                      |                                                              |
| [FedJAX](https://github.com/google/fedjax)<br />[![Stars](https://img.shields.io/github/stars/google/fedjax.svg?color=blue)](https://github.com/google/fedjax/stargazers)<br />![](https://img.shields.io/github/last-commit/google/fedjax) | [FEDJAX: Federated learning simulation with JAX](https://arxiv.org/pdf/2108.02117.pdf) | [Google](https://ai.googleblog.com/2021/10/fedjax-federated-learning-simulation.html) |                                      |                                      |                                                              |
| [Xaynet](https://github.com/xaynetwork/xaynet)<br />[![Stars](https://img.shields.io/github/stars/xaynetwork/xaynet.svg?color=blue)](https://github.com/xaynetwork/xaynet/stargazers)<br />![](https://img.shields.io/github/last-commit/xaynetwork/xaynet) |                                                              | [XayNet](https://www.xayn.com/)                              |                                      |                                      | [HomePage](https://www.xaynet.dev/) [Doc](https://docs.rs/xaynet) [Whitepaper](https://uploads-ssl.webflow.com/5f0c5c0bb18a279f0a62919e/5f157004da6585f299fa542b_XayNet%20Whitepaper%202.1.pdf)  [Legal Review](https://uploads-ssl.webflow.com/5f0c5c0bb18a279f0a62919e/5fcfa8e3389ecc84a9309513_XAIN%20Legal%20Review%202020%20v1.pdf) |
| [SyferText](https://github.com/OpenMined/SyferText)<br />[![Stars](https://img.shields.io/github/stars/OpenMined/SyferText.svg?color=blue)](https://github.com/OpenMined/SyferText/stargazers)<br />![](https://img.shields.io/github/last-commit/OpenMined/SyferText) |                                                              | [OpenMined](https://www.openmined.org/)                      |                                      |                                      |                                                              |
| [PFL-Non-IID](https://github.com/TsingZ0/PFL-Non-IID)<br />[![Stars](https://img.shields.io/github/stars/TsingZ0/PFL-Non-IID.svg?color=blue)](https://github.com/TsingZ0/PFL-Non-IID/stargazers)<br />![](https://img.shields.io/github/last-commit/TsingZ0/PFL-Non-IID) |                                                              | SJTU                                                         |                                      |                                      |                                                              |
| [FedGraphNN](https://github.com/FedML-AI/FedGraphNN)<br />[![Stars](https://img.shields.io/github/stars/FedML-AI/FedGraphNN.svg?color=blue)](https://github.com/FedML-AI/FedGraphNN/stargazers)<br />![](https://img.shields.io/github/last-commit/FedML-AI/FedGraphNN) | [FedGraphNN: A Federated Learning System and Benchmark for Graph Neural Networks](https://arxiv.org/abs/2104.07145) | [FedML](https://fedml.ai/)                                   | :white_check_mark::white_check_mark: |                                      |                                                              |
| [Galaxy Federated Learning](https://github.com/GalaxyLearning/GFL)<br />[![Stars](https://img.shields.io/github/stars/GalaxyLearning/GFL.svg?color=blue)](https://github.com/GalaxyLearning/GFL/stargazers)<br />![](https://img.shields.io/github/last-commit/GalaxyLearning/GFL) | [GFL: A Decentralized Federated Learning Framework Based On Blockchain](https://arxiv.org/pdf/2010.10996.pdf) | ZJU                                                          |                                      |                                      | [Doc](http://galaxylearning.github.io/)                      |
| [plato](https://github.com/TL-System/plato)<br />[![Stars](https://img.shields.io/github/stars/TL-System/plato.svg?color=blue)](https://github.com/TL-System/plato/stargazers)<br />![](https://img.shields.io/github/last-commit/TL-System/plato) |                                                              | UofT                                                         |                                      |                                      |                                                              |
| [NIID-Bench](https://github.com/Xtra-Computing/NIID-Bench)<br />[![Stars](https://img.shields.io/github/stars/Xtra-Computing/NIID-Bench.svg?color=blue)](https://github.com/Xtra-Computing/NIID-Bench/stargazers)<br />![](https://img.shields.io/github/last-commit/Xtra-Computing/NIID-Bench) | [Federated Learning on Non-IID Data Silos: An Experimental Study](https://arxiv.org/pdf/2102.02079.pdf) | [Xtra Computing Group](https://github.com/Xtra-Computing)    |                                      |                                      |                                                              |
| [substra](https://github.com/Substra/substra) <br />[![Stars](https://img.shields.io/github/stars/Substra/substra.svg?color=blue)](https://github.com/Substra/substra/stargazers)<br />![](https://img.shields.io/github/last-commit/Substra/substra) |                                                              | [Substra](https://github.com/Substra)                        |                                      |                                      | [Doc](https://doc.substra.ai/index.html)                     |
| [PhotoLabeller](https://github.com/mccorby/PhotoLabeller)<br />[![Stars](https://img.shields.io/github/stars/mccorby/PhotoLabeller.svg?color=blue)](https://github.com/mccorby/PhotoLabeller/stargazers)<br />![](https://img.shields.io/github/last-commit/mccorby/PhotoLabeller) |                                                              |                                                              |                                      |                                      | [Blog](https://proandroiddev.com/federated-learning-e79e054c33ef) |
| [FLSim](https://github.com/facebookresearch/FLSim)<br />[![Stars](https://img.shields.io/github/stars/facebookresearch/FLSim.svg?color=blue)](https://github.com/facebookresearch/FLSim/stargazers)<br />![](https://img.shields.io/github/last-commit/facebookresearch/FLSim) |                                                              | [facebook research ](https://github.com/facebookresearch)    |                                      |                                      |                                                              |
| [PyVertical ](https://github.com/OpenMined/PyVertical)<br />[![Stars](https://img.shields.io/github/stars/OpenMined/PyVertical.svg?color=blue)](https://github.com/OpenMined/PyVertical/stargazers)<br />![](https://img.shields.io/github/last-commit/OpenMined/PyVertical) | [PyVertical: A Vertical Federated Learning Framework for Multi-headed SplitNN](https://arxiv.org/pdf/2104.00489.pdf) | [OpenMined](https://www.openmined.org/)                      |                                      |                                      |                                                              |
| [Primihub](https://github.com/primihub/primihub)<br />[![Stars](https://img.shields.io/github/stars/primihub/primihub.svg?color=blue)](https://github.com/primihub/primihub/stargazers)<br />![](https://img.shields.io/github/last-commit/primihub/primihub) |                                                              | [primihub](https://github.com/primihub)                      |                                      |                                      | [Doc]()                                                      |
| [FedTorch](https://github.com/MLOPTPSU/FedTorch) <br />[![Stars](https://img.shields.io/github/stars/MLOPTPSU/FedTorch.svg?color=blue)](https://github.com/MLOPTPSU/FedTorch/stargazers)<br />![](https://img.shields.io/github/last-commit/MLOPTPSU/FedTorch) | [Distributionally Robust Federated Averaging](https://papers.nips.cc/paper/2020/file/ac450d10e166657ec8f93a1b65ca1b14-Paper.pdf) | Penn State                                                   |                                      |                                      |                                                              |
| [FATE-Serving](https://github.com/FederatedAI/FATE-Serving) <br />[![Stars](https://img.shields.io/github/stars/FederatedAI/FATE-Serving.svg?color=blue)](https://github.com/FederatedAI/FATE-Serving/stargazers)<br />![](https://img.shields.io/github/last-commit/FederatedAI/FATE-Serving) |                                                              | [WeBank](https://fedai.org/)                                 |                                      |                                      | [Doc](https://fate-serving.readthedocs.io/en/develop/)       |
| [FLUTE](https://github.com/microsoft/msrflute)<br />[![Stars](https://img.shields.io/github/stars/microsoft/msrflute.svg?color=blue)](https://github.com/microsoft/msrflute/stargazers)<br />![](https://img.shields.io/github/last-commit/microsoft/msrflute) | [FLUTE: A Scalable, Extensible Framework for High-Performance Federated Learning Simulations](https://arxiv.org/abs/2203.13789) | microsoft                                                    |                                      |                                      | [Doc](https://microsoft.github.io/msrflute/)                 |
| [FLSim](https://github.com/iQua/flsim) <br />[![Stars](https://img.shields.io/github/stars/iQua/flsim.svg?color=blue)](https://github.com/iQua/flsim/stargazers)<br />![](https://img.shields.io/github/last-commit/iQua/flsim) | [Optimizing Federated Learning on Non-IID Data with Reinforcement Learning](https://ieeexplore.ieee.org/document/9155494/) | University of Toronto                                        |                                      |                                      |                                                              |
| [Breaching](https://github.com/JonasGeiping/breaching)<br />[![Stars](https://img.shields.io/github/stars/JonasGeiping/breaching.svg?color=blue)](https://github.com/JonasGeiping/breaching/stargazers)<br />![](https://img.shields.io/github/last-commit/JonasGeiping/breaching) | A Framework for Attacks against Privacy in Federated Learning ([papers](https://github.com/JonasGeiping/breaching)) |                                                              |                                      |                                      |                                                              |
| [9nfl](https://github.com/jd-9n/9nfl)<br />[![Stars](https://img.shields.io/github/stars/jd-9n/9nfl.svg?color=blue)](https://github.com/jd-9n/9nfl/stargazers)<br />![](https://img.shields.io/github/last-commit/jd-9n/9nfl) |                                                              | JD                                                           |                                      |                                      |                                                              |
| [FedLearn](https://github.com/fedlearnAI/fedlearn-algo)<br />[![Stars](https://img.shields.io/github/stars/fedlearnAI/fedlearn-algo.svg?color=blue)](https://github.com/fedlearnAI/fedlearn-algo/stargazers)<br />![](https://img.shields.io/github/last-commit/fedlearnAI/fedlearn-algo) | [Fedlearn-Algo: A flexible open-source privacy-preserving machine learning platform](https://arxiv.org/abs/2107.04129) | JD                                                           |                                      |                                      |                                                              |
| [EasyFL](https://github.com/EasyFL-AI/EasyFL)<br />[![Stars](https://img.shields.io/github/stars/EasyFL-AI/EasyFL.svg?color=blue)](https://github.com/EasyFL-AI/EasyFL/stargazers)<br />![](https://img.shields.io/github/last-commit/EasyFL-AI/EasyFL) | [EasyFL: A Low-code Federated Learning Platform For Dummies](https://ieeexplore.ieee.org/abstract/document/9684558) | NTU                                                          |                                      |                                      |                                                              |
| [FEDn](https://github.com/scaleoutsystems/fedn)<br />[![Stars](https://img.shields.io/github/stars/scaleoutsystems/fedn.svg?color=blue)](https://github.com/scaleoutsystems/fedn/stargazers)<br />![](https://img.shields.io/github/last-commit/scaleoutsystems/fedn) | [Scalable federated machine learning with FEDn](https://arxiv.org/abs/2103.00148) | [scaleoutsystems](http://www.scaleoutsystems.com)            |                                      |                                      | [Doc](https://scaleoutsystems.github.io/fedn/)               |
| [FedCV](https://github.com/FedML-AI/FedCV)<br />[![Stars](https://img.shields.io/github/stars/FedML-AI/FedCV.svg?color=blue)](https://github.com/FedML-AI/FedCV/stargazers)<br />![](https://img.shields.io/github/last-commit/FedML-AI/FedCV) | [FedCV: A Federated Learning Framework for Diverse Computer Vision Tasks](https://arxiv.org/abs/2111.11066) | FedML                                                        |                                      |                                      |                                                              |
| [FedTree](https://github.com/Xtra-Computing/FedTree)<br />[![Stars](https://img.shields.io/github/stars/Xtra-Computing/FedTree.svg?color=blue)](https://github.com/Xtra-Computing/FedTree/stargazers)<br />![](https://img.shields.io/github/last-commit/Xtra-Computing/FedTree) |                                                              | [Xtra Computing Group](https://github.com/Xtra-Computing)    |                                      | :white_check_mark::white_check_mark: | [Doc](https://fedtree.readthedocs.io/en/latest/index.html)   |
| [MPLC](https://github.com/LabeliaLabs/distributed-learning-contributivity)<br />[![Stars](https://img.shields.io/github/stars/LabeliaLabs/distributed-learning-contributivity.svg?color=blue)](https://github.com/LabeliaLabs/distributed-learning-contributivity/stargazers)<br />![](https://img.shields.io/github/last-commit/LabeliaLabs/distributed-learning-contributivity) |                                                              | [LabeliaLabs](https://github.com/LabeliaLabs)                |                                      |                                      | [HomePage](https://www.labelia.org)                          |
| [OpenHealth](https://github.com/QibingLee/OpenHealth) <br />[![Stars](https://img.shields.io/github/stars/QibingLee/OpenHealth.svg?color=blue)](https://github.com/QibingLee/OpenHealth/stargazers)<br />![](https://img.shields.io/github/last-commit/QibingLee/OpenHealth) |                                                              | ZJU                                                          |                                      |                                      |                                                              |
| [OpenFed](https://github.com/FederalLab/OpenFed/)<br />[![Stars](https://img.shields.io/github/stars/FederalLab/OpenFed.svg?color=blue)](https://github.com/FederalLab/OpenFed/stargazers)<br />![](https://img.shields.io/github/last-commit/FederalLab/OpenFed) | [OpenFed: A Comprehensive and Versatile Open-Source Federated Learning Framework](https://arxiv.org/abs/2109.07852) |                                                              |                                      |                                      | [Doc](https://openfed.readthedocs.io/README.html)            |
| [FedEval](https://github.com/Di-Chai/FedEval)<br />[![Stars](https://img.shields.io/github/stars/Di-Chai/FedEval.svg?color=blue)](https://github.com/Di-Chai/FedEval/stargazers)<br />![](https://img.shields.io/github/last-commit/Di-Chai/FedEval) | [FedEval: A Benchmark System with a Comprehensive Evaluation Model for Federated Learning](https://arxiv.org/abs/2011.09655) | HKU                                                          |                                      |                                      | [Doc](https://di-chai.github.io/FedEval/)                    |
| [APPFL](https://github.com/APPFL/APPFL)<br />[![Stars](https://img.shields.io/github/stars/APPFL/APPFL.svg?color=blue)](https://github.com/APPFL/APPFL/stargazers)<br />![](https://img.shields.io/github/last-commit/APPFL/APPFL) |                                                              |                                                              |                                      |                                      | [Doc](https://appfl.readthedocs.io/en/stable/)               |
| [Flame](https://github.com/cisco-open/flame)<br />[![Stars](https://img.shields.io/github/stars/cisco-open/flame.svg?color=blue)](https://github.com/cisco-open/flame/stargazers)<br />![](https://img.shields.io/github/last-commit/cisco-open/flame) |                                                              | Cisco                                                        |                                      |                                      |                                                              |
| [Clara](https://developer.nvidia.com/clara)                  |                                                              | NVIDIA                                                       |                                      |                                      |                                                              |



# Datasets

(todo)



## How to contact us

**More items will be added to the repository**. Please feel free to suggest other key resources by opening an [issue](https://github.com/youngfish42/Awesome-Federated-Learning-on-Graph-and-Tabular-Data/issues) report, submitting a pull request, or dropping me an email @ ([im.young@foxmail.com](mailto:im.young@foxmail.com)). Enjoy reading!



## Acknowledgments

Many thanks :heart: to the other awesome list:

- Federated Learning

  - [Awesome-Federated-Learning-on-Graph-and-GNN-papers](https://github.com/huweibo/Awesome-Federated-Learning-on-Graph-and-GNN-papers)  
  - [Awesome-GNN-Research](https://github.com/XunKaiLi/Awesome-GNN-Research)
  - [Awesome-Federated-Machine-Learning](https://github.com/innovation-cat/Awesome-Federated-Machine-Learning)
  - [Awesome-Federated-Learning](https://github.com/chaoyanghe/Awesome-Federated-Learning)
  - [awesome-federated-learning](https://github.com/weimingwill/awesome-federated-learning)
  - [Federated-Learning](https://github.com/lokinko/Federated-Learning)
  - [FLsystem-paper](https://github.com/AmberLJC/FLsystem-paper)
- Other fields

  - [anomaly-detection-resources](https://github.com/yzhao062/anomaly-detection-resources)
  - [awesome-image-registration](https://github.com/Awesome-Image-Registration-Organization/awesome-image-registration)







[![map](https://rf.revolvermaps.com/h/m/a/0/ff0000/128/35/5zw06d5f905.png)](https://www.revolvermaps.com/livestats/5zw06d5f905/)





[^CE]: CE propose the concept of benefit graph which describes how each client can benefit from collaborating with other clients and advance a Pareto optimization approach to identify the optimal collaborators. CE提出了利益图的概念，描述了每个客户如何从与其他客户的合作中获益，并提出了帕累托优化方法来确定最佳合作者。
[^Comm-FedBiO]: Comm-FedBiO propose a learning-based reweighting approach to mitigate the effect of noisy labels in FL. Comm-FedBiO提出了一种基于学习的重加权方法，以减轻FL中噪声标签的影响。
[^FLDetector]: FLDetector detects malicious clients via checking their model-updates consistency to defend against model poisoning attacks with a large number of malicious clients. FLDetector 通过检查其模型更新的一致性来检测恶意客户，以防御大量恶意客户的模型中毒攻击。
[^FedSVD]: FedSVD, a practical lossless federated SVD method over billion-scale data, which can simultaneously achieve lossless accuracy and high efficiency. FedSVD，是一种实用的亿级数据上的无损联合SVD方法，可以同时实现无损精度和高效率。
[^FedWalk]: FedWalk, a random-walk-based unsupervised node embedding algorithm that operates in such a node-level visibility graph with raw graph information remaining locally. FedWalk，一个基于随机行走的无监督节点嵌入算法，在这样一个节点级可见度图中操作，原始图信息保留在本地。
[^FederatedScope-GNN]: FederatedScope-GNN present an easy-to-use FGL (federated graph learning) package. FederatedScope-GNN提出了一个易于使用的FGL（联邦图学习）软件包。
[^Fed-LTD]: Federated Learning-to-Dispatch (Fed-LTD), a framework that allows effective order dispatching by sharing both dispatching models and decisions while providing privacy protection of raw data and high efficiency. 解决跨平台叫车问题，即多平台在不共享数据的情况下协同进行订单分配。
[^InclusiveFL]: InclusiveFL is to assign models of different sizes to clients with different computing capabilities, bigger models for powerful clients and smaller ones for weak clients. InclusiveFL 将不同大小的模型分配给具有不同计算能力的客户，较大的模型用于强大的客户，较小的用于弱小的客户。
[^FedAttack]: FedAttack a simple yet effective and covert poisoning attack method on federated recommendation, core idea is using globally hardest samples to subvert model training. FedAttack是一种对联合推荐的简单而有效的隐蔽中毒攻击方法，核心思想是利用全局最难的样本来颠覆模型训练。
[^ATPFL]: ATPFL helps users federate multi-source trajectory datasets to automatically design and train a powerful TP model. ATPFL帮助用户联合多源轨迹数据集，自动设计和训练强大的TP轨迹预测模型。
[^ViT-FL]: ViT-FL demonstrate that self-attention-based architectures (e.g., Transformers) are more robust to distribution shifts and hence improve federated learning over heterogeneous data. ViT-FL证明了基于自注意力机制架构（如 Transformers）对分布的转变更加稳健，从而改善了异构数据的联邦学习。
[^FedCorr]: FedCorr, a general multi-stage framework to tackle heterogeneous label noise in FL, without making any assumptions on the noise models of local clients, while still maintaining client data privacy.  FedCorr 一个通用的多阶段框架来处理FL中的异质标签噪声，不对本地客户的噪声模型做任何假设，同时仍然保持客户数据的隐私。
[^pFedLA]: A novel pFL training framework dubbed Layer-wised Personalized Federated learning (pFedLA) that can discern the importance of each layer from different clients, and thus is able to optimize the personalized model aggregation for clients with heterogeneous data. "层级个性化联合学习"（pFedLA），它可以从不同的客户那里分辨出每一层的重要性，从而能够为拥有异质数据的客户优化个性化的模型聚合。
[^FedAlign]: FedAlign rethinks solutions to data heterogeneity in FL with a focus on local learning generality rather than proximal restriction. 我们重新思考FL中数据异质性的解决方案，重点是本地学习的通用性(generality)而不是近似限制。
[^PANs]: Position-Aware Neurons (PANs) , fusing position-related values (i.e., position encodings) into neuron outputs, making parameters across clients pre-aligned and facilitating coordinate-based parameter averaging. 位置感知神经元（PANs）将位置相关的值（即位置编码）融合到神经元输出中，使各客户的参数预先对齐，并促进基于坐标的参数平均化。
[^GGL]: Generative Gradient Leakage (GGL) validate that the private training data can still be leaked under certain defense settings with a new type of leakage. 生成梯度泄漏（GGL）验证了在某些防御设置下，私人训练数据仍可被泄漏。
[^FedDC]: FedDC propose a novel federated learning algorithm with local drift decoupling and correction. FedDC 一种带有本地漂移解耦和校正的新型联邦学习算法。
[^RSCFed]: Federated semi-supervised learning (FSSL) aims to derive a global model by training fully-labeled and fully-unlabeled clients or training partially labeled clients.  RSCFed presents a Random Sampling Consensus Federated learning, by considering the uneven reliability among models from fully-labeled clients, fully-unlabeled clients or partially labeled clients. 联邦半监督学习（FSSL）旨在通过训练有监督和无监督的客户或半监督的客户来得出一个全局模型。 随机抽样共识联合学习，即RSCFed，考虑来自有监督的客户、无监督的客户或半监督的客户的模型之间不均匀的可靠性。
[^FCCL]: FCCL (Federated Cross-Correlation and Continual Learning) For heterogeneity problem, FCCL leverages unlabeled public data for communication and construct cross-correlation matrix to learn a generalizable representation under domain shift. Meanwhile, for catastrophic forgetting, FCCL utilizes knowledge distillation in local updating, providing inter and intra domain information without leaking privacy.   FCCL（联邦交叉相关和持续学习）对于异质性问题，FCCL利用未标记的公共数据进行交流，并构建交叉相关矩阵来学习领域转移下的可泛化表示。同时，对于灾难性遗忘，FCCL利用局部更新中的知识提炼，在不泄露隐私的情况下提供域间和域内信息。
[^GLFC]: Global-Local Forgetting Compensation (GLFC) model, to learn a global class incremental model for alleviating the catastrophic forgetting from both local and global perspectives. 全局-局部遗忘补偿（GLFC）模型，从局部和全局的角度学习一个全局类增量模型来缓解灾难性的遗忘问题。
[^DP-FedAvg+BLUR+LUS]: DP-FedAvg+BLUR+LUS study the cause of model performance degradation in federated learning under user-level DP guarantee and propose two techniques, Bounded Local Update Regularization and Local Update Sparsification, to increase model quality without sacrificing privacy. DP-FedAvg+BLUR+LUS 研究了在用户级DP保证下联合学习中模型性能下降的原因,提出了两种技术，即有界局部更新正则化和局部更新稀疏化，以提高模型质量而不牺牲隐私。
[^RHFL]: RHFL (Robust Heterogeneous Federated Learning)  simultaneously handles the label noise and performs federated learning in a single framework. RHFL（稳健模型异构联邦学习），它同时处理标签噪声并在一个框架内执行联邦学习。
[^ResSFL]: ResSFL, a Split Federated Learning Framework that is designed to be MI-resistant during training. ResSFL一个分割学习的联邦学习框架，它被设计成在训练期间可以抵抗MI模型逆向攻击。 Model Inversion (MI) attack 模型逆向攻击 。
[^FedCor]: FedCor, an FL framework built on a correlation-based client selection strategy, to boost the convergence rate of FL. FedCor 一个建立在基于相关性的客户选择策略上的FL框架，以提高FL的收敛率。
[^FedFTG]: FedFTG, a data-free knowledge distillation method to fine-tune the global model in the server, which relieves the issue of direct model aggregation. FedFTG, 一种无数据的知识蒸馏方法来微调服务器中的全局模型，它缓解了直接模型聚合的问题。
[^CD2-pFed]: CD2-pFed, a novel Cyclic Distillation-guided Channel Decoupling framework, to personalize the global model in FL, under various settings of data heterogeneity. CD2-pFed，一个新的循环蒸馏引导的通道解耦框架，在各种数据异质性的设置下，在FL中实现全局模型的个性化。
[^FedSM]: FedSM propose a novel training framework  to avoid the client drift issue and successfully close the generalization gap compared with the centralized training for medical image segmentation tasks for the first time. 新的训练框架FedSM，以避免客户端漂移问题，并首次成功地缩小了与集中式训练相比在医学图像分割任务中的泛化差距。
[^FedReID]: FedReID implement federated learning to person re-identification and optimize its performance affected by statistical heterogeneity in the real-world scenario. FedReID 实现了对行人重识别任务的联邦学习，并优化了其在真实世界场景中受统计异质性影响的性能。
[^InvisibleFL]: InvisibleFL propose a privacy-preserving solution that avoids multimedia privacy leakages in federated learning.  InvisibleFL 提出了一个保护隐私的解决方案，以避免联合学习中的多媒体隐私泄漏。
[^FedUReID]: FedUReID, a federated unsupervised person ReID system to learn person ReID models without any labels while preserving privacy. FedUReID，一个联合的无监督人物识别系统，在没有任何标签的情况下学习人物识别模型，同时保护隐私。
[^FedVC+FedIR]: Introduce two new large-scale datasets for species and landmark classification, with realistic per-user data splits that simulate real-world edge learning scenarios. We also develop two new algorithms (FedVC, FedIR) that intelligently resample and reweight over the client pool, bringing large improvements in accuracy and stability in training.  为物种和地标分类引入了两个新的大规模数据集，每个用户的现实数据分割模拟了真实世界的边缘学习场景。我们还开发了两种新的算法（FedVC、FedIR），在客户池上智能地重新取样和重新加权，在训练中带来了准确性和稳定性的巨大改进
[^FedU]: FedU a novel federated unsupervised learning framework. FedU 一个新颖的无监督联邦学习框架.
[^FedAD]: FedAD propose a new distillation-based FL frame-work that can preserve privacy by design, while also consuming substantially less network communication resources when compared to the current methods. FedAD 一个新的基于蒸馏的FL框架，它可以通过设计来保护隐私，同时与目前的方法相比，消耗的网络通信资源也大大减少
[^FedUFO]: FedUFO a Unified Feature learning and Optimization objectives alignment method for non-IID FL. FedUFO 一种针对non IID FL的统一特征学习和优化目标对齐算法。
[^FL-MRCM]: FL-MRCM propose a federated learning (FL) based solution in which we take advantage of the MR data available at different institutions while preserving patients' privacy. FL-MRCM 一个基于联邦学习（FL）的解决方案，其中我们利用了不同机构的MR数据，同时保护了病人的隐私。
[^MOON]: MOON: model-contrastive federated learning. MOON is to utilize the similarity between model representations to correct the local training of individual parties, i.e., conducting contrastive learning in model-level.  MOON 模型对比学习。MOON的关键思想是利用模型表征之间的相似性来修正各方的局部训练，即在模型层面进行对比学习。
[^FedDG-ELCFS]: FedDG-ELCFS A novel problem setting of federated domain generalization (FedDG), which aims to learn a federated model from multiple distributed source domains such that it can directly generalize to unseen target domains. Episodic Learning in Continuous Frequency Space (ELCFS), for this problem by enabling each client to exploit multi-source data distributions under the challenging constraint of data decentralization. FedDG-ELCFS 联邦域泛化（FedDG）旨在从多个分布式源域中学习一个联邦模型，使其能够直接泛化到未见过的目标域中。连续频率空间中的偶发学习（ELCFS），使每个客户能够在数据分散的挑战约束下利用多源数据分布。
[^Soteria]: Soteria propose a defense against model inversion attack in FL,  learning to perturb data representation such that the quality of the reconstructed data is severely degraded, while FL performance is maintained. Soteria 一种防御FL中模型反转攻击的方法,关键思想是学习扰乱数据表示，使重建数据的质量严重下降，而FL性能保持不变。

[^LC-Fed]: LC-Fed propose a personalized federated framework with Local Calibration, to leverage the inter-site in-consistencies in both feature- and prediction- levels to boost the segmentation. LC-Fed提出了一个带有本地校准的个性化联邦学习框架，以利用特征和预测层面的站点间不一致来提高分割效果。
[^FedSAM]: Models trained in federated settings often suffer from degraded performances and fail at generalizing, especially when facing heterogeneous scenarios. FedSAM investigate such behavior through the lens of geometry of the loss and Hessian eigenspectrum, linking the model's lack of generalization capacity to the sharpness of the solution. 联邦学习环境下训练的模型经常会出现性能下降和泛化失败的情况，特别是在面对异质场景时。FedSAM 通过损失和Hessian特征谱的几何角度来研究这种行为，将模型缺乏泛化能力与解决方案的锐度联系起来。



[^FGML]: FGML a comprehensive review of the literature in Federated Graph Machine Learning. FGML 对图联邦机器学习的文献进行了全面回顾。



[^GAMF]: GAMF formulate the model fusion problem as a graph matching task, considering the second-order similarity of model weights instead of previous work merely formulating model fusion as a linear assignment problem. For the rising problem scale and multi-model consistency issues, GAMF propose an efficient graduated assignment-based model fusion method,  iteratively updates the matchings in a consistency-maintaining manner. GAMF将模型融合问题表述为图形匹配任务，考虑了模型权重的二阶相似性，而不是之前的工作仅仅将模型融合表述为一个线性赋值问题。针对问题规模的扩大和多模型的一致性问题，GAMF提出了一种高效的基于分级赋值的模型融合方法，以保持一致性的方式迭代更新匹配结果。
